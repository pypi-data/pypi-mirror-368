"""
Emotion data analysis and insights
"""

import zoneinfo
from collections import Counter, defaultdict
from datetime import datetime, timedelta, timezone
from typing import Any, Dict, List, Tuple

from rich.console import Console
from rich.panel import Panel
from rich.progress import track
from rich.table import Table
from rich.text import Text

from .data_manager import DataManager

# Korean timezone
KST = zoneinfo.ZoneInfo("Asia/Seoul")

console = Console()


class EmotionAnalyzer:
    """Analyzes emotion log data and provides insights"""

    def __init__(self):
        self.data_manager = DataManager()

    def show_stats(self, period: str = "week"):
        """Show basic emotion statistics"""
        # Get data for the specified period
        entries = self._get_period_entries(period)

        if not entries:
            console.print(f"[yellow]{period} ê¸°ê°„ì— ê¸°ë¡ëœ ê°ì •ì´ ì—†ìŠµë‹ˆë‹¤.[/yellow]")
            return

        console.print(f"\n[bold blue]ğŸ“Š {period.upper()} ê°ì • ë¶„í¬[/bold blue]")
        console.print("â”" * 30)

        # Emotion distribution
        emotions = [entry["emotion"] for entry in entries if entry.get("emotion")]
        emotion_counts = Counter(emotions)
        total_count = len(entries)

        # Create emotion distribution table
        table = Table(show_header=True, header_style="bold cyan")
        table.add_column("ê°ì •", style="cyan")
        table.add_column("íšŸìˆ˜", justify="right")
        table.add_column("ë¹„ìœ¨", justify="right")
        table.add_column("ì‹œê°í™”", style="blue")

        for emotion, count in emotion_counts.most_common():
            percentage = (count / total_count) * 100
            bar = "â–ˆ" * int(percentage / 3)  # Scale down for display
            table.add_row(
                emotion, str(count), f"{percentage:.1f}%", f"{bar} {percentage:.1f}%"
            )

        console.print(table)

        # Average intensity
        intensities = [
            entry.get("intensity", 5) for entry in entries if entry.get("intensity")
        ]
        if intensities:
            avg_intensity = sum(intensities) / len(intensities)
            console.print(f"\nğŸ“ˆ í‰ê·  ê°•ë„: {avg_intensity:.1f}/10")

        # Context distribution
        contexts = [entry["context"] for entry in entries if entry.get("context")]
        context_counts = Counter(contexts)
        console.print(f"\nğŸ·ï¸ ì£¼ìš” ì»¨í…ìŠ¤íŠ¸:")
        for context, count in context_counts.most_common(3):
            percentage = (count / total_count) * 100
            console.print(f"   {context}: {count}íšŒ ({percentage:.1f}%)")

        console.print(f"\nğŸ“… ì´ ê¸°ë¡: {total_count}ê°œ")

    def show_patterns(self):
        """Show emotion patterns and trends"""
        entries = self.data_manager.load_entries()

        if len(entries) < 5:
            console.print(
                "[yellow]íŒ¨í„´ ë¶„ì„ì„ ìœ„í•´ì„œëŠ” ìµœì†Œ 5ê°œ ì´ìƒì˜ ê¸°ë¡ì´ í•„ìš”í•©ë‹ˆë‹¤.[/yellow]"
            )
            return

        console.print("\n[bold blue]ğŸ” ë°œê²¬ëœ íŒ¨í„´ë“¤[/bold blue]")
        console.print("â”" * 30)

        patterns = []

        # Day of week patterns
        patterns.extend(self._analyze_day_patterns(entries))

        # Time of day patterns
        patterns.extend(self._analyze_time_patterns(entries))

        # Tag-emotion patterns
        patterns.extend(self._analyze_tag_patterns(entries))

        # Context-emotion patterns
        patterns.extend(self._analyze_context_patterns(entries))

        if patterns:
            for pattern in patterns:
                console.print(f"â€¢ {pattern}")
        else:
            console.print("[dim]ì•„ì§ ëª…í™•í•œ íŒ¨í„´ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.[/dim]")

    def show_triggers(self):
        """Show stress triggers and negative emotion analysis"""
        entries = self.data_manager.load_entries()

        # Define negative emotions
        negative_emotions = [
            "ìŠ¤íŠ¸ë ˆìŠ¤",
            "ë¶ˆì•ˆ",
            "ì¢Œì ˆ",
            "í™”ë‚¨",
            "ê¸´ì¥",
            "í”¼ë¡œ",
            "ê±±ì •",
            "ìŠ¬í””",
            "ì§œì¦",
            "ì‹¤ë§",
            "ìš°ìš¸",
            "ë‘ë ¤ì›€",
        ]

        # Filter negative emotion entries
        negative_entries = [
            entry
            for entry in entries
            if entry.get("emotion", "").lower()
            in [e.lower() for e in negative_emotions]
        ]

        if not negative_entries:
            console.print("[green]ë¶€ì •ì ì¸ ê°ì • ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤! ğŸ‰[/green]")
            return

        console.print("\n[bold red]ğŸ¯ ìŠ¤íŠ¸ë ˆìŠ¤ ìœ ë°œ ìš”ì¸ ë¶„ì„[/bold red]")
        console.print("â”" * 35)

        # Analyze situations that trigger negative emotions
        situations = [
            entry["situation"] for entry in negative_entries if entry.get("situation")
        ]
        situation_analysis = self._analyze_triggers(situations, negative_entries)

        # Create triggers table
        table = Table(show_header=True, header_style="bold red")
        table.add_column("ìˆœìœ„", justify="center")
        table.add_column("íŠ¸ë¦¬ê±°", style="red")
        table.add_column("ë°œìƒ íšŸìˆ˜", justify="right")
        table.add_column("í‰ê·  ê°•ë„", justify="right")

        for i, (trigger, count, avg_intensity) in enumerate(situation_analysis[:5], 1):
            table.add_row(str(i), trigger, f"{count}íšŒ", f"{avg_intensity:.1f}/10")

        console.print(table)

        # Most stressful tags
        tags_analysis = self._analyze_tag_triggers(negative_entries)
        if tags_analysis:
            console.print(f"\n[bold red]ğŸ·ï¸ ì£¼ìš” ìŠ¤íŠ¸ë ˆìŠ¤ íƒœê·¸:[/bold red]")
            for tag, count, avg_intensity in tags_analysis[:3]:
                console.print(f"   {tag}: {count}íšŒ (í‰ê·  ê°•ë„ {avg_intensity:.1f})")

    def show_timeline(self, period: str = "today"):
        """Show emotion timeline"""
        entries = self._get_period_entries(period)

        if not entries:
            console.print(f"[yellow]{period} ê¸°ê°„ì— ê¸°ë¡ëœ ê°ì •ì´ ì—†ìŠµë‹ˆë‹¤.[/yellow]")
            return

        console.print(f"\n[bold blue]ğŸ“ˆ {period.upper()} ê°ì • íƒ€ì„ë¼ì¸[/bold blue]")
        console.print("â”" * 30)

        for entry in entries:
            # Parse timestamp and convert to KST
            timestamp_str = entry["timestamp"]
            if timestamp_str.endswith("Z"):
                timestamp = datetime.fromisoformat(
                    timestamp_str.replace("Z", "+00:00")
                ).astimezone(KST)
            elif "+" in timestamp_str:
                timestamp = datetime.fromisoformat(timestamp_str).astimezone(KST)
            else:
                timestamp = datetime.fromisoformat(timestamp_str)
                if timestamp.tzinfo is None:
                    timestamp = timestamp.replace(tzinfo=KST)

            time_str = timestamp.strftime("%H:%M")
            emotion = entry.get("emotion", "?")
            intensity = entry.get("intensity", 5)
            situation = entry.get("situation", "")[:30] + (
                "..." if len(entry.get("situation", "")) > 30 else ""
            )

            # Create visual bar based on intensity
            bar = "â–ˆ" * intensity
            bar_color = self._get_emotion_color(emotion)

            console.print(
                f"{time_str}  {emotion}({intensity}) [{bar_color}]{bar}[/{bar_color}]  {situation}"
            )

    def _get_period_entries(self, period: str) -> List[Dict[str, Any]]:
        """Get entries for a specific period"""
        now = datetime.now(KST)

        if period == "today":
            start_date = now.replace(hour=0, minute=0, second=0, microsecond=0)
            end_date = now
        elif period == "week":
            start_date = now - timedelta(days=7)
            end_date = now
        elif period == "month":
            start_date = now - timedelta(days=30)
            end_date = now
        else:
            # Default to week
            start_date = now - timedelta(days=7)
            end_date = now

        return self.data_manager.load_entries(start_date, end_date)

    def _analyze_day_patterns(self, entries: List[Dict[str, Any]]) -> List[str]:
        """Analyze patterns by day of week"""
        patterns = []
        day_emotions = defaultdict(list)

        for entry in entries:
            # Parse timestamp and convert to KST
            timestamp_str = entry["timestamp"]
            if timestamp_str.endswith("Z"):
                timestamp = datetime.fromisoformat(
                    timestamp_str.replace("Z", "+00:00")
                ).astimezone(KST)
            elif "+" in timestamp_str:
                timestamp = datetime.fromisoformat(timestamp_str).astimezone(KST)
            else:
                timestamp = datetime.fromisoformat(timestamp_str)
                if timestamp.tzinfo is None:
                    timestamp = timestamp.replace(tzinfo=KST)

            day_name = timestamp.strftime("%A")
            emotion = entry.get("emotion", "")
            intensity = entry.get("intensity", 5)

            day_emotions[day_name].append((emotion, intensity))

        # Find patterns
        for day, emotions in day_emotions.items():
            if len(emotions) >= 3:  # Need sufficient data
                negative_emotions = ["ìŠ¤íŠ¸ë ˆìŠ¤", "ë¶ˆì•ˆ", "ì¢Œì ˆ", "í™”ë‚¨", "ê¸´ì¥"]
                negative_count = sum(
                    1 for emotion, _ in emotions if emotion in negative_emotions
                )

                if negative_count / len(emotions) > 0.6:  # 60% negative
                    patterns.append(
                        f"{day}ì— ë¶€ì •ì ì¸ ê°ì •ì´ ì§‘ì¤‘ë˜ëŠ” ê²½í–¥ ({negative_count}/{len(emotions)})"
                    )

        return patterns

    def _analyze_time_patterns(self, entries: List[Dict[str, Any]]) -> List[str]:
        """Analyze patterns by time of day"""
        patterns = []
        time_emotions = defaultdict(list)

        for entry in entries:
            # Parse timestamp and convert to KST
            timestamp_str = entry["timestamp"]
            if timestamp_str.endswith("Z"):
                timestamp = datetime.fromisoformat(
                    timestamp_str.replace("Z", "+00:00")
                ).astimezone(KST)
            elif "+" in timestamp_str:
                timestamp = datetime.fromisoformat(timestamp_str).astimezone(KST)
            else:
                timestamp = datetime.fromisoformat(timestamp_str)
                if timestamp.tzinfo is None:
                    timestamp = timestamp.replace(tzinfo=KST)

            hour = timestamp.hour
            emotion = entry.get("emotion", "")
            intensity = entry.get("intensity", 5)

            time_slot = self._get_time_slot(hour)
            time_emotions[time_slot].append((emotion, intensity))

        # Find high-stress time periods
        for time_slot, emotions in time_emotions.items():
            if len(emotions) >= 3:
                avg_intensity = sum(intensity for _, intensity in emotions) / len(
                    emotions
                )
                if avg_intensity > 6.5:
                    patterns.append(
                        f"{time_slot} ì‹œê°„ëŒ€ì— ê°ì • ê°•ë„ê°€ ë†’ì€ í¸ (í‰ê·  {avg_intensity:.1f})"
                    )

        return patterns

    def _analyze_tag_patterns(self, entries: List[Dict[str, Any]]) -> List[str]:
        """Analyze emotion patterns by tags"""
        patterns = []
        tag_emotions = defaultdict(list)

        for entry in entries:
            tags = entry.get("tags", [])
            emotion = entry.get("emotion", "")
            intensity = entry.get("intensity", 5)

            for tag in tags:
                tag_emotions[tag].append((emotion, intensity))

        # Find problematic tags
        for tag, emotions in tag_emotions.items():
            if len(emotions) >= 3:
                avg_intensity = sum(intensity for _, intensity in emotions) / len(
                    emotions
                )
                if avg_intensity > 7:
                    patterns.append(
                        f"'{tag}' íƒœê·¸ê°€ ìˆì„ ë•Œ ê°ì • ê°•ë„ê°€ ë†’ìŒ (í‰ê·  {avg_intensity:.1f})"
                    )

        return patterns

    def _analyze_context_patterns(self, entries: List[Dict[str, Any]]) -> List[str]:
        """Analyze emotion patterns by context"""
        patterns = []
        context_emotions = defaultdict(list)

        for entry in entries:
            context = entry.get("context", "")
            emotion = entry.get("emotion", "")
            intensity = entry.get("intensity", 5)

            context_emotions[context].append((emotion, intensity))

        # Find context-specific patterns
        for context, emotions in context_emotions.items():
            if len(emotions) >= 5:
                negative_emotions = ["ìŠ¤íŠ¸ë ˆìŠ¤", "ë¶ˆì•ˆ", "ì¢Œì ˆ", "í™”ë‚¨", "ê¸´ì¥"]
                negative_count = sum(
                    1 for emotion, _ in emotions if emotion in negative_emotions
                )

                if negative_count / len(emotions) > 0.7:
                    patterns.append(
                        f"'{context}' ì»¨í…ìŠ¤íŠ¸ì—ì„œ ë¶€ì •ì  ê°ì •ì´ ë¹ˆë²ˆí•¨ ({negative_count}/{len(emotions)})"
                    )

        return patterns

    def _analyze_triggers(
        self, situations: List[str], entries: List[Dict[str, Any]]
    ) -> List[Tuple[str, int, float]]:
        """Analyze situation triggers"""
        # Simple keyword-based analysis
        keywords = defaultdict(list)

        for i, situation in enumerate(situations):
            # Extract keywords (simple approach)
            words = situation.split()
            for word in words:
                if len(word) > 1:  # Skip single characters
                    keywords[word].append(entries[i].get("intensity", 5))

        # Calculate trigger strength
        triggers = []
        for keyword, intensities in keywords.items():
            if len(intensities) >= 2:  # Need multiple occurrences
                count = len(intensities)
                avg_intensity = sum(intensities) / count
                triggers.append((keyword, count, avg_intensity))

        # Sort by combination of frequency and intensity
        triggers.sort(key=lambda x: x[1] * x[2], reverse=True)
        return triggers

    def _analyze_tag_triggers(
        self, entries: List[Dict[str, Any]]
    ) -> List[Tuple[str, int, float]]:
        """Analyze tag-based triggers"""
        tag_data = defaultdict(list)

        for entry in entries:
            tags = entry.get("tags", [])
            intensity = entry.get("intensity", 5)

            for tag in tags:
                tag_data[tag].append(intensity)

        triggers = []
        for tag, intensities in tag_data.items():
            if len(intensities) >= 2:
                count = len(intensities)
                avg_intensity = sum(intensities) / count
                triggers.append((tag, count, avg_intensity))

        triggers.sort(key=lambda x: x[1] * x[2], reverse=True)
        return triggers

    def _get_time_slot(self, hour: int) -> str:
        """Convert hour to time slot description"""
        if 6 <= hour < 12:
            return "ì˜¤ì „"
        elif 12 <= hour < 18:
            return "ì˜¤í›„"
        elif 18 <= hour < 22:
            return "ì €ë…"
        else:
            return "ë°¤"

    def _get_emotion_color(self, emotion: str) -> str:
        """Get color for emotion visualization"""
        positive_emotions = [
            "ê¸°ì¨",
            "ë§Œì¡±",
            "ìì‹ ê°",
            "ì•ˆë„",
            "ì„¤ë ˜",
            "í‰ì˜¨",
            "í–‰ë³µ",
            "ê°ì‚¬",
        ]
        negative_emotions = [
            "ìŠ¤íŠ¸ë ˆìŠ¤",
            "ë¶ˆì•ˆ",
            "ì¢Œì ˆ",
            "í™”ë‚¨",
            "ê¸´ì¥",
            "í”¼ë¡œ",
            "ê±±ì •",
            "ìŠ¬í””",
        ]

        if emotion in positive_emotions:
            return "green"
        elif emotion in negative_emotions:
            return "red"
        else:
            return "blue"
