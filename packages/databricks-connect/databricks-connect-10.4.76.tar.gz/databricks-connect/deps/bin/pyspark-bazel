#!/usr/bin/env bash

#
# DATABRICKS CONFIDENTIAL & PROPRIETARY
# __________________
#
# Copyright 2019 Databricks, Inc.
# All Rights Reserved.
#
# NOTICE:  All information contained herein is, and remains the property of Databricks, Inc.
# and its suppliers, if any.  The intellectual and technical concepts contained herein are
# proprietary to Databricks, Inc. and its suppliers and may be covered by U.S. and foreign Patents,
# patents in process, and are protected by trade secret and/or copyright law. Dissemination, use,
# or reproduction of this information is strictly forbidden unless prior written permission is
# obtained from Databricks, Inc.
#
# If you view or obtain a copy of this information and believe Databricks, Inc. may not have
# intended it to be made available, please promptly report it to Databricks Legal Department
# @ legal@databricks.com.
#

# Shell script for starting the PySpark Shell REPL using Bazel

set -euo pipefail

REPL_TARGET=//repl
HIVE_UNSHADED_TARGET=//sql/hive:hive-unshaded-hive-2.3__hadoop-3.2_2.12
# Uncomment as appropriate to run debug/release/asan
# For asan you also need to modify the env in conf/spark-env.sh. Instructions are in that file.
bazel build "${REPL_TARGET}" "${HIVE_UNSHADED_TARGET}" --config debug
# bazel build "${REPL_TARGET}" "${HIVE_UNSHADED_TARGET}" --config release
# bazel build "${REPL_TARGET}" "${HIVE_UNSHADED_TARGET}" --config asan
export BAZEL_SPARK_SUBMIT="$(cat bazel-bin/sql/hive/hive-unshaded-hive-2.3__hadoop-3.2_2.12.runtimeclasspath.txt | tr '\n' ':')"
export BAZEL_SPARK_SUBMIT="$BAZEL_SPARK_SUBMIT:$(cat bazel-bin/repl/repl-hive-2.3__hadoop-3.2_2.12.runtimeclasspath.txt | tr '\n' ':')"

GIT_ROOT="$(git rev-parse --show-toplevel)"

"$GIT_ROOT/bin/pyspark" "$@"
