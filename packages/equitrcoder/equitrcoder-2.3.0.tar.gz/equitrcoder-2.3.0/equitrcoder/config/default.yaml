llm:
  provider: litellm
  model: ""  # No default model - users must select one
  api_base: ""
  budget: 1.0
  temperature: 0.1
  max_tokens: 4000

sandbox:
  type: venv
  timeout: 30
  max_memory: 512  # MB
  allow_network: false

session:
  persist: true
  max_context: "auto"  # Automatically determined based on model capabilities
  session_dir: ~/.EQUITR-coder/sessions

repository:
  index_on_start: true
  ignore_patterns:
    - "*.pyc"
    - "__pycache__"
    - ".git"
    - "node_modules"
    - ".venv"
    - "venv"
    - "*.log"

orchestrator:
  max_iterations: 20
  error_retry_limit: 3
  error_retry_delay: 1.0
  supervisor_model: "o3"
  worker_model: "moonshot/kimi-k2-0711-preview"

# Consolidated limits configuration
limits:
  max_cost: 5.0
  max_workers: 3
  max_depth: 3
  devops_timeout: 600  # 10 minutes for DevOps operations
  context_max_tokens: 4000
  summary_max_tokens: 1000
  test_max_tokens: 1
  planning_max_tokens: 400
  requirements_max_tokens: 2000
  design_max_tokens: 2500
  todos_max_tokens: 2000

profiles:
  default: default
  available:
    - ml_researcher
    - app_developer
