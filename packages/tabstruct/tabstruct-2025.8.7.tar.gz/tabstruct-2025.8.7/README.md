# TabStruct: Measuring Structural Fidelity of Tabular Data

<div align="center">

<img src="docs/wiki/_media/repo_logo.png" height="150px">

[![Arxiv-Paper](https://img.shields.io/badge/Arxiv-Paper-olivegreen)](https://arxiv.org/abs/2503.09453)
[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![Downloads](https://static.pepy.tech/badge/tabstruct)](https://pypi.org/project/tabstruct/)

</div>

> [!IMPORTANT]
> Official code for the paper ["How Well Does Your Tabular Generator Learn the Structure of Tabular Data?"](https://arxiv.org/abs/2503.09453), published in Deep Generative Model in Machine Learning: Theory, Principle and Efficacy (ICLR 2025 Workshop).
>
> Authored by [Xiangjian Jiang](https://silencex12138.github.io/), [Nikola Simidjievski](https://simidjievskin.github.io/), [Mateja Jamnik](https://www.cl.cam.ac.uk/~mj201/), University of Cambridge, UK

## ðŸ“Œ Overview

![TabStruct banner](https://s2.loli.net/2025/05/16/TZ1clpvNBDhi8AE.png)

**TabStruct** is an endâ€‘toâ€‘end benchmark for **tabular data generation, prediction, and evaluation**. It ships with readyâ€‘toâ€‘use pipelines for

- generating highâ€‘quality synthetic tables,
- training predictive models, and
- analysing results with a rich suite of metrics â€“ especially those that quantify **structural fidelity**.

All components are designed to plugâ€‘andâ€‘play, so you can mix, match, and extend them to suit your own workflow.

## ðŸ“– Citation

For attribution in academic contexts, please cite this work as:

```
@inproceedings{jiang2025well,
  title={How Well Does Your Tabular Generator Learn the Structure of Tabular Data?},
  author={Jiang, Xiangjian and Simidjievski, Nikola and Jamnik, Mateja},
  booktitle={ICLR 2025 Workshop on Deep Generative Model in Machine Learning: Theory, Principle and Efficacy}
}
```

## ðŸ“š Key Features

### Data generation

- Outâ€‘ofâ€‘theâ€‘box support for popular tabular generators: **SMOTE, TVAE, CTGAN, NFlow, TabDDPM, ARF**, and more.

### Evaluation dimensions

- **Density estimation** â€“ How well does the synthetic data approximate the real distribution?
- **Privacy preservation** â€“ Does the generator leak sensitive records?
- **ML efficacy** â€“ How do models trained on synthetic data perform compared to real data?
- **Structural fidelity** â€“ Does the generator respect the causal structures of real data?

### Predictive tasks

- Classification & regression pipelines built on **scikitâ€‘learn**, with optional neuralâ€‘network backbones.

## ðŸš€ Installation

We recommend managing dependencies with **conda**â€¯+â€¯**mamba**.

```bash
# 1ï¸âƒ£ Upgrade conda and activate the base env
conda update -n base -c conda-forge conda
conda activate base

# 2ï¸âƒ£ Install the highâ€‘performance dependency resolver
conda install conda-libmamba-solver --yes
conda config --set solver libmamba
conda install -c conda-forge mamba --yes

# 3ï¸âƒ£ Create a new conda env
conda create --name tabstruct python=3.10.18 --no-default-packages
conda activate tabstruct

# 4ï¸âƒ£ Set up the env
bash scripts/utils/install.sh
```

> **Headsâ€‘up:** Search the codebase for absolute paths and replace them with paths on your machine.

## ðŸ“Š Logging with W\&B

TabStruct logs every experiment to **WeightsÂ &Â Biases** (W\&B). Use the default project or set your own credentials in `src/tabstruct/common/__init__.py`:

```python
WANDB_ENTITY  = "tabular-data-generation"
WANDB_PROJECT = "TabStruct"
```

## âœ… Quick sanity check

Run a toy classification job (Kâ€‘NN on the **Adult** dataset):

```bash
python -m src.tabstruct.experiment.run_experiment \
  --model knn \
  --save_model \
  --dataset adult \
  --test_size 0.2 \
  --valid_size 0.1 \
  --tags ENV-TEST
```

A successful run prints a series of **green** log lines like:

```text
[YYYYâ€‘MMâ€‘DD] Codebase: >>>>>>>>>> Launching create_data_module() <<<<<<<<<<<
â€¦
```

If you see those, congratulations â€“ your environment is ready! ðŸŽ‰

## ðŸ’¥ Example Workflows

### 1. Generate synthetic data

```bash
python -m src.tabstruct.experiment.run_experiment \
    --pipeline "generation" \
    --generation_only \
    --model "smote" \
    --dataset "mfeat-fourier" \
    --test_size 0.2 \
    --valid_size 0.1 \
    --tags "dev"
```

Template script: `docs/tutorial/example_scripts/generation/train.sh`.

### 2. Evaluate synthetic data

```bash
python -m src.tabstruct.experiment.run_experiment \
	--pipeline "generation" \
	--model "smote" \
	--eval_only \
	--dataset "mfeat-fourier" \
	--test_size 0.2 \
	--valid_size 0.1 \
	--generator_tags "dev" \
	--tags "dev"
```

Template script: `docs/tutorial/example_scripts/generation/eval.sh`.

### 3. Predict on tabular data

```shell
python -m src.tabstruct.experiment.run_experiment \
	--model 'mlp' \
	--save_model \
	--max_steps_tentative 1500 \
	--dataset 'adult' \
	--test_size 0.2 \
	--valid_size 0.1 \
	--tags 'dev'
```

Template script: `docs/tutorial/example_scripts/prediction/train.sh`

<!--  -->
