# syntax=docker/dockerfile:1
# Optimized GPU Dockerfile for Stockula
# Size reduced from 25.2GB to ~8-10GB through:
# - Using minimal CUDA base instead of full PyTorch image
# - Removing AutoGluon (saves ~8GB)
# - Using system Python instead of venv
# - Aggressive cleanup of caches and build artifacts
# - Single-stage build for efficiency

FROM nvidia/cuda:12.1.0-cudnn8-runtime-ubuntu22.04 AS runtime

# Build arguments
ARG PYTHON_VERSION=3.11
ARG PYTORCH_VERSION=2.5.1
ARG CUDA_VERSION=cu121

# Labels for image metadata
LABEL org.opencontainers.image.title="Stockula GPU" \
      org.opencontainers.image.description="GPU-accelerated trading platform (optimized)" \
      org.opencontainers.image.vendor="Stockula Project" \
      org.opencontainers.image.source="https://github.com/mkm29/stockula"

# Environment variables
ENV DEBIAN_FRONTEND=noninteractive \
    PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PIP_NO_CACHE_DIR=1 \
    PIP_DISABLE_PIP_VERSION_CHECK=1 \
    NVIDIA_VISIBLE_DEVICES=all \
    NVIDIA_DRIVER_CAPABILITIES=compute,utility \
    PATH="/usr/local/bin:$PATH" \
    PYTHONPATH="/app/src"

# Install Python and minimal runtime dependencies
# Ubuntu 22.04 needs deadsnakes PPA for Python 3.11
RUN apt-get update && apt-get install -y --no-install-recommends \
    software-properties-common \
    && add-apt-repository ppa:deadsnakes/ppa -y \
    && apt-get update \
    && apt-get install -y --no-install-recommends \
    python${PYTHON_VERSION} \
    python${PYTHON_VERSION}-distutils \
    python${PYTHON_VERSION}-dev \
    build-essential \
    libgomp1 \
    libopenblas-base \
    curl \
    && curl -sS https://bootstrap.pypa.io/get-pip.py | python${PYTHON_VERSION} \
    && ln -sf /usr/bin/python${PYTHON_VERSION} /usr/local/bin/python \
    && ln -sf /usr/bin/python${PYTHON_VERSION} /usr/local/bin/python3 \
    && apt-get remove -y software-properties-common \
    && apt-get autoremove -y \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/*

# Upgrade pip
RUN python -m pip install --no-cache-dir --upgrade pip setuptools wheel

# Copy requirements file
COPY requirements-gpu.txt /tmp/

# Install PyTorch with CUDA support first (~2GB)
RUN pip install --no-cache-dir \
    torch==${PYTORCH_VERSION} \
    --index-url https://download.pytorch.org/whl/${CUDA_VERSION} \
    && rm -rf ~/.cache/pip

# Install all dependencies from requirements file
# Note: torch is already installed, pip will skip it
# AutoGluon line will be skipped due to Python version constraint
RUN pip install --no-cache-dir \
    -r /tmp/requirements-gpu.txt \
    && rm -rf ~/.cache/pip /tmp/requirements-gpu.txt

# Clean up Python artifacts
RUN find /usr -type d -name __pycache__ -exec rm -rf {} + 2>/dev/null || true \
    && find /usr -type f \( -name '*.pyc' -o -name '*.pyo' \) -delete 2>/dev/null || true \
    && rm -rf /root/.cache /tmp/* /var/tmp/*

# Remove build-essential after compilation
RUN apt-get remove -y build-essential \
    && apt-get autoremove -y \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

# Create app structure and user
RUN useradd -m -u 1000 -s /bin/bash stockula \
    && mkdir -p /app/src /app/data /app/results /app/logs \
    && chown -R stockula:stockula /app

# Copy application code
COPY --chown=stockula:stockula src/stockula /app/src/stockula
COPY --chown=stockula:stockula pyproject.toml README.md /app/

# Install stockula without dependencies
WORKDIR /app
RUN pip install --no-cache-dir --no-deps -e . \
    && rm -rf ~/.cache/pip /tmp/* /var/tmp/*

# Switch to non-root user
USER stockula
WORKDIR /app

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD python -c "import torch; import stockula; torch.cuda.is_available(); print('healthy')" || exit 1

# Default command
ENTRYPOINT ["python", "-m"]
CMD ["stockula", "--help"]

# ============================================
# CLI Stage - adds minimal interactive tools
# ============================================
FROM runtime AS gpu-cli

USER root

# Add interactive tools
RUN apt-get update && apt-get install -y --no-install-recommends \
    less \
    nano \
    curl \
    htop \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/*

USER stockula
RUN mkdir -p /home/stockula/.local/bin && \
    ln -s /usr/local/bin/python /home/stockula/.local/bin/python3 && \
    echo 'export PATH="/home/stockula/.local/bin:$PATH"' >> /home/stockula/.bashrc

# Create GPU diagnostic script
RUN cat <<EOF > /home/stockula/.local/bin/gpu-check
#!/bin/bash
echo "=== GPU Information ==="
nvidia-smi 2>/dev/null || echo "nvidia-smi not available"
echo ""
echo "=== PyTorch CUDA ==="
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA Available: {torch.cuda.is_available()}')"
echo ""
echo "=== Stockula GPU Features ==="
python -c "import stockula; print('Stockula loaded successfully')"
EOF
RUN chmod +x /home/stockula/.local/bin/gpu-check


CMD ["/bin/bash"]
