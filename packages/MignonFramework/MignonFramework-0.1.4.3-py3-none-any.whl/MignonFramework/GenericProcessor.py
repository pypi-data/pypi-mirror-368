"""
ä¸€ä¸ªé«˜åº¦é€šç”¨çš„æ–‡ä»¶åˆ°æ•°æ®åº“ETLï¼ˆæå–ã€è½¬æ¢ã€åŠ è½½ï¼‰å·¥å…·ã€‚å®ƒé€šè¿‡ä¸€ä¸ªç»Ÿä¸€çš„ run() æ–¹æ³•ï¼Œ
å¯ä»¥æ™ºèƒ½å¤„ç†å•ä¸ªæ–‡ä»¶æˆ–æ•´ä¸ªç›®å½•ï¼Œæ”¯æŒâ€œæ•´æ–‡ä»¶JSONâ€å’Œâ€œé€è¡ŒJSONâ€ä¸¤ç§æ¨¡å¼ï¼Œå¹¶æä¾›äº†æ–­ç‚¹ç»­ä¼ ã€
å¯è§†åŒ–è¿›åº¦æ¡å’Œäº‹ä»¶å›è°ƒç­‰é«˜çº§åŠŸèƒ½ã€‚
"""
import json as std_json
import os
import ast
import sys
import io
import re
from abc import ABC, abstractmethod
from contextlib import redirect_stdout
from datetime import datetime
from typing import Dict, Callable, List, Optional, Any

from MignonFramework.MySQLManager import MysqlManager
from MignonFramework.CountLinesInFolder import count_lines_in_single_file
from MignonFramework.ConfigReader import ConfigManager
from MignonFramework.BaseWriter import BaseWriter


class Rename:
    """ä¸€ä¸ªè¾…åŠ©ç±»ï¼Œåœ¨modifier_functionä¸­ç”¨äºæ˜ç¡®è¡¨ç¤ºé‡å‘½åæ“ä½œã€‚"""

    def __init__(self, new_key_name: str):
        self.new_key_name = new_key_name


class GenericFileProcessor:
    """
    ä¸€ä¸ªé€šç”¨çš„ã€å¯å®šåˆ¶çš„JSONæ–‡ä»¶å¤„ç†å™¨ï¼Œç”¨äºå°†æ–‡ä»¶å†…å®¹æ‰¹é‡å†™å…¥æŒ‡å®šç›®æ ‡ã€‚
    æ”¯æŒé›¶é…ç½®å¯åŠ¨ï¼Œä¼šè‡ªåŠ¨å¼•å¯¼ç”¨æˆ·åˆ›å»ºé…ç½®æ–‡ä»¶ã€‚
    """

    def __init__(self,
                 writer: Optional[BaseWriter] = None,
                 table_name: Optional[str] = None,
                 mode: str = 'line',
                 modifier_function: Optional[Callable[[Dict], Dict]] = None,
                 filter_function: Optional[Callable[[Dict, int], bool]] = None,
                 exclude_keys: Optional[List[str]] = None,
                 default_values: Optional[Dict[str, Any]] = None,
                 batch_size: int = 1000,
                 callBack: Optional[Callable[[bool, List[Dict], str, Optional[int]], None]] = None,
                 print_mapping_table: bool = True,
                 on_error: str = 'stop'):
        """
        åˆå§‹åŒ–å¤„ç†å™¨ã€‚

        Args:
            writer (BaseWriter, optional): æ•°æ®å†™å…¥å™¨å®ä¾‹ã€‚å¦‚æœä¸ºNoneï¼Œå°†å°è¯•ä»é…ç½®æ–‡ä»¶åŠ è½½ã€‚
            table_name (str, optional): ç›®æ ‡è¡¨åã€‚å¦‚æœä¸ºNoneï¼Œå°†å°è¯•ä»é…ç½®æ–‡ä»¶åŠ è½½ã€‚
            mode (str): æ–‡ä»¶å¤„ç†æ¨¡å¼ã€‚å¯é€‰å€¼ä¸º 'line' (é»˜è®¤) æˆ– 'file'ã€‚
            modifier_function (Callable, optional): è‡ªå®šä¹‰ä¿®æ”¹å‡½æ•°ã€‚
            filter_function (Callable[[Dict, int], bool], optional): æ•°æ®è¿‡æ»¤å‡½æ•°ï¼Œæ¥æ”¶æ•°æ®å’Œè¡Œå·ï¼Œè¿”å›Falseåˆ™è·³è¿‡ã€‚
            exclude_keys (List[str], optional): éœ€è¦æ’é™¤çš„æºJSONé”®åˆ—è¡¨ã€‚
            default_values (Dict[str, Any], optional): ä¸ºç¼ºå¤±æˆ–ä¸ºNoneçš„é”®æä¾›é»˜è®¤å€¼ã€‚
            batch_size (int): æ¯æ‰¹æäº¤çš„è®°å½•æ•°ã€‚
            callBack (Callable, optional): æ‰¹å¤„ç†å®Œæˆåçš„å›è°ƒå‡½æ•°ã€‚
            print_mapping_table (bool): æ˜¯å¦åœ¨è¿è¡Œå‰æ‰“å°å­—æ®µæ˜ å°„å¯¹ç…§è¡¨ã€‚
            on_error (str): é”™è¯¯å¤„ç†ç­–ç•¥ ('continue', 'stop', 'log_to_file')ã€‚
        """
        self.is_ready = True
        self.config_manager = ConfigManager(filename='./resources/config/generic.ini', section='GenericProcessor')
        self.path_from_config = None
        self.test = False  # åˆå§‹åŒ–testå±æ€§

        # ä¼˜å…ˆä½¿ç”¨ä»£ç ä¸­ä¼ å…¥çš„ writer å’Œ table_name
        self.writer = writer
        self.table_name = table_name

        # å¦‚æœä»£ç ä¸­æœªæä¾›ï¼Œåˆ™å°è¯•ä»é…ç½®æ–‡ä»¶åŠ è½½
        if self.writer is None or self.table_name is None:
            self._init_from_config()

        if not self.is_ready:
            return

        if not isinstance(self.writer, BaseWriter):
            raise TypeError("writer å¿…é¡»æ˜¯ BaseWriter çš„ä¸€ä¸ªå®ä¾‹ã€‚")
        if mode not in ['file', 'line']:
            raise ValueError("mode å‚æ•°å¿…é¡»æ˜¯ 'file' æˆ– 'line'ã€‚")

        self.modifier_function = modifier_function
        self.filter_function = filter_function
        self.exclude_keys = set(exclude_keys) if exclude_keys else set()
        self.default_values = default_values if default_values else {}
        self.mode = mode
        self.batch_size = batch_size
        self.callBack = callBack
        self.print_mapping_table = print_mapping_table
        self.on_error = on_error

    def _init_from_config(self):
        """ä»é…ç½®æ–‡ä»¶åˆå§‹åŒ–å¤„ç†å™¨ã€‚å¦‚æœé…ç½®ä¸å®Œæ•´ï¼Œåˆ™å¼•å¯¼ç”¨æˆ·åˆ›å»ºã€‚"""
        config_data = self.config_manager.get_all_fields()

        # ä»…åœ¨ä»£ç æœªæä¾› writer æ—¶æ‰å°è¯•ä»é…ç½®åˆ›å»º
        if self.writer is None:
            db_keys = ['host', 'user', 'password', 'database']
            if config_data and all(config_data.get(k) and 'YOUR_' not in str(config_data.get(k)) for k in db_keys):
                db_config = {k: config_data[k] for k in db_keys}
                self.writer = MysqlManager(**db_config)
                if not self.writer.is_connected():
                    print(f"[ERROR] ä½¿ç”¨ generic.ini ä¸­çš„é…ç½®è¿æ¥æ•°æ®åº“å¤±è´¥ã€‚")
                    self.is_ready = False
                    return
            else:
                self._guide_user_to_config()
                return

        # ä»…åœ¨ä»£ç æœªæä¾› table_name æ—¶æ‰å°è¯•ä»é…ç½®è·å–
        if self.table_name is None:
            if config_data and config_data.get('table_name') and 'YOUR_' not in str(config_data.get('table_name')):
                self.table_name = config_data['table_name']
            else:
                self._guide_user_to_config()
                return

        # å°è¯•è·å–è·¯å¾„ä½œä¸ºå¤‡ç”¨
        if config_data and config_data.get('path') and 'YOUR_' not in str(config_data.get('path')):
            self.path_from_config = config_data['path']

    def _guide_user_to_config(self):
        """å¼•å¯¼ç”¨æˆ·å¡«å†™é…ç½®æ–‡ä»¶ã€‚"""
        print("\n" + "=" * 60)
        print("ğŸš€ æ¬¢è¿ä½¿ç”¨ GenericFileProcessor é›¶é…ç½®å‘å¯¼ï¼")
        print("å¤„ç†å™¨æ£€æµ‹åˆ°é…ç½®ä¸å®Œæ•´ï¼Œå°†ä¸ºæ‚¨åˆ›å»ºæˆ–æ›´æ–°é…ç½®æ–‡ä»¶ã€‚")
        print(f"é…ç½®æ–‡ä»¶è·¯å¾„: {os.path.abspath('./resources/config/generic.ini')}")
        print("è¯·åœ¨è¯¥æ–‡ä»¶ä¸­å¡«å†™æ‚¨çš„æ•°æ®åº“ä¿¡æ¯å’Œè¦å¤„ç†çš„æ–‡ä»¶è·¯å¾„ã€‚")
        print("=" * 60 + "\n")

        placeholders = {
            'host': 'YOUR_DATABASE_HOST', 'user': 'YOUR_USERNAME', 'password': 'YOUR_PASSWORD',
            'database': 'YOUR_DATABASE_NAME', 'table_name': 'YOUR_TARGET_TABLE',
            'path': 'PATH_TO_YOUR_FILE_OR_DIRECTORY'
        }
        for key, value in placeholders.items():
            if not self.config_manager.get_field(key) or 'YOUR_' in str(self.config_manager.get_field(key)):
                self.config_manager.update_field(key, value)

        self.is_ready = False

    def _to_snake_case(self, name: str) -> str:
        if not isinstance(name, str) or not name:
            return ""
        s1 = re.sub(r'(.)([A-Z][a-z]+)', r'\1_\2', name)
        return re.sub(r'([a-z0-9])([A-Z])', r'\1_\2', s1).lower()

    def _safe_json_load(self, text: str) -> Optional[Dict]:
        try:
            return std_json.loads(text)
        except std_json.JSONDecodeError:
            try:
                return ast.literal_eval(text)
            except (ValueError, SyntaxError, MemoryError, TypeError):
                return None

    def _finalize_types(self, data_dict: dict) -> dict:
        final_data = {}
        for key, value in data_dict.items():
            if value is None:
                final_data[key] = ''
            elif isinstance(value, (dict, list)):
                final_data[key] = std_json.dumps(value, ensure_ascii=False)
            else:
                final_data[key] = value
        return final_data

    def _process_single_item(self, json_data: dict, temp_exclude_keys=None, temp_default_values=None) -> Optional[Dict]:
        # åˆå¹¶åˆå§‹é…ç½®å’Œä¸´æ—¶é…ç½®
        current_excludes = self.exclude_keys.union(temp_exclude_keys or set())
        current_defaults = {**self.default_values, **(temp_default_values or {})}

        data_with_defaults = {}
        all_original_keys = set(json_data.keys()) | set(current_defaults.keys())
        for key in all_original_keys:
            value = json_data.get(key)
            if (value is None or value == '') and key in current_defaults:
                data_with_defaults[key] = current_defaults[key]
            else:
                data_with_defaults[key] = value

        parsed_data = {}
        for original_key, final_value in data_with_defaults.items():
            if original_key in current_excludes:
                continue
            new_key = self._to_snake_case(original_key)
            parsed_data[new_key] = final_value

        if self.modifier_function:
            patch_dict = self.modifier_function(data_with_defaults)
            for original_key, instruction in patch_dict.items():
                auto_key = self._to_snake_case(original_key)
                if isinstance(instruction, Rename):
                    if auto_key in parsed_data:
                        parsed_data[instruction.new_key_name] = parsed_data.pop(auto_key)
                elif isinstance(instruction, tuple) and len(instruction) == 2:
                    if auto_key in parsed_data:
                        del parsed_data[auto_key]
                    parsed_data[instruction[0]] = instruction[1]
                else:
                    parsed_data[auto_key] = instruction

        return self._finalize_types(parsed_data)

    def _execute_batch(self, json_list: List[Dict], filename: str, line_num: Optional[int] = None):
        if not json_list:
            return
        f = io.StringIO()
        status = False
        with redirect_stdout(f):
            status = self.writer.upsert_batch(json_list, self.table_name, test=self.test)
        captured_output = f.getvalue().strip()
        if self.callBack:
            try:
                self.callBack(status, json_list, filename, line_num)
            except Exception as cb_e:
                print(f"\n[ERROR] å›è°ƒå‡½æ•°æ‰§è¡Œå¤±è´¥: {cb_e}")
        if not status:
            raise Exception(f"æ•°æ®å†™å…¥å¤±è´¥ã€‚è¯¦ç»†ä¿¡æ¯: {captured_output}")

    def _generate_and_print_mapping(self, sample_json: Dict[str, Any]):
        print("\n" + "=" * 102)
        print("--- å­—æ®µæ˜ å°„å¯¹ç…§è¡¨ (Field Mapping Table) ---")
        col_widths = (30, 30, 30)
        header = "| {:{w1}} | {:{w2}} | {:{w3}} |".format(
            "æºå­—æ®µ", "ç›®æ ‡å­—æ®µ", "ç¤ºä¾‹å€¼/é»˜è®¤å€¼", w1=col_widths[0], w2=col_widths[1], w3=col_widths[2]
        )
        print(header)
        print("-" * (sum(col_widths) + 7))

        sample_with_defaults = {}
        all_sample_keys = set(sample_json.keys()) | set(self.default_values.keys())
        for key in all_sample_keys:
            value = sample_json.get(key)
            if (value is None or value == '') and key in self.default_values:
                sample_with_defaults[key] = self.default_values[key]
            else:
                sample_with_defaults[key] = value

        patch = self.modifier_function(sample_with_defaults) if self.modifier_function else {}
        all_keys = sorted(list(set(sample_with_defaults.keys()) | set(patch.keys())))

        for key in all_keys:
            if key in self.exclude_keys:
                mapped_key, value_str = "SKIPPED", "N/A"
            else:
                instruction = patch.get(key)
                if isinstance(instruction, Rename):
                    mapped_key = instruction.new_key_name
                elif isinstance(instruction, tuple):
                    mapped_key = instruction[0]
                else:
                    mapped_key = self._to_snake_case(key)

                if instruction is not None:
                    if isinstance(instruction, tuple):
                        value_str = f"(mod) {instruction[1]}"
                    elif not isinstance(instruction, Rename):
                        value_str = f"(mod) {instruction}"
                    else:
                        value_str = str(sample_with_defaults.get(key, 'N/A'))
                elif key in sample_with_defaults and sample_with_defaults[key] is not None:
                    value_str = str(sample_with_defaults[key])
                else:
                    value_str = "N/A"

            value_str = (value_str[:25] + '...') if len(value_str) > 25 else value_str

            padding = [w - self._get_display_width(s) for w, s in zip(col_widths, [key, mapped_key, value_str])]
            print(f"| {key}{' ' * padding[0]} | {mapped_key}{' ' * padding[1]} | {value_str}{' ' * padding[2]} |")

        print("=" * 102 + "\n")

    def _get_display_width(self, s: str) -> int:
        return sum(2 if '\u4e00' <= char <= '\u9fff' else 1 for char in s)

    def _find_original_key(self, snake_key: str, sample_json: dict) -> Optional[str]:
        """æ ¹æ®snake_caseé”®åæŸ¥åŸå§‹é”®ã€‚"""
        for key in sample_json.keys():
            if self._to_snake_case(key) == snake_key:
                return key
        return None

    def _run_test_mode(self, file_path: str):
        """æ‰§è¡Œæµ‹è¯•æ¨¡å¼ï¼Œè‡ªåŠ¨è¯Šæ–­å¹¶å»ºè®®ä¿®å¤æ–¹æ¡ˆã€‚"""
        print("\n--- å¯åŠ¨æµ‹è¯•æ¨¡å¼ ---")
        print(f"å°†ä½¿ç”¨æ–‡ä»¶ '{os.path.basename(file_path)}' çš„ç¬¬ä¸€æ‰¹æ•°æ®è¿›è¡Œæµ‹è¯•...")

        raw_json_batch = []
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                for line in f:
                    if len(raw_json_batch) >= self.batch_size:
                        break
                    if line.strip():
                        if json_data := self._safe_json_load(line):
                            raw_json_batch.append(json_data)
        except Exception as e:
            print(f"[ERROR] è¯»å–æµ‹è¯•æ–‡ä»¶æ—¶å¤±è´¥: {e}")
            return

        if not raw_json_batch:
            print("[ERROR] æœªèƒ½åœ¨æ–‡ä»¶ä¸­æ‰¾åˆ°æœ‰æ•ˆçš„JSONæ•°æ®è¿›è¡Œæµ‹è¯•ã€‚")
            return

        suggested_excludes = set()
        suggested_defaults = {}
        error_counts = {}
        MAX_ATTEMPTS = 5

        for attempt in range(1, MAX_ATTEMPTS + 1):
            print(f"\n--- ç¬¬ {attempt} æ¬¡å°è¯• ---")
            try:
                processed_batch = [self._process_single_item(item, suggested_excludes, suggested_defaults) for item in
                                   raw_json_batch]
                processed_batch = [item for item in processed_batch if item is not None]

                self._execute_batch(processed_batch, os.path.basename(file_path))

                print("  [æˆåŠŸ] å½“å‰é…ç½®æœ‰æ•ˆï¼Œæµ‹è¯•é€šè¿‡ï¼")
                break
            except Exception as e:
                error_code = e.args[0] if isinstance(e.args, tuple) and len(e.args) > 0 else 0
                error_message = str(e)

                if error_code == 1054:
                    match = re.search(r"Unknown column '(.+?)'", error_message)
                    if match:
                        col = match.group(1)
                        original_key = self._find_original_key(col, raw_json_batch[0])
                        if original_key:
                            print(f"  [è¯Šæ–­] å‘ç°æœªçŸ¥åˆ— '{col}'ï¼Œå¯¹åº”æºå­—æ®µ '{original_key}'ã€‚")
                            suggested_excludes.add(original_key)
                            print(f"  [æ“ä½œ] å°† '{original_key}' åŠ å…¥å»ºè®®æ’é™¤åˆ—è¡¨ã€‚")
                            continue

                if error_code == 1292:
                    match = re.search(r"Incorrect date value: '.+?' for column '(.+?)'", error_message)
                    if match:
                        col = match.group(1)
                        original_key = self._find_original_key(col, raw_json_batch[0])
                        if original_key:
                            error_counts[original_key] = error_counts.get(original_key, 0) + 1
                            if error_counts[original_key] > 3:
                                print(f"  [å¤±è´¥] å­—æ®µ '{original_key}' è‡ªåŠ¨ä¿®å¤è¶…è¿‡3æ¬¡ï¼Œæµ‹è¯•ä¸­æ­¢ã€‚")
                                break
                            print(f"  [è¯Šæ–­] å‘ç°æ— æ•ˆæ—¥æœŸå€¼ï¼Œåˆ— '{col}'ï¼Œå¯¹åº”æºå­—æ®µ '{original_key}'ã€‚")
                            suggested_defaults[original_key] = datetime.now()
                            print(f"  [æ“ä½œ] ä¸º '{original_key}' åŠ å…¥å»ºè®®çš„é»˜è®¤æ—¥æœŸã€‚")
                            continue

                print(f"  [å¤±è´¥] é‡åˆ°æ— æ³•è‡ªåŠ¨å¤„ç†çš„é”™è¯¯ï¼Œæµ‹è¯•ä¸­æ­¢: {e}")
                break

        print("\n" + "=" * 60)
        print("--- æµ‹è¯•æ¨¡å¼æ€»ç»“ä¸é…ç½®å»ºè®® ---")
        if suggested_excludes:
            print("\nå»ºè®®çš„ `exclude_keys` åˆ—è¡¨:")
            print(f"exclude_keys = {list(suggested_excludes)}")
        else:
            print("\næœªå‘ç°éœ€è¦æ’é™¤çš„å­—æ®µã€‚")

        if suggested_defaults:
            print("\nå»ºè®®çš„ `default_values` å­—å…¸ (æ—¥æœŸå°†æ˜¯è¿è¡Œæ—¶çš„æ—¶é—´):")
            defaults_str = {k: str(v) for k, v in suggested_defaults.items()}
            print(f"default_values = {defaults_str}")
        else:
            print("\næœªå‘ç°éœ€è¦è®¾ç½®é»˜è®¤å€¼çš„æ—¥æœŸå­—æ®µã€‚")
        print("=" * 60 + "\n")

    def run(self, path: Optional[str] = None, start_line: int = 1, test: bool = False):
        if not self.is_ready:
            print("[INFO] å¤„ç†å™¨å°šæœªå°±ç»ªï¼Œè¯·æ ¹æ®æç¤ºå®Œæˆé…ç½®åå†æ¬¡è¿è¡Œã€‚")
            return

        self.test = test  # å°† test çŠ¶æ€ä¿å­˜åˆ°å®ä¾‹

        target_path = path if path is not None else self.path_from_config
        if not target_path or not os.path.exists(target_path):
            if path is None and self.path_from_config is None:
                self._guide_user_to_config()
            else:
                print(f"[ERROR] ç›®æ ‡è·¯å¾„æ— æ•ˆæˆ–ä¸å­˜åœ¨: {target_path}")
            return

        files_to_process = [os.path.join(target_path, f) for f in os.listdir(target_path) if
                            os.path.isfile(os.path.join(target_path, f)) and f.lower().endswith(
                                ('.json', '.txt'))] if os.path.isdir(target_path) else [target_path]

        if not files_to_process:
            print(f"åœ¨è·¯å¾„ '{target_path}' ä¸­æœªæ‰¾åˆ°å¯å¤„ç†çš„æ–‡ä»¶ã€‚")
            return

        if test:
            self._run_test_mode(files_to_process[0])
            return

        if self.print_mapping_table:
            try:
                composite_sample = {}
                lines_scanned = 0
                with open(files_to_process[0], 'r', encoding='utf-8') as f:
                    for line in f:
                        if lines_scanned >= 1000:
                            break
                        if line.strip():
                            if sample_data := self._safe_json_load(line):
                                composite_sample.update(sample_data)
                                lines_scanned += 1
                if composite_sample:
                    self._generate_and_print_mapping(composite_sample)
                else:
                    print("[WARNING] æœªèƒ½åœ¨æ–‡ä»¶å‰1000è¡Œæ‰¾åˆ°æœ‰æ•ˆçš„JSONæ•°æ®æ¥ç”Ÿæˆå¯¹ç…§è¡¨ã€‚")
            except Exception as e:
                print(f"[WARNING] æ— æ³•ç”Ÿæˆå¯¹ç…§è¡¨: {e}")

        print(f"\n--- å¼€å§‹å¤„ç†è·¯å¾„: {target_path} (æ¨¡å¼: {self.mode}) ---")
        print(f"å‘ç° {len(files_to_process)} ä¸ªæ–‡ä»¶å¾…å¤„ç†...")

        for i, file_path in enumerate(files_to_process):
            filename, line_num = os.path.basename(file_path), 0
            print(f"\n[{i + 1}/{len(files_to_process)}] æ­£åœ¨å¤„ç†: {filename}")

            try:
                if self.mode == 'file':
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    if content.strip():
                        if json_data := self._safe_json_load(content):
                            if not self.filter_function or self.filter_function(json_data, 1):
                                if parsed_dic := self._process_single_item(json_data):
                                    self._execute_batch([parsed_dic], filename)
                        else:
                            print(f"\n[WARNING] æ— æ³•è§£ææ–‡ä»¶å†…å®¹: {filename}")

                elif self.mode == 'line':
                    if start_line > 1:
                        print(f"  [INFO] ä»ç¬¬ {start_line} è¡Œå¼€å§‹å¤„ç†...")
                    total_lines = count_lines_in_single_file(file_path) or 0
                    json_list = []
                    with open(file_path, 'r', encoding='utf-8') as f:
                        for line_num, line in enumerate(f, 1):
                            if line_num < start_line or not line.strip():
                                continue

                            try:
                                json_data = self._safe_json_load(line)
                                if not json_data:
                                    raise ValueError("è§£æå¤±è´¥")
                                if self.filter_function and not self.filter_function(json_data, line_num):
                                    continue
                                if parsed_dic := self._process_single_item(json_data):
                                    json_list.append(parsed_dic)

                                if total_lines > 0:
                                    bar = 'â–ˆ' * int(40 * line_num / total_lines) + '-' * (
                                            40 - int(40 * line_num / total_lines))
                                    sys.stdout.write(
                                        f'\r|{bar}| {line_num / total_lines:.1%} ({line_num}/{total_lines})  æœ¬æ‰¹: [{len(json_list)}/{self.batch_size}]')
                                    sys.stdout.flush()

                                if len(json_list) >= self.batch_size:
                                    self._execute_batch(json_list, filename, line_num)
                                    json_list = []
                            except Exception as parse_e:
                                error_msg = f"\n[WARNING] å¤„ç†æ–‡ä»¶ {filename} ç¬¬ {line_num} è¡Œæ—¶å‘ç”Ÿé”™è¯¯: {parse_e}"
                                if self.on_error == 'stop':
                                    raise
                                if self.on_error == 'log_to_file':
                                    with open('error.log', 'a', encoding='utf-8') as err_f:
                                        err_f.write(
                                            f"{datetime.now()} | {filename} | Line {line_num} | {parse_e}\n{line}\n")
                                print(error_msg)
                                print(f"  [FAILING LINE]: {line.strip()}")
                    print()
                    self._execute_batch(json_list, filename, line_num)
                print(f"  [æˆåŠŸ] æ–‡ä»¶å·²å¤„ç†ã€‚")
            except Exception as e:
                print(f"\n  [å¤±è´¥] å¤„ç†æ–‡ä»¶ {filename} æ—¶å‘ç”Ÿè‡´å‘½é”™è¯¯: {e}ã€‚")
                continue
        print("\n--- æ‰€æœ‰ä»»åŠ¡å¤„ç†å®Œæˆ ---")
