"""
L2 FirstLastSimilarityReranker - é¦–å°¾å­—ç›¸ä¼¼åº¦é‡æ’å™¨
åŸºæ–¼é¦–å°¾å­—éŸ»æ¯ç›¸ä¼¼åº¦çš„é‡æ’ç®—æ³•ï¼Œå°‡2.5è¬å€™é¸è©ç¸®æ¸›åˆ°500å€‹é«˜è³ªé‡å€™é¸
"""

import time
import logging
from typing import List, Dict, Set, Optional, Tuple, Union
from pathlib import Path

from core.phonetic_classifier import PhoneticClassifier, PhoneticFeatures
from analyzers.finals_analyzer import FinalsAnalyzer, FinalsFeatures
from data.super_dictionary_manager import SuperDictionaryManager


class FirstLastSimilarityReranker:
    """
    L2é¦–å°¾å­—ç›¸ä¼¼åº¦é‡æ’å™¨
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. åŸºæ–¼é¦–å°¾å­—éŸ»æ¯ç›¸ä¼¼åº¦é‡æ–°æ’åºå€™é¸è©
    2. åˆ©ç”¨å€’åºå­—å…¸å»ºç«‹å°¾å­—å¿«é€Ÿç´¢å¼•
    3. æ”¯æ´ç•°é•·åº¦è©å½™è™•ç†èˆ‡é•·åº¦æ‡²ç½°
    4. åœ¨50mså…§è™•ç†2.5è¬å€™é¸è©ï¼Œè¼¸å‡º500å€‹ç²¾é¸å€™é¸
    5. ç‚ºL3å±¤æä¾›é«˜è³ªé‡çš„å€™é¸è©é›†åˆ
    """
    
    def __init__(self, 
                 dict_manager: SuperDictionaryManager,
                 phonetic_classifier: PhoneticClassifier,
                 finals_analyzer: FinalsAnalyzer):
        """
        åˆå§‹åŒ–L2é‡æ’å™¨
        
        Args:
            dict_manager: å­—å…¸ç®¡ç†å™¨
            phonetic_classifier: èªéŸ³åˆ†é¡å™¨
            finals_analyzer: éŸ»æ¯åˆ†æå™¨
        """
        self.logger = logging.getLogger(__name__)
        self.dict_manager = dict_manager
        self.classifier = phonetic_classifier
        self.finals_analyzer = finals_analyzer
        
        # é‡æ’çµ±è¨ˆ
        self.rerank_stats = {
            "total_queries": 0,
            "total_candidates_input": 0,
            "total_candidates_output": 0,
            "total_time_ms": 0.0,
            "cache_hits": 0
        }
        
        # çµæœç·©å­˜
        self.result_cache: Dict[str, List[Tuple[str, float]]] = {}
        self.cache_enabled = True
        
        self.logger.info("FirstLastSimilarityReranker initialized")
    
    def rerank(self, query: str, 
               candidates: List[str], 
               top_k: int = 500) -> List[str]:
        """
        åŸ·è¡ŒL2é¦–å°¾å­—ç›¸ä¼¼åº¦é‡æ’
        
        Args:
            query: æŸ¥è©¢è©å½™
            candidates: L1ç¯©é¸å¾Œçš„å€™é¸è©åˆ—è¡¨
            top_k: è¿”å›çš„top-kçµæœæ•¸é‡
            
        Returns:
            é‡æ’å¾Œçš„å€™é¸è©åˆ—è¡¨ (æŒ‰ç›¸ä¼¼åº¦é™åº)
        """
        start_time = time.time()
        
        if not query or not candidates:
            return []
        
        # æª¢æŸ¥ç·©å­˜
        cache_key = f"{query}_{len(candidates)}_{top_k}"
        if self.cache_enabled and cache_key in self.result_cache:
            self.rerank_stats["cache_hits"] += 1
            cached_results = self.result_cache[cache_key]
            return [word for word, _ in cached_results]
        
        # è¨ˆç®—æ‰€æœ‰å€™é¸è©çš„ç›¸ä¼¼åº¦
        scored_candidates = []
        
        for candidate in candidates:
            if candidate == query:
                # å®Œå…¨åŒ¹é…çµ¦äºˆæœ€é«˜åˆ†æ•¸
                scored_candidates.append((candidate, 1.0))
            else:
                similarity = self.calculate_first_last_similarity(query, candidate)
                if similarity > 0.0:  # åªä¿ç•™æœ‰ç›¸ä¼¼åº¦çš„å€™é¸
                    scored_candidates.append((candidate, similarity))
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åºï¼Œå–top-k
        scored_candidates.sort(key=lambda x: x[1], reverse=True)
        top_candidates = scored_candidates[:top_k]
        
        # æ›´æ–°çµ±è¨ˆä¿¡æ¯
        end_time = time.time()
        processing_time = (end_time - start_time) * 1000
        
        self.rerank_stats["total_queries"] += 1
        self.rerank_stats["total_candidates_input"] += len(candidates)
        self.rerank_stats["total_candidates_output"] += len(top_candidates)
        self.rerank_stats["total_time_ms"] += processing_time
        
        # ç·©å­˜çµæœ
        if self.cache_enabled:
            self.result_cache[cache_key] = top_candidates
        
        # è¿”å›è©å½™åˆ—è¡¨
        result_words = [word for word, _ in top_candidates]
        
        self.logger.debug(f"L2 Rerank: {query} â†’ {len(candidates)} to {len(result_words)} "
                         f"({processing_time:.1f}ms)")
        
        return result_words
    
    def calculate_first_last_similarity(self, word1: str, word2: str) -> float:
        """
        è¨ˆç®—é¦–å°¾å­—éŸ»æ¯ç›¸ä¼¼åº¦ - æ”¯æ´ç•°é•·åº¦è©å½™
        
        Args:
            word1, word2: å¾…æ¯”è¼ƒçš„è©å½™
            
        Returns:
            ç›¸ä¼¼åº¦åˆ†æ•¸ (0.0-1.0)
        """
        if not word1 or not word2:
            return 0.0
        
        if word1 == word2:
            return 1.0
        
        # æå–é¦–å°¾å­—ç‰¹å¾µ
        word1_first = word1[0]
        word1_last = word1[-1] if len(word1) > 1 else word1[0]
        
        word2_first = word2[0]
        word2_last = word2[-1] if len(word2) > 1 else word2[0]
        
        # è¨ˆç®—é¦–å­—ç›¸ä¼¼åº¦
        first_similarity = self._calculate_character_similarity(word1_first, word2_first)
        
        # è¨ˆç®—å°¾å­—ç›¸ä¼¼åº¦ (è€ƒæ…®å–®å­—è©æƒ…æ³)
        if len(word1) == 1 and len(word2) == 1:
            # å…©å€‹éƒ½æ˜¯å–®å­—è©ï¼Œå°¾å­—ç›¸ä¼¼åº¦ç­‰æ–¼é¦–å­—ç›¸ä¼¼åº¦
            last_similarity = first_similarity
        elif len(word1) == 1 or len(word2) == 1:
            # ä¸€å€‹å–®å­—ä¸€å€‹å¤šå­—ï¼Œçµ¦äºˆä¸­ç­‰ç›¸ä¼¼åº¦
            last_similarity = 0.5
        else:
            # éƒ½æ˜¯å¤šå­—è©ï¼Œè¨ˆç®—å¯¦éš›å°¾å­—ç›¸ä¼¼åº¦
            last_similarity = self._calculate_character_similarity(word1_last, word2_last)
        
        # åŠ æ¬Šçµ„åˆ (é¦–å­—æ¬Šé‡æ›´é«˜ï¼Œå› ç‚ºå°èªéŸ³è­˜åˆ¥æ›´é‡è¦)
        weighted_similarity = first_similarity * 0.7 + last_similarity * 0.3
        
        # é•·åº¦æ‡²ç½°
        length_penalty = self.calculate_length_penalty(word1, word2)
        
        # æœ€çµ‚ç›¸ä¼¼åº¦
        final_similarity = weighted_similarity * length_penalty
        
        return min(final_similarity, 1.0)
    
    def _calculate_character_similarity(self, char1: str, char2: str) -> float:
        """
        è¨ˆç®—å–®å­—çš„èªéŸ³ç›¸ä¼¼åº¦
        
        Args:
            char1, char2: å¾…æ¯”è¼ƒçš„å­—ç¬¦
            
        Returns:
            ç›¸ä¼¼åº¦åˆ†æ•¸ (0.0-1.0)
        """
        if char1 == char2:
            return 1.0
        
        # æå–èªéŸ³ç‰¹å¾µ
        features1 = self.classifier.extract_phonetic_features(char1)
        features2 = self.classifier.extract_phonetic_features(char2)
        
        # è²æ¯ç›¸ä¼¼åº¦ (40%æ¬Šé‡)
        consonant_sim = self.classifier.calculate_consonant_similarity(
            features1.consonant or "", 
            features2.consonant or ""
        )
        
        # éŸ»æ¯ç›¸ä¼¼åº¦ (60%æ¬Šé‡ï¼Œæ›´é‡è¦)
        finals1 = self.finals_analyzer.extract_finals_features(char1)
        finals2 = self.finals_analyzer.extract_finals_features(char2)
        
        finals_sim = self.finals_analyzer.calculate_finals_similarity(
            finals1.finals, 
            finals2.finals
        )
        
        # åŠ æ¬Šçµ„åˆ
        total_similarity = consonant_sim * 0.4 + finals_sim * 0.6
        
        return total_similarity
    
    def calculate_length_penalty(self, word1: str, word2: str) -> float:
        """
        è¨ˆç®—é•·åº¦å·®ç•°æ‡²ç½°ä¿‚æ•¸
        
        Args:
            word1, word2: å¾…æ¯”è¼ƒçš„è©å½™
            
        Returns:
            æ‡²ç½°ä¿‚æ•¸ (0.7-1.0)
        """
        len_diff = abs(len(word1) - len(word2))
        
        if len_diff == 0:
            return 1.0      # ç„¡æ‡²ç½°
        elif len_diff == 1:
            return 0.95     # è¼•å¾®æ‡²ç½°
        elif len_diff == 2:
            return 0.85     # ä¸­åº¦æ‡²ç½°
        elif len_diff == 3:
            return 0.75     # è¼ƒé‡æ‡²ç½°
        else:
            return 0.7      # é‡åº¦æ‡²ç½° (ä½†ä¸å®Œå…¨æ’é™¤)
    
    def batch_rerank(self, queries: List[str], 
                    candidates_lists: List[List[str]], 
                    top_k: int = 500) -> Dict[str, List[str]]:
        """
        æ‰¹é‡åŸ·è¡ŒL2é‡æ’
        
        Args:
            queries: æŸ¥è©¢è©å½™åˆ—è¡¨
            candidates_lists: å°æ‡‰çš„å€™é¸è©åˆ—è¡¨
            top_k: æ¯å€‹æŸ¥è©¢è¿”å›çš„top-kæ•¸é‡
            
        Returns:
            æŸ¥è©¢è©åˆ°é‡æ’çµæœçš„æ˜ å°„
        """
        results = {}
        
        for query, candidates in zip(queries, candidates_lists):
            results[query] = self.rerank(query, candidates, top_k)
        
        return results
    
    def get_rerank_statistics(self) -> Dict[str, any]:
        """ç²å–é‡æ’å™¨æ€§èƒ½çµ±è¨ˆ"""
        stats = self.rerank_stats.copy()
        
        if stats["total_queries"] > 0:
            stats["avg_input_candidates"] = stats["total_candidates_input"] / stats["total_queries"]
            stats["avg_output_candidates"] = stats["total_candidates_output"] / stats["total_queries"]
            stats["avg_processing_time_ms"] = stats["total_time_ms"] / stats["total_queries"]
            stats["avg_reduction_ratio"] = (stats["total_candidates_output"] / 
                                          max(stats["total_candidates_input"], 1))
            stats["cache_hit_rate"] = stats["cache_hits"] / stats["total_queries"]
        
        stats["cache_size"] = len(self.result_cache)
        stats["cache_enabled"] = self.cache_enabled
        
        return stats
    
    def clear_cache(self):
        """æ¸…é™¤é‡æ’çµæœç·©å­˜"""
        self.result_cache.clear()
        self.logger.info("L2 reranker cache cleared")
    
    def benchmark_performance(self, 
                            test_cases: List[Tuple[str, List[str]]] = None,
                            iterations: int = 10) -> Dict[str, float]:
        """
        æ€§èƒ½åŸºæº–æ¸¬è©¦
        
        Args:
            test_cases: [(æŸ¥è©¢è©, å€™é¸è©åˆ—è¡¨)] çš„æ¸¬è©¦æ¡ˆä¾‹
            iterations: æ¸¬è©¦è¿­ä»£æ¬¡æ•¸
            
        Returns:
            æ€§èƒ½æ¸¬è©¦çµæœ
        """
        if test_cases is None:
            # ç”Ÿæˆæ¸¬è©¦æ•¸æ“š
            test_cases = [
                ("çŸ¥é“", ["çŸ¥é“", "è³‡é“", "æŒ‡å°", "åˆ¶å°", "æ™ºæ…§"] * 100),  # 500å€‹å€™é¸
                ("åƒé£¯", ["åƒé£¯", "æ¬¡é£¯", "åƒå®Œ", "æ¬¡å®Œ", "é£¯èœ"] * 100),
                ("å®‰å…¨", ["å®‰å…¨", "æ˜‚å…¨", "æŒ‰å…¨", "æš—å…¨", "æ¡ˆå…¨"] * 100),
            ]
        
        self.clear_cache()  # æ¸…é™¤ç·©å­˜ç¢ºä¿çœŸå¯¦æ€§èƒ½
        
        start_time = time.time()
        total_candidates_processed = 0
        total_output_candidates = 0
        
        for _ in range(iterations):
            for query, candidates in test_cases:
                result = self.rerank(query, candidates, top_k=500)
                total_candidates_processed += len(candidates)
                total_output_candidates += len(result)
        
        end_time = time.time()
        total_time = end_time - start_time
        total_operations = iterations * len(test_cases)
        
        return {
            "total_time_seconds": total_time,
            "total_operations": total_operations,
            "operations_per_second": total_operations / total_time,
            "avg_time_per_query_ms": (total_time * 1000) / total_operations,
            "total_candidates_processed": total_candidates_processed,
            "avg_input_candidates": total_candidates_processed / total_operations,
            "avg_output_candidates": total_output_candidates / total_operations,
            "avg_reduction_ratio": total_output_candidates / total_candidates_processed
        }
    
    def analyze_similarity_distribution(self, 
                                      query: str, 
                                      candidates: List[str]) -> Dict[str, any]:
        """
        åˆ†æç›¸ä¼¼åº¦åˆ†ä½ˆæƒ…æ³
        
        Args:
            query: æŸ¥è©¢è©
            candidates: å€™é¸è©åˆ—è¡¨
            
        Returns:
            ç›¸ä¼¼åº¦åˆ†ä½ˆçµ±è¨ˆ
        """
        similarities = []
        length_distribution = {}
        
        for candidate in candidates:
            sim = self.calculate_first_last_similarity(query, candidate)
            similarities.append(sim)
            
            len_diff = abs(len(query) - len(candidate))
            length_distribution[len_diff] = length_distribution.get(len_diff, 0) + 1
        
        if not similarities:
            return {"error": "No candidates provided"}
        
        similarities.sort(reverse=True)
        
        return {
            "total_candidates": len(candidates),
            "similarity_stats": {
                "max": max(similarities),
                "min": min(similarities),
                "avg": sum(similarities) / len(similarities),
                "median": similarities[len(similarities) // 2],
                "top_10_avg": sum(similarities[:10]) / min(10, len(similarities))
            },
            "length_distribution": length_distribution,
            "high_similarity_count": sum(1 for s in similarities if s > 0.8),
            "medium_similarity_count": sum(1 for s in similarities if 0.5 < s <= 0.8),
            "low_similarity_count": sum(1 for s in similarities if 0.0 < s <= 0.5)
        }


def test_l2_reranker():
    """æ¸¬è©¦FirstLastSimilarityRerankeråŠŸèƒ½"""
    print("ğŸ§ª æ¸¬è©¦FirstLastSimilarityRerankeråŠŸèƒ½")
    print("=" * 50)
    
    try:
        # åˆå§‹åŒ–ä¾è³´çµ„ä»¶
        dict_manager = SuperDictionaryManager(
            super_dict_path="data/super_dicts/super_dict_combined.json",
            super_dict_reversed_path="data/super_dicts/super_dict_reversed.json"
        )
        
        classifier = PhoneticClassifier()
        finals_analyzer = FinalsAnalyzer()
        reranker = FirstLastSimilarityReranker(dict_manager, classifier, finals_analyzer)
        
        # æ¸¬è©¦æ¡ˆä¾‹
        test_cases = [
            ("çŸ¥é“", ["çŸ¥é“", "è³‡é“", "æŒ‡å°", "åˆ¶å°", "æ™ºæ…§", "åƒé£¯", "ç¡è¦º", "å·¥ä½œ"]),
            ("åƒé£¯", ["åƒé£¯", "æ¬¡é£¯", "åƒå®Œ", "æ¬¡å®Œ", "é£¯èœ", "çŸ¥é“", "ç¡è¦º", "å·¥ä½œ"]),
            ("å®‰å…¨", ["å®‰å…¨", "æ˜‚å…¨", "æŒ‰å…¨", "æš—å…¨", "æ¡ˆå…¨", "çŸ¥é“", "åƒé£¯", "ç¡è¦º"]),
        ]
        
        print("ğŸ“Š L2é‡æ’æ¸¬è©¦:")
        print("-" * 40)
        
        for query, candidates in test_cases:
            print(f"\næŸ¥è©¢: '{query}'")
            print(f"åŸå§‹å€™é¸: {candidates}")
            
            # é‡æ’
            start_time = time.time()
            reranked = reranker.rerank(query, candidates, top_k=5)
            processing_time = (time.time() - start_time) * 1000
            
            print(f"é‡æ’çµæœ: {reranked}")
            print(f"è™•ç†æ™‚é–“: {processing_time:.1f}ms")
            
            # ç›¸ä¼¼åº¦åˆ†æ
            analysis = reranker.analyze_similarity_distribution(query, candidates)
            print(f"ç›¸ä¼¼åº¦çµ±è¨ˆ: æœ€é«˜={analysis['similarity_stats']['max']:.3f}, "
                  f"å¹³å‡={analysis['similarity_stats']['avg']:.3f}")
        
        # æ‰¹é‡æ¸¬è©¦
        print("\nğŸ“Š æ‰¹é‡é‡æ’æ¸¬è©¦:")
        print("-" * 40)
        
        queries = [case[0] for case in test_cases]
        candidates_lists = [case[1] for case in test_cases]
        
        batch_results = reranker.batch_rerank(queries, candidates_lists, top_k=3)
        for query, results in batch_results.items():
            print(f"  {query}: {results}")
        
        # æ€§èƒ½åŸºæº–æ¸¬è©¦
        print("\nğŸ“Š æ€§èƒ½åŸºæº–æ¸¬è©¦:")
        print("-" * 40)
        
        # æ¨¡æ“¬L1ç¯©é¸å¾Œçš„è¦æ¨¡ (2.5è¬å€™é¸)
        large_candidates = ["æ¸¬è©¦è©å½™"] * 2500  # ç°¡åŒ–æ¸¬è©¦
        large_test_cases = [
            ("çŸ¥é“", large_candidates),
            ("åƒé£¯", large_candidates),
        ]
        
        benchmark = reranker.benchmark_performance(large_test_cases, iterations=2)
        print(f"  ç¸½æ“ä½œæ•¸: {benchmark['total_operations']}")
        print(f"  æ¯ç§’æ“ä½œæ•¸: {benchmark['operations_per_second']:.1f}")
        print(f"  å¹³å‡è™•ç†æ™‚é–“: {benchmark['avg_time_per_query_ms']:.2f}ms")
        print(f"  å¹³å‡å€™é¸è©æ•¸: {benchmark['avg_input_candidates']:.0f}")
        print(f"  è¼¸å‡ºæ¸›å°‘æ¯”ä¾‹: {benchmark['avg_reduction_ratio']:.1%}")
        
        # çµ±è¨ˆä¿¡æ¯
        print("\nğŸ“Š é‡æ’å™¨çµ±è¨ˆ:")
        print("-" * 40)
        
        stats = reranker.get_rerank_statistics()
        print(f"  ç¸½æŸ¥è©¢æ•¸: {stats['total_queries']}")
        print(f"  å¹³å‡è¼¸å…¥å€™é¸æ•¸: {stats.get('avg_input_candidates', 0):.0f}")
        print(f"  å¹³å‡è¼¸å‡ºå€™é¸æ•¸: {stats.get('avg_output_candidates', 0):.0f}")
        print(f"  å¹³å‡è™•ç†æ™‚é–“: {stats.get('avg_processing_time_ms', 0):.2f}ms")
        print(f"  ç·©å­˜å‘½ä¸­ç‡: {stats.get('cache_hit_rate', 0):.1%}")
        
        # é©—æ”¶æ¨™æº–æª¢æŸ¥
        print("\nğŸ“Š L2é‡æ’å™¨é©—æ”¶æ¨™æº–æª¢æŸ¥:")
        print("-" * 40)
        
        avg_time = stats.get('avg_processing_time_ms', 0)
        print(f"  âœ“ å¹³å‡è™•ç†æ™‚é–“: {avg_time:.1f}ms "
              f"{'< 50ms' if avg_time < 50 else '>= 50ms âŒ'}")
        
        reduction_ratio = stats.get('avg_reduction_ratio', 0)
        print(f"  âœ“ å€™é¸è©ç¸®æ¸›: {1-reduction_ratio:.1%} "
              f"({'é©ä¸­' if 0.7 < reduction_ratio < 0.9 else 'éœ€èª¿æ•´ âŒ'})")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    # è¨­ç½®æ—¥èªŒ
    logging.basicConfig(level=logging.INFO)
    
    # åŸ·è¡Œæ¸¬è©¦
    success = test_l2_reranker()
    print(f"\næ¸¬è©¦ {'âœ… PASSED' if success else 'âŒ FAILED'}")