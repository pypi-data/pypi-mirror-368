"""
L1 FirstConsonantFilter - é¦–å­—è²æ¯å¿«é€Ÿç¯©é¸å™¨
åŸºæ–¼è²æ¯åˆ†çµ„çš„O(1)+O(k)å¿«é€Ÿç¯©é¸ï¼Œå°‡17è¬è©å…¸ç¸®æ¸›åˆ°2.5è¬å€™é¸
"""

import time
import logging
from typing import List, Dict, Set, Optional, Tuple
from pathlib import Path

from core.phonetic_classifier import PhoneticClassifier, PhoneticFeatures
from data.super_dictionary_manager import SuperDictionaryManager


class FirstConsonantFilter:
    """
    L1é¦–å­—è²æ¯å¿«é€Ÿç¯©é¸å™¨
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. åŸºæ–¼è²æ¯åˆ†çµ„å¿«é€Ÿæ’é™¤90%ä¸ç›¸é—œå€™é¸è©
    2. åˆ©ç”¨SuperDictionaryManagerçš„é¦–å­—ç´¢å¼•å¯¦ç¾O(1)æŸ¥è©¢
    3. æ”¯æ´å¹³ç¿¹èˆŒä¸åˆ†ã€é‚Šé¼»éŸ³ä¸åˆ†ç­‰å°ç£åœ‹èªè®Šç•°
    4. åœ¨100mså…§è™•ç†17è¬è©å…¸ï¼Œç¸®æ¸›åˆ°0.8-2.5è¬å€™é¸
    """
    
    def __init__(self, 
                 super_dict_manager: SuperDictionaryManager,
                 phonetic_classifier: PhoneticClassifier):
        """
        åˆå§‹åŒ–L1ç¯©é¸å™¨
        
        Args:
            super_dict_manager: 17è¬è©å…¸ç®¡ç†å™¨
            phonetic_classifier: èªéŸ³åˆ†é¡å™¨
        """
        self.logger = logging.getLogger(__name__)
        self.dict_manager = super_dict_manager
        self.classifier = phonetic_classifier
        
        # æ€§èƒ½çµ±è¨ˆ
        self.filter_stats = {
            "total_queries": 0,
            "total_candidates_input": 0,
            "total_candidates_output": 0,
            "total_time_ms": 0.0,
            "cache_hits": 0
        }
        
        # çµæœç·©å­˜ï¼ˆé‡å°ç›¸åŒæŸ¥è©¢ï¼‰
        self.result_cache: Dict[str, List[str]] = {}
        self.cache_enabled = True
        
        self.logger.info("FirstConsonantFilter initialized")
    
    def filter(self, query: str, 
               use_full_dict: bool = True,
               enable_cache: bool = True) -> List[str]:
        """
        åŸ·è¡ŒL1è²æ¯ç¯©é¸
        
        Args:
            query: æŸ¥è©¢è©å½™
            use_full_dict: æ˜¯å¦ä½¿ç”¨å®Œæ•´17è¬è©å…¸
            enable_cache: æ˜¯å¦å•Ÿç”¨çµæœç·©å­˜
            
        Returns:
            ç¯©é¸å¾Œçš„å€™é¸è©åˆ—è¡¨
        """
        start_time = time.time()
        
        # æª¢æŸ¥ç·©å­˜
        if enable_cache and self.cache_enabled:
            cache_key = f"{query}_{use_full_dict}"
            if cache_key in self.result_cache:
                self.filter_stats["cache_hits"] += 1
                return self.result_cache[cache_key].copy()
        
        # æå–æŸ¥è©¢è©é¦–å­—çš„èªéŸ³ç‰¹å¾µ
        if not query or len(query) == 0:
            return []
        
        query_first_char = query[0]
        query_features = self.classifier.extract_phonetic_features(query_first_char)
        query_consonant_group = query_features.consonant_group
        
        # ç²å–å€™é¸è©é›†åˆ
        if use_full_dict:
            # ä½¿ç”¨å®Œæ•´17è¬è©å…¸
            candidates = self.dict_manager.get_all_words()
        else:
            # ä½¿ç”¨é¦–å­—ç´¢å¼•é ç¯©é¸ï¼ˆæ›´æ¿€é€²çš„å„ªåŒ–ï¼‰
            candidates = self.dict_manager.get_words_by_first_char(query_first_char)
        
        # åŸ·è¡Œè²æ¯åˆ†çµ„ç¯©é¸
        filtered_candidates = []
        
        for candidate in candidates:
            if not candidate or len(candidate) == 0:
                continue
            
            # æå–å€™é¸è©é¦–å­—ç‰¹å¾µ
            candidate_first_char = candidate[0]
            candidate_features = self.classifier.extract_phonetic_features(candidate_first_char)
            candidate_consonant_group = candidate_features.consonant_group
            
            # åˆ¤æ–·æ˜¯å¦é€šéç¯©é¸
            if self._should_pass_filter(query_features, candidate_features):
                filtered_candidates.append(candidate)
        
        # æ›´æ–°çµ±è¨ˆä¿¡æ¯
        end_time = time.time()
        processing_time = (end_time - start_time) * 1000  # è½‰æ›ç‚ºæ¯«ç§’
        
        self.filter_stats["total_queries"] += 1
        self.filter_stats["total_candidates_input"] += len(candidates)
        self.filter_stats["total_candidates_output"] += len(filtered_candidates)
        self.filter_stats["total_time_ms"] += processing_time
        
        # ç·©å­˜çµæœ
        if enable_cache and self.cache_enabled:
            cache_key = f"{query}_{use_full_dict}"
            self.result_cache[cache_key] = filtered_candidates.copy()
        
        self.logger.debug(f"L1 Filter: {query} â†’ {len(candidates)} to {len(filtered_candidates)} "
                         f"({processing_time:.1f}ms)")
        
        return filtered_candidates
    
    def _should_pass_filter(self, query_features: PhoneticFeatures, 
                           candidate_features: PhoneticFeatures) -> bool:
        """
        åˆ¤æ–·å€™é¸è©æ˜¯å¦æ‡‰è©²é€šéL1ç¯©é¸
        
        Args:
            query_features: æŸ¥è©¢è©èªéŸ³ç‰¹å¾µ
            candidate_features: å€™é¸è©èªéŸ³ç‰¹å¾µ
            
        Returns:
            æ˜¯å¦é€šéç¯©é¸
        """
        # 1. å®Œå…¨åŒ¹é…
        if query_features.consonant == candidate_features.consonant:
            return True
        
        # 2. åŒè²æ¯åˆ†çµ„
        if (query_features.consonant_group == candidate_features.consonant_group and 
            query_features.consonant_group != "æœªçŸ¥åˆ†çµ„"):
            return True
        
        # 3. ç‰¹æ®Šè®Šç•°è™•ç†ï¼šå¹³ç¿¹èˆŒä¸åˆ†
        if self._is_flat_retroflex_variant(query_features, candidate_features):
            return True
        
        # 4. ç‰¹æ®Šè®Šç•°è™•ç†ï¼šé‚Šé¼»éŸ³ä¸åˆ†ï¼ˆæŸäº›æ–¹è¨€ï¼‰
        if self._is_lateral_nasal_variant(query_features, candidate_features):
            return True
        
        return False
    
    def _is_flat_retroflex_variant(self, features1: PhoneticFeatures, 
                                  features2: PhoneticFeatures) -> bool:
        """æª¢æŸ¥æ˜¯å¦ç‚ºå¹³ç¿¹èˆŒä¸åˆ†è®Šç•°"""
        group1 = features1.consonant_group
        group2 = features2.consonant_group
        
        return ((group1 == "èˆŒå°–å‰éŸ³" and group2 == "èˆŒå°–å¾ŒéŸ³") or
                (group1 == "èˆŒå°–å¾ŒéŸ³" and group2 == "èˆŒå°–å‰éŸ³"))
    
    def _is_lateral_nasal_variant(self, features1: PhoneticFeatures,
                                 features2: PhoneticFeatures) -> bool:
        """æª¢æŸ¥æ˜¯å¦ç‚ºé‚Šé¼»éŸ³ä¸åˆ†è®Šç•°"""
        # ç°¡åŒ–å¯¦ç¾ï¼šã„‹(n) å’Œ ã„Œ(l) éƒ½å±¬æ–¼èˆŒå°–ä¸­éŸ³
        # åœ¨æŸäº›æ–¹è¨€ä¸­ä¸åˆ†
        consonant1 = features1.consonant
        consonant2 = features2.consonant
        
        return ((consonant1 == "ã„‹" and consonant2 == "ã„Œ") or
                (consonant1 == "ã„Œ" and consonant2 == "ã„‹"))
    
    def batch_filter(self, queries: List[str], 
                    use_full_dict: bool = True) -> Dict[str, List[str]]:
        """
        æ‰¹é‡åŸ·è¡ŒL1ç¯©é¸
        
        Args:
            queries: æŸ¥è©¢è©å½™åˆ—è¡¨
            use_full_dict: æ˜¯å¦ä½¿ç”¨å®Œæ•´è©å…¸
            
        Returns:
            æŸ¥è©¢è©åˆ°å€™é¸è©åˆ—è¡¨çš„æ˜ å°„
        """
        results = {}
        
        for query in queries:
            results[query] = self.filter(query, use_full_dict)
        
        return results
    
    def get_filter_statistics(self) -> Dict[str, any]:
        """ç²å–ç¯©é¸å™¨æ€§èƒ½çµ±è¨ˆ"""
        stats = self.filter_stats.copy()
        
        if stats["total_queries"] > 0:
            stats["avg_input_candidates"] = stats["total_candidates_input"] / stats["total_queries"]
            stats["avg_output_candidates"] = stats["total_candidates_output"] / stats["total_queries"]
            stats["avg_processing_time_ms"] = stats["total_time_ms"] / stats["total_queries"]
            stats["avg_filter_ratio"] = (stats["total_candidates_output"] / 
                                       max(stats["total_candidates_input"], 1))
            stats["cache_hit_rate"] = stats["cache_hits"] / stats["total_queries"]
        
        stats["cache_size"] = len(self.result_cache)
        stats["cache_enabled"] = self.cache_enabled
        
        return stats
    
    def clear_cache(self):
        """æ¸…é™¤çµæœç·©å­˜"""
        self.result_cache.clear()
        self.logger.info("L1 filter cache cleared")
    
    def benchmark_performance(self, 
                            test_queries: List[str] = None,
                            iterations: int = 100) -> Dict[str, float]:
        """
        æ€§èƒ½åŸºæº–æ¸¬è©¦
        
        Args:
            test_queries: æ¸¬è©¦æŸ¥è©¢åˆ—è¡¨
            iterations: æ¸¬è©¦è¿­ä»£æ¬¡æ•¸
            
        Returns:
            æ€§èƒ½æ¸¬è©¦çµæœ
        """
        if test_queries is None:
            test_queries = ["çŸ¥é“", "è³‡é“", "åƒé£¯", "å®‰å…¨", "é€™æ¨£"]
        
        self.clear_cache()  # æ¸…é™¤ç·©å­˜ç¢ºä¿çœŸå¯¦æ€§èƒ½
        
        start_time = time.time()
        total_candidates_processed = 0
        
        for _ in range(iterations):
            for query in test_queries:
                result = self.filter(query, use_full_dict=True, enable_cache=False)
                total_candidates_processed += len(result)
        
        end_time = time.time()
        total_time = end_time - start_time
        total_operations = iterations * len(test_queries)
        
        return {
            "total_time_seconds": total_time,
            "total_operations": total_operations,
            "operations_per_second": total_operations / total_time,
            "avg_time_per_query_ms": (total_time * 1000) / total_operations,
            "total_candidates_processed": total_candidates_processed,
            "avg_candidates_per_query": total_candidates_processed / total_operations
        }


def test_l1_consonant_filter():
    """æ¸¬è©¦FirstConsonantFilteråŠŸèƒ½"""
    print("ğŸ§ª æ¸¬è©¦FirstConsonantFilteråŠŸèƒ½")
    print("=" * 50)
    
    try:
        # åˆå§‹åŒ–ä¾è³´çµ„ä»¶
        dict_manager = SuperDictionaryManager(
            super_dict_path="data/super_dicts/super_dict_combined.json",
            super_dict_reversed_path="data/super_dicts/super_dict_reversed.json"
        )
        
        classifier = PhoneticClassifier()
        filter_l1 = FirstConsonantFilter(dict_manager, classifier)
        
        # æ¸¬è©¦æ¡ˆä¾‹
        test_cases = [
            "çŸ¥é“",   # å¹³ç¿¹èˆŒæ¸¬è©¦
            "åƒé£¯",   # å¹³ç¿¹èˆŒæ¸¬è©¦
            "å®‰å…¨",   # å‰å¾Œé¼»éŸ³æ¸¬è©¦
            "ä¾†äº†",   # é‚Šé¼»éŸ³æ¸¬è©¦
            "é›»è…¦"    # ä¸€èˆ¬æ¸¬è©¦
        ]
        
        print("ğŸ“Š å–®å€‹æŸ¥è©¢ç¯©é¸æ¸¬è©¦:")
        print("-" * 40)
        
        for query in test_cases:
            start_time = time.time()
            filtered = filter_l1.filter(query, use_full_dict=True)
            processing_time = (time.time() - start_time) * 1000
            
            print(f"æŸ¥è©¢: '{query}'")
            print(f"  ç¯©é¸çµæœ: {len(filtered)} å€‹å€™é¸")
            print(f"  è™•ç†æ™‚é–“: {processing_time:.1f}ms")
            print(f"  å‰10å€‹: {filtered[:10]}")
            print()
        
        # æ‰¹é‡æ¸¬è©¦
        print("ğŸ“Š æ‰¹é‡ç¯©é¸æ¸¬è©¦:")
        print("-" * 40)
        
        batch_results = filter_l1.batch_filter(test_cases[:3])
        for query, candidates in batch_results.items():
            print(f"  {query}: {len(candidates)} å€‹å€™é¸")
        
        # æ€§èƒ½åŸºæº–æ¸¬è©¦
        print("ğŸ“Š æ€§èƒ½åŸºæº–æ¸¬è©¦:")
        print("-" * 40)
        
        benchmark = filter_l1.benchmark_performance(test_cases[:3], iterations=10)
        print(f"  ç¸½æ“ä½œæ•¸: {benchmark['total_operations']}")
        print(f"  æ¯ç§’æ“ä½œæ•¸: {benchmark['operations_per_second']:.1f}")
        print(f"  å¹³å‡æŸ¥è©¢æ™‚é–“: {benchmark['avg_time_per_query_ms']:.2f}ms")
        print(f"  å¹³å‡å€™é¸è©æ•¸: {benchmark['avg_candidates_per_query']:.0f}")
        
        # çµ±è¨ˆä¿¡æ¯
        print("ğŸ“Š ç¯©é¸å™¨çµ±è¨ˆä¿¡æ¯:")
        print("-" * 40)
        
        stats = filter_l1.get_filter_statistics()
        print(f"  ç¸½æŸ¥è©¢æ•¸: {stats['total_queries']}")
        print(f"  å¹³å‡è¼¸å…¥å€™é¸æ•¸: {stats.get('avg_input_candidates', 0):.0f}")
        print(f"  å¹³å‡è¼¸å‡ºå€™é¸æ•¸: {stats.get('avg_output_candidates', 0):.0f}")
        print(f"  å¹³å‡ç¯©é¸æ¯”ä¾‹: {stats.get('avg_filter_ratio', 0):.1%}")
        print(f"  ç·©å­˜å‘½ä¸­ç‡: {stats.get('cache_hit_rate', 0):.1%}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        return False


if __name__ == "__main__":
    # è¨­ç½®æ—¥èªŒ
    logging.basicConfig(level=logging.INFO)
    
    # åŸ·è¡Œæ¸¬è©¦
    success = test_l1_consonant_filter()
    print(f"\næ¸¬è©¦ {'âœ… PASSED' if success else 'âŒ FAILED'}")