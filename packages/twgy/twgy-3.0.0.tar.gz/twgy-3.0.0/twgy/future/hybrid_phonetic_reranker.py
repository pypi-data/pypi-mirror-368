"""
ç¬¬äºŒæœŸæ··åˆæ¶æ§‹è¨­è¨ˆ - è¦å‰‡åŸºç¤ + æ©Ÿå™¨å­¸ç¿’æ¨¡å‹çµ„åˆ
åŸºæ–¼ç¬¬ä¸€æœŸæ”¶é›†çš„è¨“ç·´æ•¸æ“šè¨­è¨ˆä¸‹ä¸€ä»£èªéŸ³é‡æ’ç³»çµ±
"""

import time
import logging
import json
from typing import List, Dict, Optional, Union, Any, Tuple
from pathlib import Path
from dataclasses import dataclass
from abc import ABC, abstractmethod

# ç¬¬ä¸€æœŸç³»çµ±å°å…¥
from phonetic_reranker import PhoneticReranker, RerankerConfig, RerankerResult
from data.training_data_logger import TrainingDataLogger


@dataclass
class MLModelConfig:
    """æ©Ÿå™¨å­¸ç¿’æ¨¡å‹é…ç½®"""
    model_type: str = "transformer"  # transformer, lstm, cnn
    model_path: str = "models/phonetic_similarity.pt"
    max_sequence_length: int = 10
    hidden_size: int = 256
    num_attention_heads: int = 8
    num_layers: int = 4
    
    # è¨“ç·´é…ç½®
    batch_size: int = 32
    learning_rate: float = 0.001
    num_epochs: int = 100
    validation_split: float = 0.2


@dataclass  
class HybridConfig:
    """æ··åˆç³»çµ±é…ç½®"""
    # ç¬¬ä¸€æœŸè¦å‰‡ç³»çµ±é…ç½®
    rule_based_config: RerankerConfig = None
    
    # æ©Ÿå™¨å­¸ç¿’æ¨¡å‹é…ç½®
    ml_model_config: MLModelConfig = None
    
    # æ··åˆç­–ç•¥é…ç½®
    fusion_strategy: str = "weighted_ensemble"  # weighted_ensemble, cascaded, adaptive
    rule_weight: float = 0.6  # è¦å‰‡ç³»çµ±æ¬Šé‡
    ml_weight: float = 0.4    # MLæ¨¡å‹æ¬Šé‡
    
    # é©æ‡‰æ€§é…ç½®
    enable_adaptive_weighting: bool = True
    confidence_threshold: float = 0.8
    fallback_to_rules: bool = True


class BaseMLModel(ABC):
    """æ©Ÿå™¨å­¸ç¿’æ¨¡å‹åŸºç¤é¡"""
    
    @abstractmethod
    def predict(self, query: str, candidates: List[str]) -> List[Tuple[str, float]]:
        """é æ¸¬å€™é¸è©ç›¸ä¼¼åº¦åˆ†æ•¸"""
        pass
    
    @abstractmethod
    def train(self, training_data: List[Dict[str, Any]]) -> Dict[str, float]:
        """è¨“ç·´æ¨¡å‹"""
        pass
    
    @abstractmethod
    def save_model(self, path: str) -> bool:
        """ä¿å­˜æ¨¡å‹"""
        pass
    
    @abstractmethod
    def load_model(self, path: str) -> bool:
        """è¼‰å…¥æ¨¡å‹"""
        pass


class TransformerPhoneticModel(BaseMLModel):
    """
    åŸºæ–¼Transformerçš„èªéŸ³ç›¸ä¼¼åº¦æ¨¡å‹
    
    ç‰¹é»ï¼š
    1. æ³¨æ„åŠ›æ©Ÿåˆ¶æ•æ‰è²éŸ»èª¿é•·è·é›¢ä¾è³´
    2. å­—ç¬¦ç´šåˆ¥çš„èªéŸ³ç‰¹å¾µç·¨ç¢¼
    3. æ”¯æ´è®Šé•·åºåˆ—è™•ç†
    4. é è¨“ç·´ + å¾®èª¿æ¶æ§‹
    """
    
    def __init__(self, config: MLModelConfig):
        self.config = config
        self.logger = logging.getLogger(__name__)
        
        # æ¨¡å‹çµ„ä»¶åˆå§‹åŒ– (å¯¦éš›éœ€è¦ä½¿ç”¨æ·±åº¦å­¸ç¿’æ¡†æ¶å¦‚PyTorch)
        self.tokenizer = None  # å­—ç¬¦ç´šåˆ¥åˆ†è©å™¨
        self.feature_encoder = None  # èªéŸ³ç‰¹å¾µç·¨ç¢¼å™¨
        self.transformer = None  # Transformeræ ¸å¿ƒ
        self.similarity_head = None  # ç›¸ä¼¼åº¦é æ¸¬é ­
        
        self.logger.info(f"TransformerPhoneticModel initialized with {config.model_type}")
    
    def predict(self, query: str, candidates: List[str]) -> List[Tuple[str, float]]:
        """
        ä½¿ç”¨Transformeré æ¸¬ç›¸ä¼¼åº¦åˆ†æ•¸
        
        Args:
            query: æŸ¥è©¢è©
            candidates: å€™é¸è©åˆ—è¡¨
            
        Returns:
            (å€™é¸è©, ç›¸ä¼¼åº¦åˆ†æ•¸) åˆ—è¡¨
        """
        if not self.transformer:
            # æ¨¡å‹æœªè¼‰å…¥ï¼Œè¿”å›åŸºæº–åˆ†æ•¸
            return [(candidate, 0.5) for candidate in candidates]
        
        # å¯¦éš›å¯¦ç¾éœ€è¦ï¼š
        # 1. å­—ç¬¦ç´šåˆ¥tokenization
        # 2. èªéŸ³ç‰¹å¾µç·¨ç¢¼ (è²éŸ»èª¿å‘é‡åŒ–)
        # 3. Transformer encoderè™•ç†
        # 4. ç›¸ä¼¼åº¦è¨ˆç®—
        
        # æ¨¡æ“¬å¯¦ç¾
        results = []
        for candidate in candidates:
            # ç°¡åŒ–çš„ç›¸ä¼¼åº¦è¨ˆç®—é‚è¼¯
            if query == candidate:
                similarity = 1.0
            elif len(query) == len(candidate):
                similarity = 0.8  # åŒé•·åº¦è©çµ¦äºˆè¼ƒé«˜åˆ†æ•¸
            else:
                similarity = 0.6
            
            results.append((candidate, similarity))
        
        return results
    
    def train(self, training_data: List[Dict[str, Any]]) -> Dict[str, float]:
        """
        è¨“ç·´Transformeræ¨¡å‹
        
        Args:
            training_data: ç¬¬ä¸€æœŸç³»çµ±æ”¶é›†çš„è¨“ç·´æ•¸æ“š
            
        Returns:
            è¨“ç·´æŒ‡æ¨™å­—å…¸
        """
        self.logger.info(f"Training transformer model on {len(training_data)} samples")
        
        # å¯¦éš›è¨“ç·´æµç¨‹ï¼š
        # 1. æ•¸æ“šé è™•ç†å’Œç‰¹å¾µæå–
        # 2. å»ºæ§‹è¨“ç·´/é©—è­‰æ•¸æ“šé›†
        # 3. æ¨¡å‹è¨“ç·´å¾ªç’°
        # 4. é©—è­‰å’Œæ—©åœ
        # 5. æ¨¡å‹ä¿å­˜
        
        # æ¨¡æ“¬è¨“ç·´æŒ‡æ¨™
        metrics = {
            "train_loss": 0.15,
            "val_loss": 0.18,
            "accuracy": 0.92,
            "f1_score": 0.89,
            "training_time_hours": 2.5
        }
        
        return metrics
    
    def save_model(self, path: str) -> bool:
        """ä¿å­˜è¨“ç·´å¥½çš„æ¨¡å‹"""
        try:
            # å¯¦éš›ä¿å­˜é‚è¼¯
            self.logger.info(f"Model saved to {path}")
            return True
        except Exception as e:
            self.logger.error(f"Failed to save model: {e}")
            return False
    
    def load_model(self, path: str) -> bool:
        """è¼‰å…¥é è¨“ç·´æ¨¡å‹"""
        try:
            # å¯¦éš›è¼‰å…¥é‚è¼¯
            self.logger.info(f"Model loaded from {path}")
            return True
        except Exception as e:
            self.logger.error(f"Failed to load model: {e}")
            return False


class HybridPhoneticReranker:
    """
    æ··åˆèªéŸ³é‡æ’ç³»çµ± - ç¬¬äºŒæœŸæ¶æ§‹
    
    æ•´åˆå„ªå‹¢ï¼š
    1. è¦å‰‡ç³»çµ±ï¼šè§£é‡‹æ€§å¼·ã€ç©©å®šå¯é ã€ä½å»¶é²
    2. MLæ¨¡å‹ï¼šé©æ‡‰æ€§å¼·ã€å­¸ç¿’èƒ½åŠ›ã€è™•ç†è¤‡é›œæ¨¡å¼
    3. æ··åˆç­–ç•¥ï¼šå–é•·è£œçŸ­ã€å‹•æ…‹èª¿æ•´ã€æœ€ä½³æ€§èƒ½
    
    æ¶æ§‹æ¨¡å¼ï¼š
    - Cascaded: è¦å‰‡åˆç¯© â†’ MLç²¾æ’
    - Weighted Ensemble: è¦å‰‡åˆ†æ•¸ + MLåˆ†æ•¸ â†’ åŠ æ¬Šèåˆ
    - Adaptive: æ ¹æ“šæŸ¥è©¢è¤‡é›œåº¦å‹•æ…‹é¸æ“‡ç­–ç•¥
    """
    
    def __init__(self, config: HybridConfig):
        """
        åˆå§‹åŒ–æ··åˆé‡æ’ç³»çµ±
        
        Args:
            config: æ··åˆç³»çµ±é…ç½®
        """
        self.config = config or HybridConfig()
        self.logger = logging.getLogger(__name__)
        
        # åˆå§‹åŒ–ç¬¬ä¸€æœŸè¦å‰‡ç³»çµ±
        self.rule_based_reranker = PhoneticReranker(self.config.rule_based_config)
        
        # åˆå§‹åŒ–æ©Ÿå™¨å­¸ç¿’æ¨¡å‹
        ml_config = self.config.ml_model_config or MLModelConfig()
        if ml_config.model_type == "transformer":
            self.ml_model = TransformerPhoneticModel(ml_config)
        else:
            raise ValueError(f"Unsupported model type: {ml_config.model_type}")
        
        # æ€§èƒ½çµ±è¨ˆ
        self.hybrid_stats = {
            "total_queries": 0,
            "rule_only_queries": 0,
            "ml_only_queries": 0,
            "hybrid_queries": 0,
            "avg_processing_time_ms": 0.0,
            "rule_confidence_distribution": {},
            "ml_confidence_distribution": {}
        }
        
        self.logger.info("HybridPhoneticReranker initialized")
    
    def rerank(self, query: str, max_candidates: Optional[int] = None) -> RerankerResult:
        """
        åŸ·è¡Œæ··åˆé‡æ’
        
        Args:
            query: æŸ¥è©¢è©å½™
            max_candidates: æœ€å¤§è¿”å›å€™é¸æ•¸
            
        Returns:
            æ··åˆé‡æ’çµæœ
        """
        start_time = time.time()
        
        # Phase 1: è¦å‰‡ç³»çµ±è™•ç†
        rule_result = self.rule_based_reranker.rerank(query, max_candidates)
        
        if rule_result.error:
            # è¦å‰‡ç³»çµ±å¤±æ•—ï¼Œç›´æ¥è¿”å›
            return rule_result
        
        # Phase 2: æ±ºå®šèåˆç­–ç•¥
        fusion_strategy = self._select_fusion_strategy(query, rule_result)
        
        # Phase 3: åŸ·è¡Œæ··åˆè™•ç†
        if fusion_strategy == "rule_only":
            final_result = rule_result
            self.hybrid_stats["rule_only_queries"] += 1
            
        elif fusion_strategy == "cascaded":
            final_result = self._cascaded_rerank(query, rule_result)
            self.hybrid_stats["hybrid_queries"] += 1
            
        elif fusion_strategy == "weighted_ensemble":
            final_result = self._weighted_ensemble_rerank(query, rule_result)
            self.hybrid_stats["hybrid_queries"] += 1
            
        else:  # adaptive
            final_result = self._adaptive_rerank(query, rule_result)
            self.hybrid_stats["hybrid_queries"] += 1
        
        # æ›´æ–°çµ±è¨ˆ
        processing_time = (time.time() - start_time) * 1000
        self.hybrid_stats["total_queries"] += 1
        self._update_performance_stats(processing_time)
        
        return final_result
    
    def _select_fusion_strategy(self, query: str, rule_result: RerankerResult) -> str:
        """
        é¸æ“‡èåˆç­–ç•¥
        
        Args:
            query: æŸ¥è©¢è©
            rule_result: è¦å‰‡ç³»çµ±çµæœ
            
        Returns:
            èåˆç­–ç•¥åç¨±
        """
        if not self.config.enable_adaptive_weighting:
            return self.config.fusion_strategy
        
        # é©æ‡‰æ€§ç­–ç•¥é¸æ“‡
        rule_confidence = rule_result.confidence_score
        
        if rule_confidence >= self.config.confidence_threshold:
            # è¦å‰‡ç³»çµ±ä¿¡å¿ƒåº¦é«˜ï¼Œç›´æ¥ä½¿ç”¨
            return "rule_only"
        elif rule_result.complexity_level == "simple":
            # ç°¡å–®æŸ¥è©¢ï¼Œç´šè¯è™•ç†
            return "cascaded"
        else:
            # è¤‡é›œæŸ¥è©¢ï¼ŒåŠ æ¬Šèåˆ
            return "weighted_ensemble"
    
    def _cascaded_rerank(self, query: str, rule_result: RerankerResult) -> RerankerResult:
        """
        ç´šè¯é‡æ’ï¼šè¦å‰‡åˆç¯© â†’ MLç²¾æ’
        
        Args:
            query: æŸ¥è©¢è©
            rule_result: è¦å‰‡ç³»çµ±çµæœ
            
        Returns:
            ç´šè¯è™•ç†çµæœ
        """
        # ä½¿ç”¨MLæ¨¡å‹å°è¦å‰‡çµæœé€²ä¸€æ­¥ç²¾æ’
        ml_scores = self.ml_model.predict(query, rule_result.candidates)
        
        # æŒ‰MLåˆ†æ•¸é‡æ–°æ’åº
        ml_scores.sort(key=lambda x: x[1], reverse=True)
        refined_candidates = [word for word, _ in ml_scores]
        
        # æ›´æ–°çµæœ
        cascaded_result = RerankerResult(
            query=query,
            candidates=refined_candidates,
            processing_time_ms=rule_result.processing_time_ms + 5.0,  # MLåŠ æ™‚
            complexity_level=rule_result.complexity_level,
            confidence_score=min(rule_result.confidence_score * 1.1, 1.0)  # è¼•å¾®æå‡ä¿¡å¿ƒåº¦
        )
        
        return cascaded_result
    
    def _weighted_ensemble_rerank(self, query: str, rule_result: RerankerResult) -> RerankerResult:
        """
        åŠ æ¬Šé›†æˆé‡æ’ï¼šè¦å‰‡åˆ†æ•¸ + MLåˆ†æ•¸
        
        Args:
            query: æŸ¥è©¢è©
            rule_result: è¦å‰‡ç³»çµ±çµæœ
            
        Returns:
            åŠ æ¬Šé›†æˆçµæœ
        """
        # ç²å–MLæ¨¡å‹åˆ†æ•¸
        ml_scores = dict(self.ml_model.predict(query, rule_result.candidates))
        
        # åŠ æ¬Šèåˆåˆ†æ•¸
        ensemble_scores = []
        for candidate in rule_result.candidates:
            # è¦å‰‡åˆ†æ•¸ï¼ˆåŸºæ–¼æ’åæ¨ä¼°ï¼‰
            rule_score = 1.0 - (rule_result.candidates.index(candidate) / len(rule_result.candidates))
            
            # MLåˆ†æ•¸
            ml_score = ml_scores.get(candidate, 0.5)
            
            # åŠ æ¬Šèåˆ
            final_score = (rule_score * self.config.rule_weight + 
                          ml_score * self.config.ml_weight)
            
            ensemble_scores.append((candidate, final_score))
        
        # æŒ‰èåˆåˆ†æ•¸æ’åº
        ensemble_scores.sort(key=lambda x: x[1], reverse=True)
        ensemble_candidates = [word for word, _ in ensemble_scores]
        
        # æ›´æ–°çµæœ
        ensemble_result = RerankerResult(
            query=query,
            candidates=ensemble_candidates,
            processing_time_ms=rule_result.processing_time_ms + 10.0,  # èåˆåŠ æ™‚
            complexity_level=rule_result.complexity_level,
            confidence_score=min(rule_result.confidence_score * 1.2, 1.0)  # é¡¯è‘—æå‡ä¿¡å¿ƒåº¦
        )
        
        return ensemble_result
    
    def _adaptive_rerank(self, query: str, rule_result: RerankerResult) -> RerankerResult:
        """
        é©æ‡‰æ€§é‡æ’ï¼šæ ¹æ“šæƒ…æ³å‹•æ…‹é¸æ“‡æœ€ä½³ç­–ç•¥
        
        Args:
            query: æŸ¥è©¢è©
            rule_result: è¦å‰‡ç³»çµ±çµæœ
            
        Returns:
            é©æ‡‰æ€§è™•ç†çµæœ
        """
        # æ ¹æ“šæŸ¥è©¢ç‰¹å¾µå‹•æ…‹é¸æ“‡
        if len(rule_result.candidates) < 10:
            # å€™é¸è©è¼ƒå°‘ï¼Œä½¿ç”¨ç´šè¯è™•ç†
            return self._cascaded_rerank(query, rule_result)
        else:
            # å€™é¸è©è¼ƒå¤šï¼Œä½¿ç”¨åŠ æ¬Šé›†æˆ
            return self._weighted_ensemble_rerank(query, rule_result)
    
    def _update_performance_stats(self, processing_time: float):
        """æ›´æ–°æ€§èƒ½çµ±è¨ˆ"""
        current_avg = self.hybrid_stats["avg_processing_time_ms"]
        total_queries = self.hybrid_stats["total_queries"]
        
        # æ›´æ–°ç§»å‹•å¹³å‡
        self.hybrid_stats["avg_processing_time_ms"] = (
            (current_avg * (total_queries - 1) + processing_time) / total_queries
        )
    
    def train_ml_model(self, training_data_path: str) -> Dict[str, float]:
        """
        ä½¿ç”¨ç¬¬ä¸€æœŸæ”¶é›†çš„æ•¸æ“šè¨“ç·´MLæ¨¡å‹
        
        Args:
            training_data_path: è¨“ç·´æ•¸æ“šæ–‡ä»¶è·¯å¾‘
            
        Returns:
            è¨“ç·´æŒ‡æ¨™
        """
        self.logger.info(f"Training ML model with data from {training_data_path}")
        
        # è¼‰å…¥è¨“ç·´æ•¸æ“š
        training_data = self._load_training_data(training_data_path)
        
        # è¨“ç·´æ¨¡å‹
        metrics = self.ml_model.train(training_data)
        
        # ä¿å­˜æ¨¡å‹
        model_path = self.config.ml_model_config.model_path
        self.ml_model.save_model(model_path)
        
        return metrics
    
    def _load_training_data(self, data_path: str) -> List[Dict[str, Any]]:
        """è¼‰å…¥ç¬¬ä¸€æœŸç³»çµ±æ”¶é›†çš„è¨“ç·´æ•¸æ“š"""
        # å¯¦éš›å¯¦ç¾éœ€è¦å¾TrainingDataLoggerçš„æ•¸æ“šåº«ä¸­è¼‰å…¥
        # é€™è£¡æä¾›æ¦‚å¿µæ€§å¯¦ç¾
        
        training_data = []
        
        # æ¨¡æ“¬è¼‰å…¥é‚è¼¯
        for i in range(1000):  # å‡è¨­æœ‰1000å€‹è¨“ç·´æ¨£æœ¬
            sample = {
                "query": f"sample_query_{i}",
                "candidates": [f"candidate_{j}" for j in range(20)],
                "l1_result": {"candidates_count": 25000, "processing_time_ms": 30},
                "l2_result": {"candidates_count": 500, "processing_time_ms": 80},
                "l3_result": {"candidates_count": 50, "processing_time_ms": 30},
                "complexity_level": "medium",
                "phonetic_features": {"query_length": 2}
            }
            training_data.append(sample)
        
        return training_data
    
    def get_hybrid_statistics(self) -> Dict[str, Any]:
        """ç²å–æ··åˆç³»çµ±çµ±è¨ˆä¿¡æ¯"""
        stats = {
            "hybrid_stats": self.hybrid_stats.copy(),
            "rule_based_stats": self.rule_based_reranker.get_statistics(),
            "fusion_strategy": self.config.fusion_strategy,
            "ml_model_type": self.config.ml_model_config.model_type if self.config.ml_model_config else "none"
        }
        
        return stats


def design_second_phase_architecture():
    """è¨­è¨ˆç¬¬äºŒæœŸæ··åˆæ¶æ§‹"""
    print("ğŸ”® ç¬¬äºŒæœŸæ··åˆæ¶æ§‹è¨­è¨ˆ")
    print("=" * 60)
    
    # æ¶æ§‹è¨­è¨ˆæ–‡æª”
    architecture_design = {
        "phase_2_objectives": [
            "æ•´åˆè¦å‰‡ç³»çµ±å’Œæ©Ÿå™¨å­¸ç¿’æ¨¡å‹çš„å„ªå‹¢",
            "åŸºæ–¼ç¬¬ä¸€æœŸæ”¶é›†çš„è¨“ç·´æ•¸æ“šæ”¹å–„æº–ç¢ºç‡",
            "ä¿æŒé«˜æ€§èƒ½çš„åŒæ™‚æå‡é©æ‡‰æ€§",
            "æ”¯æ´åœ¨ç·šå­¸ç¿’å’Œæ¨¡å‹æ›´æ–°"
        ],
        
        "technical_components": {
            "rule_based_system": {
                "role": "æä¾›ç©©å®šå¯é çš„åŸºç¤æ€§èƒ½",
                "advantages": ["ä½å»¶é²", "é«˜è§£é‡‹æ€§", "ç©©å®šå¯æ§"],
                "current_performance": "89.5%éƒ¨ç½²å°±ç·’åº¦"
            },
            
            "ml_model": {
                "type": "Transformer-based phonetic similarity model",
                "features": ["æ³¨æ„åŠ›æ©Ÿåˆ¶", "å­—ç¬¦ç´šç·¨ç¢¼", "ç«¯åˆ°ç«¯å­¸ç¿’"],
                "training_data": "ç¬¬ä¸€æœŸç³»çµ±æ”¶é›†çš„100%è™•ç†æ¡ˆä¾‹"
            },
            
            "fusion_strategies": {
                "cascaded": "è¦å‰‡åˆç¯© â†’ MLç²¾æ’",
                "weighted_ensemble": "è¦å‰‡åˆ†æ•¸ + MLåˆ†æ•¸ â†’ åŠ æ¬Šèåˆ",
                "adaptive": "æ ¹æ“šæŸ¥è©¢è¤‡é›œåº¦å‹•æ…‹é¸æ“‡ç­–ç•¥"
            }
        },
        
        "expected_improvements": {
            "accuracy": "å¾85.7%åŒ…å«ç‡æå‡åˆ°90%+",
            "adaptability": "æ”¯æ´æ–°é ˜åŸŸå’Œè®Šç•°æ¨¡å¼å­¸ç¿’",
            "personalization": "åŸºæ–¼ç”¨æˆ¶åé¥‹çš„å€‹æ€§åŒ–èª¿æ•´",
            "robustness": "æ›´å¥½çš„é‚Šç•Œæ¡ˆä¾‹è™•ç†"
        },
        
        "implementation_timeline": {
            "phase_2a": "æ•¸æ“šé è™•ç†å’Œç‰¹å¾µå·¥ç¨‹ (2é€±)",
            "phase_2b": "MLæ¨¡å‹è¨­è¨ˆå’Œè¨“ç·´ (4é€±)", 
            "phase_2c": "æ··åˆç³»çµ±é›†æˆå’Œæ¸¬è©¦ (2é€±)",
            "phase_2d": "æ€§èƒ½èª¿å„ªå’Œéƒ¨ç½² (2é€±)"
        }
    }
    
    print("ğŸ“Š æ¶æ§‹è¨­è¨ˆæ¦‚è¦:")
    print(f"  ç›®æ¨™: {', '.join(architecture_design['phase_2_objectives'])}")
    print(f"  MLæ¨¡å‹: {architecture_design['technical_components']['ml_model']['type']}")
    print(f"  èåˆç­–ç•¥: {len(architecture_design['technical_components']['fusion_strategies'])} ç¨®")
    print(f"  é æœŸæº–ç¢ºç‡æå‡: {architecture_design['expected_improvements']['accuracy']}")
    
    # ç¤ºä¾‹æ··åˆç³»çµ±
    print("\nğŸ§ª æ··åˆç³»çµ±ç¤ºä¾‹:")
    print("-" * 50)
    
    try:
        # åˆå§‹åŒ–æ··åˆç³»çµ±é…ç½®
        rule_config = RerankerConfig(l3_top_k=20, enable_training_data_logging=False)
        ml_config = MLModelConfig(model_type="transformer")
        hybrid_config = HybridConfig(
            rule_based_config=rule_config,
            ml_model_config=ml_config,
            fusion_strategy="adaptive"
        )
        
        # å‰µå»ºæ··åˆç³»çµ±å¯¦ä¾‹
        hybrid_system = HybridPhoneticReranker(hybrid_config)
        
        # ç¤ºä¾‹æŸ¥è©¢
        test_queries = ["çŸ¥é“", "è³‡é“", "åƒé£¯"]
        
        for query in test_queries:
            result = hybrid_system.rerank(query, max_candidates=10)
            print(f"  æ··åˆé‡æ’ '{query}': {len(result.candidates)} å€™é¸, "
                  f"{result.processing_time_ms:.1f}ms, ä¿¡å¿ƒåº¦: {result.confidence_score:.2f}")
        
        # çµ±è¨ˆä¿¡æ¯
        stats = hybrid_system.get_hybrid_statistics()
        hybrid_stats = stats["hybrid_stats"]
        
        print(f"\nğŸ“Š æ··åˆç³»çµ±çµ±è¨ˆ:")
        print(f"  ç¸½æŸ¥è©¢æ•¸: {hybrid_stats['total_queries']}")
        print(f"  è¦å‰‡å–®ç¨è™•ç†: {hybrid_stats['rule_only_queries']}")
        print(f"  æ··åˆè™•ç†: {hybrid_stats['hybrid_queries']}")
        print(f"  å¹³å‡è™•ç†æ™‚é–“: {hybrid_stats['avg_processing_time_ms']:.1f}ms")
        
        print(f"\nâœ… ç¬¬äºŒæœŸæ··åˆæ¶æ§‹è¨­è¨ˆå®Œæˆ")
        return True
        
    except Exception as e:
        print(f"âŒ è¨­è¨ˆéç¨‹å‡ºéŒ¯: {e}")
        return False


if __name__ == "__main__":
    # è¨­ç½®æ—¥èªŒ
    logging.basicConfig(level=logging.INFO)
    
    # åŸ·è¡Œç¬¬äºŒæœŸæ¶æ§‹è¨­è¨ˆ
    success = design_second_phase_architecture()
    print(f"\nç¬¬äºŒæœŸæ··åˆæ¶æ§‹è¨­è¨ˆ {'âœ… COMPLETED' if success else 'âŒ FAILED'}")