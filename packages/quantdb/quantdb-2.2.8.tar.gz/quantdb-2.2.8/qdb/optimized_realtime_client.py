"""
ä¼˜åŒ–çš„å®æ—¶æ•°æ®å®¢æˆ·ç«¯å®ç°

è¿™ä¸ªæ–‡ä»¶å±•ç¤ºäº†å¦‚ä½•ä¼˜åŒ– SimpleQDBClient ä¸­çš„å®æ—¶æ•°æ®è·å–åŠŸèƒ½ï¼Œ
è§£å†³å½“å‰å®ç°ä¸­çš„æ€§èƒ½é—®é¢˜ã€‚
"""

import os
import sqlite3
import time
from pathlib import Path
from typing import List, Dict, Optional, Any
from datetime import datetime, timedelta
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed

try:
    import akshare as ak
    AKSHARE_AVAILABLE = True
except ImportError:
    AKSHARE_AVAILABLE = False

class OptimizedRealtimeClient:
    """ä¼˜åŒ–çš„å®æ—¶æ•°æ®å®¢æˆ·ç«¯"""
    
    def __init__(self, cache_dir: Optional[str] = None):
        self.cache_dir = cache_dir or os.path.expanduser("~/.qdb_cache")
        self._ensure_cache_dir()
        self.db_path = os.path.join(self.cache_dir, "realtime_cache.db")
        self._init_realtime_cache()
        
        # å†…å­˜ç¼“å­˜é…ç½®
        self.memory_cache = {}
        self.cache_ttl = 60  # 1åˆ†é’Ÿç¼“å­˜
        self.trading_hours_ttl = 30  # äº¤æ˜“æ—¶é—´å†…30ç§’ç¼“å­˜
        
        # æ‰¹é‡è·å–ä¼˜åŒ–
        self.batch_cache = {}
        self.batch_cache_time = None
        self.batch_cache_ttl = 300  # 5åˆ†é’Ÿæ‰¹é‡ç¼“å­˜
        
        # çº¿ç¨‹é”
        self._cache_lock = threading.Lock()
        
    def _ensure_cache_dir(self):
        """ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨"""
        Path(self.cache_dir).mkdir(parents=True, exist_ok=True)
        
    def _init_realtime_cache(self):
        """åˆå§‹åŒ–å®æ—¶æ•°æ®ç¼“å­˜è¡¨"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS realtime_cache (
                    symbol TEXT PRIMARY KEY,
                    data TEXT NOT NULL,
                    timestamp REAL NOT NULL,
                    is_trading_hours BOOLEAN DEFAULT 0
                )
            ''')
            
            # åˆ›å»ºç´¢å¼•
            cursor.execute('''
                CREATE INDEX IF NOT EXISTS idx_timestamp 
                ON realtime_cache(timestamp)
            ''')
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            print(f"âš ï¸ åˆå§‹åŒ–å®æ—¶ç¼“å­˜å¤±è´¥: {e}")
    
    def _is_trading_hours(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦åœ¨äº¤æ˜“æ—¶é—´å†…"""
        now = datetime.now()
        weekday = now.weekday()
        
        # å‘¨æœ«ä¸äº¤æ˜“
        if weekday >= 5:
            return False
            
        # ç®€åŒ–çš„äº¤æ˜“æ—¶é—´åˆ¤æ–­ (9:30-11:30, 13:00-15:00)
        current_time = now.time()
        morning_start = datetime.strptime("09:30", "%H:%M").time()
        morning_end = datetime.strptime("11:30", "%H:%M").time()
        afternoon_start = datetime.strptime("13:00", "%H:%M").time()
        afternoon_end = datetime.strptime("15:00", "%H:%M").time()
        
        return (morning_start <= current_time <= morning_end or 
                afternoon_start <= current_time <= afternoon_end)
    
    def _get_cache_ttl(self) -> int:
        """æ ¹æ®äº¤æ˜“æ—¶é—´è·å–ç¼“å­˜TTL"""
        return self.trading_hours_ttl if self._is_trading_hours() else self.cache_ttl
    
    def _get_from_memory_cache(self, symbol: str) -> Optional[Dict[str, Any]]:
        """ä»å†…å­˜ç¼“å­˜è·å–æ•°æ®"""
        with self._cache_lock:
            if symbol in self.memory_cache:
                cached_time, cached_data = self.memory_cache[symbol]
                ttl = self._get_cache_ttl()
                
                if time.time() - cached_time < ttl:
                    cached_data = cached_data.copy()
                    cached_data['cache_hit'] = True
                    cached_data['cache_source'] = 'memory'
                    return cached_data
                else:
                    # è¿‡æœŸåˆ é™¤
                    del self.memory_cache[symbol]
        return None
    
    def _save_to_memory_cache(self, symbol: str, data: Dict[str, Any]):
        """ä¿å­˜åˆ°å†…å­˜ç¼“å­˜"""
        with self._cache_lock:
            self.memory_cache[symbol] = (time.time(), data.copy())
    
    def _get_from_db_cache(self, symbol: str) -> Optional[Dict[str, Any]]:
        """ä»æ•°æ®åº“ç¼“å­˜è·å–æ•°æ®"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                SELECT data, timestamp, is_trading_hours 
                FROM realtime_cache 
                WHERE symbol = ?
            ''', (symbol,))
            
            result = cursor.fetchone()
            conn.close()
            
            if result:
                data_str, cached_time, was_trading_hours = result
                ttl = self.trading_hours_ttl if was_trading_hours else self.cache_ttl
                
                if time.time() - cached_time < ttl:
                    import json
                    cached_data = json.loads(data_str)
                    cached_data['cache_hit'] = True
                    cached_data['cache_source'] = 'database'
                    return cached_data
                    
        except Exception as e:
            print(f"âš ï¸ æ•°æ®åº“ç¼“å­˜è¯»å–å¤±è´¥: {e}")
        
        return None
    
    def _save_to_db_cache(self, symbol: str, data: Dict[str, Any]):
        """ä¿å­˜åˆ°æ•°æ®åº“ç¼“å­˜"""
        try:
            import json
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT OR REPLACE INTO realtime_cache 
                (symbol, data, timestamp, is_trading_hours)
                VALUES (?, ?, ?, ?)
            ''', (
                symbol, 
                json.dumps(data), 
                time.time(), 
                self._is_trading_hours()
            ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            print(f"âš ï¸ æ•°æ®åº“ç¼“å­˜ä¿å­˜å¤±è´¥: {e}")
    
    def get_realtime_data(self, symbol: str, force_refresh: bool = False) -> Dict[str, Any]:
        """
        ä¼˜åŒ–çš„å•ä¸ªè‚¡ç¥¨å®æ—¶æ•°æ®è·å–
        
        ä¼˜åŒ–ç‚¹:
        1. å¤šçº§ç¼“å­˜ (å†…å­˜ -> æ•°æ®åº“ -> ç½‘ç»œ)
        2. æ™ºèƒ½TTL (äº¤æ˜“æ—¶é—´å†…æ›´çŸ­çš„ç¼“å­˜æ—¶é—´)
        3. æ›´å¥½çš„é”™è¯¯å¤„ç†
        """
        if not force_refresh:
            # å°è¯•å†…å­˜ç¼“å­˜
            cached_data = self._get_from_memory_cache(symbol)
            if cached_data:
                return cached_data
            
            # å°è¯•æ•°æ®åº“ç¼“å­˜
            cached_data = self._get_from_db_cache(symbol)
            if cached_data:
                # åŒæ—¶ä¿å­˜åˆ°å†…å­˜ç¼“å­˜
                self._save_to_memory_cache(symbol, cached_data)
                return cached_data
        
        # ä»ç½‘ç»œè·å–
        try:
            if not AKSHARE_AVAILABLE:
                return self._get_mock_data(symbol)
            
            # ä½¿ç”¨æ›´é«˜æ•ˆçš„AKShareæ¥å£
            df = ak.stock_zh_a_spot()
            
            # æ¸…ç†symbolæ ¼å¼
            clean_symbol = self._clean_symbol(symbol)
            
            # æŸ¥æ‰¾å¯¹åº”çš„è‚¡ç¥¨æ•°æ®
            stock_data = df[df['ä»£ç '] == clean_symbol]
            
            if not stock_data.empty:
                row = stock_data.iloc[0]
                data = self._convert_akshare_data(symbol, row)
                data['cache_hit'] = False
                data['cache_source'] = 'network'
                
                # ä¿å­˜åˆ°ç¼“å­˜
                self._save_to_memory_cache(symbol, data)
                self._save_to_db_cache(symbol, data)
                
                return data
            else:
                return {
                    'symbol': symbol,
                    'error': 'Symbol not found in market data',
                    'cache_hit': False,
                    'timestamp': datetime.now().isoformat()
                }
                
        except Exception as e:
            return {
                'symbol': symbol,
                'error': str(e),
                'cache_hit': False,
                'timestamp': datetime.now().isoformat()
            }
    
    def get_realtime_data_batch_optimized(self, symbols: List[str], force_refresh: bool = False) -> Dict[str, Dict[str, Any]]:
        """
        ä¼˜åŒ–çš„æ‰¹é‡å®æ—¶æ•°æ®è·å–
        
        ä¼˜åŒ–ç‚¹:
        1. åªè°ƒç”¨ä¸€æ¬¡ ak.stock_zh_a_spot()
        2. æ™ºèƒ½ç¼“å­˜ç®¡ç†
        3. å¹¶å‘å¤„ç†ç¼“å­˜æŸ¥è¯¢
        4. æ‰¹é‡æ•°æ®ç¼“å­˜
        """
        result = {}
        symbols_to_fetch = []
        
        # å¹¶å‘æ£€æŸ¥ç¼“å­˜
        if not force_refresh:
            with ThreadPoolExecutor(max_workers=4) as executor:
                cache_futures = {
                    executor.submit(self._get_from_memory_cache, symbol): symbol 
                    for symbol in symbols
                }
                
                for future in as_completed(cache_futures):
                    symbol = cache_futures[future]
                    cached_data = future.result()
                    
                    if cached_data:
                        result[symbol] = cached_data
                    else:
                        symbols_to_fetch.append(symbol)
        else:
            symbols_to_fetch = symbols.copy()
        
        # æ‰¹é‡è·å–éœ€è¦æ›´æ–°çš„æ•°æ®
        if symbols_to_fetch:
            batch_data = self._fetch_batch_data(symbols_to_fetch)
            
            # æ›´æ–°ç»“æœå’Œç¼“å­˜
            for symbol in symbols_to_fetch:
                if symbol in batch_data:
                    data = batch_data[symbol]
                    result[symbol] = data
                    
                    # å¼‚æ­¥ä¿å­˜åˆ°ç¼“å­˜
                    self._save_to_memory_cache(symbol, data)
                    # æ•°æ®åº“ä¿å­˜å¯ä»¥å¼‚æ­¥è¿›è¡Œ
                    threading.Thread(
                        target=self._save_to_db_cache, 
                        args=(symbol, data)
                    ).start()
                else:
                    result[symbol] = {
                        'symbol': symbol,
                        'error': 'No data available in batch',
                        'cache_hit': False,
                        'timestamp': datetime.now().isoformat()
                    }
        
        return result
    
    def _fetch_batch_data(self, symbols: List[str]) -> Dict[str, Dict[str, Any]]:
        """è·å–æ‰¹é‡æ•°æ® - åªè°ƒç”¨ä¸€æ¬¡AKShare API"""
        try:
            if not AKSHARE_AVAILABLE:
                return {symbol: self._get_mock_data(symbol) for symbol in symbols}
            
            # æ£€æŸ¥æ‰¹é‡ç¼“å­˜
            now = time.time()
            if (self.batch_cache_time and 
                now - self.batch_cache_time < self.batch_cache_ttl and
                not self._is_trading_hours()):  # éäº¤æ˜“æ—¶é—´ä½¿ç”¨æ‰¹é‡ç¼“å­˜
                
                result = {}
                for symbol in symbols:
                    clean_symbol = self._clean_symbol(symbol)
                    if clean_symbol in self.batch_cache:
                        data = self.batch_cache[clean_symbol].copy()
                        data['cache_hit'] = True
                        data['cache_source'] = 'batch_cache'
                        result[symbol] = data
                return result
            
            # è·å–å…¨å¸‚åœºæ•°æ® (ä½†åªè°ƒç”¨ä¸€æ¬¡)
            print("ğŸ“¡ è·å–å…¨å¸‚åœºå®æ—¶æ•°æ®...")
            df = ak.stock_zh_a_spot()
            
            # æ›´æ–°æ‰¹é‡ç¼“å­˜
            self.batch_cache = {}
            self.batch_cache_time = now
            
            result = {}
            for symbol in symbols:
                clean_symbol = self._clean_symbol(symbol)
                stock_data = df[df['ä»£ç '] == clean_symbol]
                
                if not stock_data.empty:
                    row = stock_data.iloc[0]
                    data = self._convert_akshare_data(symbol, row)
                    data['cache_hit'] = False
                    data['cache_source'] = 'network_batch'
                    
                    result[symbol] = data
                    self.batch_cache[clean_symbol] = data.copy()
            
            return result
            
        except Exception as e:
            print(f"âš ï¸ æ‰¹é‡è·å–å¤±è´¥: {e}")
            return {}
    
    def _clean_symbol(self, symbol: str) -> str:
        """æ¸…ç†è‚¡ç¥¨ä»£ç æ ¼å¼"""
        clean_symbol = symbol
        if "." in clean_symbol:
            clean_symbol = clean_symbol.split(".")[0]
        if clean_symbol.lower().startswith(("sh", "sz")):
            clean_symbol = clean_symbol[2:]
        return clean_symbol
    
    def _convert_akshare_data(self, symbol: str, row) -> Dict[str, Any]:
        """è½¬æ¢AKShareæ•°æ®æ ¼å¼"""
        try:
            return {
                'symbol': symbol,
                'name': str(row.get('åç§°', 'N/A')),
                'current_price': float(row.get('æœ€æ–°ä»·', 0)),
                'change': float(row.get('æ¶¨è·Œé¢', 0)),
                'change_percent': float(row.get('æ¶¨è·Œå¹…', 0)),
                'open': float(row.get('ä»Šå¼€', 0)),
                'high': float(row.get('æœ€é«˜', 0)),
                'low': float(row.get('æœ€ä½', 0)),
                'volume': int(row.get('æˆäº¤é‡', 0)),
                'amount': float(row.get('æˆäº¤é¢', 0)),
                'timestamp': datetime.now().isoformat(),
                'market_status': 'open' if self._is_trading_hours() else 'closed'
            }
        except Exception as e:
            return {
                'symbol': symbol,
                'error': f'Data conversion failed: {e}',
                'timestamp': datetime.now().isoformat()
            }
    
    def _get_mock_data(self, symbol: str) -> Dict[str, Any]:
        """ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®"""
        import random
        
        base_prices = {
            '000001': 10.50, '000002': 25.30, '600000': 8.20,
            '000858': 158.50, '002415': 32.80
        }
        
        base_price = base_prices.get(symbol, 50.0)
        change = random.uniform(-2, 2)
        change_percent = (change / base_price) * 100
        
        return {
            'symbol': symbol,
            'name': f'Mock Stock {symbol}',
            'current_price': round(base_price + change, 2),
            'change': round(change, 2),
            'change_percent': round(change_percent, 2),
            'open': round(base_price + random.uniform(-1, 1), 2),
            'high': round(base_price + random.uniform(0, 3), 2),
            'low': round(base_price + random.uniform(-3, 0), 2),
            'volume': random.randint(1000000, 10000000),
            'amount': random.randint(50000000, 500000000),
            'timestamp': datetime.now().isoformat(),
            'market_status': 'open' if self._is_trading_hours() else 'closed',
            'cache_hit': False,
            'cache_source': 'mock'
        }
    
    def clear_cache(self):
        """æ¸…é™¤æ‰€æœ‰ç¼“å­˜"""
        with self._cache_lock:
            self.memory_cache.clear()
            self.batch_cache.clear()
            self.batch_cache_time = None
        
        try:
            if os.path.exists(self.db_path):
                os.remove(self.db_path)
                self._init_realtime_cache()
            print("âœ… å®æ—¶æ•°æ®ç¼“å­˜å·²æ¸…é™¤")
        except Exception as e:
            print(f"âš ï¸ æ¸…é™¤ç¼“å­˜å¤±è´¥: {e}")
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        with self._cache_lock:
            memory_count = len(self.memory_cache)
            batch_count = len(self.batch_cache)
        
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute('SELECT COUNT(*) FROM realtime_cache')
            db_count = cursor.fetchone()[0]
            conn.close()
        except:
            db_count = 0
        
        return {
            'memory_cache_count': memory_count,
            'database_cache_count': db_count,
            'batch_cache_count': batch_count,
            'cache_ttl': self._get_cache_ttl(),
            'is_trading_hours': self._is_trading_hours(),
            'batch_cache_valid': (
                self.batch_cache_time and 
                time.time() - self.batch_cache_time < self.batch_cache_ttl
            ) if self.batch_cache_time else False
        }
