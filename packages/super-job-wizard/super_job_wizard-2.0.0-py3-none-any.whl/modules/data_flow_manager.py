# -*- coding: utf-8 -*-
"""
ğŸ”„ æ•°æ®æµç®¡ç†å™¨æ¨¡å—
Data Flow Manager Module

ä¼˜åŒ–æ¨¡å—é—´è°ƒç”¨é“¾ï¼Œå®ç°å•ä¾‹æ¨¡å¼ã€æ™ºèƒ½ç¼“å­˜å’Œæ•°æ®å…±äº«

åŠŸèƒ½ï¼š
ğŸ—ï¸ å•ä¾‹æ¨¡å¼ç®¡ç†æ‰€æœ‰æ¨¡å—å®ä¾‹
ğŸ’¾ æ™ºèƒ½ç¼“å­˜æœºåˆ¶
ğŸ”— æ•°æ®ä¼ é€’é“¾è·¯è¿½è¸ª
ğŸ“Š æ€§èƒ½ç›‘æ§å’Œä¼˜åŒ–
ğŸ¯ ç»Ÿä¸€è°ƒç”¨æ¥å£

ä½œè€…: AI Assistant
ç‰ˆæœ¬: 1.0
"""

import time
import hashlib
import threading
from typing import Dict, List, Optional, Any, Union, Callable
from datetime import datetime, timedelta
from dataclasses import dataclass, field
import json

# å¯¼å…¥æ•°æ®æ¥å£æ ‡å‡†
try:
    from .data_interface import (
        DataInterfaceManager, UserProfile, JobData, AnalysisResult,
        DataCache, PersonalityType, RiskLevel, JobStatus, AnalysisType
    )
except ImportError:
    # å¦‚æœç›¸å¯¹å¯¼å…¥å¤±è´¥ï¼Œå°è¯•ç»å¯¹å¯¼å…¥
    import sys
    import os
    sys.path.append(os.path.dirname(__file__))
    from data_interface import (
        DataInterfaceManager, UserProfile, JobData, AnalysisResult,
        DataCache, PersonalityType, RiskLevel, JobStatus, AnalysisType
    )


# ================================
# ğŸ“Š æ€§èƒ½ç›‘æ§æ•°æ®ç»“æ„
# ================================

@dataclass
class CallMetrics:
    """è°ƒç”¨æŒ‡æ ‡æ•°æ®ç»“æ„"""
    module_name: str
    method_name: str
    call_count: int = 0
    total_time: float = 0.0
    avg_time: float = 0.0
    last_called: Optional[datetime] = None
    cache_hits: int = 0
    cache_misses: int = 0
    
    def update_metrics(self, execution_time: float, cache_hit: bool = False):
        """æ›´æ–°è°ƒç”¨æŒ‡æ ‡"""
        self.call_count += 1
        self.total_time += execution_time
        self.avg_time = self.total_time / self.call_count
        self.last_called = datetime.now()
        
        if cache_hit:
            self.cache_hits += 1
        else:
            self.cache_misses += 1


# ================================
# ğŸ—ï¸ å•ä¾‹æ¨¡å¼åŸºç±»
# ================================

class SingletonMeta(type):
    """å•ä¾‹æ¨¡å¼å…ƒç±»"""
    _instances = {}
    _lock = threading.Lock()
    
    def __call__(cls, *args, **kwargs):
        if cls not in cls._instances:
            with cls._lock:
                if cls not in cls._instances:
                    cls._instances[cls] = super().__call__(*args, **kwargs)
        return cls._instances[cls]


# ================================
# ğŸ’¾ æ™ºèƒ½ç¼“å­˜ç®¡ç†å™¨
# ================================

class SmartCacheManager:
    """æ™ºèƒ½ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self, max_size: int = 1000, default_ttl: int = 3600):
        self.max_size = max_size
        self.default_ttl = default_ttl
        self.cache: Dict[str, DataCache] = {}
        self._lock = threading.Lock()
    
    def _generate_cache_key(self, module: str, method: str, args: tuple, kwargs: dict) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        # åˆ›å»ºå”¯ä¸€æ ‡è¯†ç¬¦
        key_data = {
            "module": module,
            "method": method,
            "args": str(args),
            "kwargs": str(sorted(kwargs.items()))
        }
        key_string = json.dumps(key_data, sort_keys=True)
        return hashlib.md5(key_string.encode()).hexdigest()
    
    def get(self, module: str, method: str, args: tuple, kwargs: dict) -> Optional[Any]:
        """è·å–ç¼“å­˜æ•°æ®"""
        cache_key = self._generate_cache_key(module, method, args, kwargs)
        
        with self._lock:
            if cache_key in self.cache:
                cache_item = self.cache[cache_key]
                if not cache_item.is_expired():
                    return cache_item.data
                else:
                    # åˆ é™¤è¿‡æœŸç¼“å­˜
                    del self.cache[cache_key]
        
        return None
    
    def set(self, module: str, method: str, args: tuple, kwargs: dict, data: Any, ttl: Optional[int] = None) -> None:
        """è®¾ç½®ç¼“å­˜æ•°æ®"""
        cache_key = self._generate_cache_key(module, method, args, kwargs)
        ttl = ttl or self.default_ttl
        
        with self._lock:
            # å¦‚æœç¼“å­˜å·²æ»¡ï¼Œåˆ é™¤æœ€æ—§çš„é¡¹
            if len(self.cache) >= self.max_size:
                oldest_key = min(self.cache.keys(), key=lambda k: self.cache[k].created_at)
                del self.cache[oldest_key]
            
            self.cache[cache_key] = DataCache(
                cache_key=cache_key,
                data=data,
                cache_type=f"{module}.{method}",
                ttl=ttl
            )
    
    def clear(self, module: Optional[str] = None) -> None:
        """æ¸…é™¤ç¼“å­˜"""
        with self._lock:
            if module:
                # æ¸…é™¤ç‰¹å®šæ¨¡å—çš„ç¼“å­˜
                keys_to_remove = [k for k, v in self.cache.items() if v.cache_type.startswith(module)]
                for key in keys_to_remove:
                    del self.cache[key]
            else:
                # æ¸…é™¤æ‰€æœ‰ç¼“å­˜
                self.cache.clear()
    
    def get_cache_stats(self) -> Dict:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        with self._lock:
            total_items = len(self.cache)
            expired_items = sum(1 for item in self.cache.values() if item.is_expired())
            
            return {
                "total_items": total_items,
                "active_items": total_items - expired_items,
                "expired_items": expired_items,
                "cache_types": list(set(item.cache_type for item in self.cache.values())),
                "memory_usage_estimate": total_items * 1024  # ç²—ç•¥ä¼°è®¡
            }


# ================================
# ğŸ”„ æ•°æ®æµç®¡ç†å™¨ä¸»ç±»
# ================================

class DataFlowManager(metaclass=SingletonMeta):
    """æ•°æ®æµç®¡ç†å™¨ - ç»Ÿä¸€ç®¡ç†æ‰€æœ‰æ¨¡å—å®ä¾‹å’Œæ•°æ®æµ"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ•°æ®æµç®¡ç†å™¨"""
        print("ğŸš€ åˆå§‹åŒ–æ•°æ®æµç®¡ç†å™¨...")
        
        # æ ¸å¿ƒç»„ä»¶
        self.data_interface = DataInterfaceManager()
        self.cache_manager = SmartCacheManager()
        
        # æ¨¡å—å®ä¾‹å­˜å‚¨
        self._module_instances: Dict[str, Any] = {}
        self._module_lock = threading.Lock()
        
        # æ€§èƒ½ç›‘æ§
        self.call_metrics: Dict[str, CallMetrics] = {}
        self.metrics_lock = threading.Lock()
        
        # æ•°æ®å…±äº«å­˜å‚¨
        self.shared_data: Dict[str, Any] = {}
        self.shared_data_lock = threading.Lock()
        
        print("âœ… æ•°æ®æµç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆï¼")
    
    def get_module_instance(self, module_name: str, module_class: type) -> Any:
        """è·å–æ¨¡å—å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
        with self._module_lock:
            if module_name not in self._module_instances:
                print(f"ğŸ—ï¸ åˆ›å»ºæ–°çš„æ¨¡å—å®ä¾‹: {module_name}")
                self._module_instances[module_name] = module_class()
            
            return self._module_instances[module_name]
    
    def call_module_method(
        self, 
        module_name: str, 
        method_name: str, 
        *args, 
        use_cache: bool = True,
        cache_ttl: Optional[int] = None,
        **kwargs
    ) -> Any:
        """è°ƒç”¨æ¨¡å—æ–¹æ³•ï¼ˆå¸¦ç¼“å­˜å’Œæ€§èƒ½ç›‘æ§ï¼‰"""
        
        # æ£€æŸ¥ç¼“å­˜
        if use_cache:
            cached_result = self.cache_manager.get(module_name, method_name, args, kwargs)
            if cached_result is not None:
                self._update_call_metrics(module_name, method_name, 0, cache_hit=True)
                return cached_result
        
        # è·å–æ¨¡å—å®ä¾‹
        if module_name not in self._module_instances:
            raise ValueError(f"æ¨¡å— {module_name} æœªæ³¨å†Œ")
        
        module_instance = self._module_instances[module_name]
        
        # æ£€æŸ¥æ–¹æ³•æ˜¯å¦å­˜åœ¨
        if not hasattr(module_instance, method_name):
            raise AttributeError(f"æ¨¡å— {module_name} æ²¡æœ‰æ–¹æ³• {method_name}")
        
        # æ‰§è¡Œæ–¹æ³•å¹¶ç›‘æ§æ€§èƒ½
        start_time = time.time()
        try:
            method = getattr(module_instance, method_name)
            result = method(*args, **kwargs)
            
            execution_time = time.time() - start_time
            
            # ç¼“å­˜ç»“æœ
            if use_cache:
                self.cache_manager.set(module_name, method_name, args, kwargs, result, cache_ttl)
            
            # æ›´æ–°æ€§èƒ½æŒ‡æ ‡
            self._update_call_metrics(module_name, method_name, execution_time, cache_hit=False)
            
            return result
            
        except Exception as e:
            execution_time = time.time() - start_time
            self._update_call_metrics(module_name, method_name, execution_time, cache_hit=False)
            raise e
    
    def _update_call_metrics(self, module_name: str, method_name: str, execution_time: float, cache_hit: bool):
        """æ›´æ–°è°ƒç”¨æŒ‡æ ‡"""
        metric_key = f"{module_name}.{method_name}"
        
        with self.metrics_lock:
            if metric_key not in self.call_metrics:
                self.call_metrics[metric_key] = CallMetrics(module_name, method_name)
            
            self.call_metrics[metric_key].update_metrics(execution_time, cache_hit)
    
    def register_module(self, module_name: str, module_instance: Any) -> None:
        """æ³¨å†Œæ¨¡å—å®ä¾‹"""
        with self._module_lock:
            self._module_instances[module_name] = module_instance
            print(f"ğŸ“ æ³¨å†Œæ¨¡å—: {module_name}")
    
    def share_data(self, key: str, data: Any, ttl: Optional[int] = None) -> None:
        """å…±äº«æ•°æ®åˆ°å…¨å±€å­˜å‚¨"""
        with self.shared_data_lock:
            self.shared_data[key] = {
                "data": data,
                "created_at": datetime.now(),
                "ttl": ttl
            }
    
    def get_shared_data(self, key: str) -> Optional[Any]:
        """è·å–å…±äº«æ•°æ®"""
        with self.shared_data_lock:
            if key in self.shared_data:
                item = self.shared_data[key]
                
                # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
                if item["ttl"]:
                    if (datetime.now() - item["created_at"]).seconds > item["ttl"]:
                        del self.shared_data[key]
                        return None
                
                return item["data"]
        
        return None
    
    def get_performance_report(self) -> Dict:
        """è·å–æ€§èƒ½æŠ¥å‘Š"""
        with self.metrics_lock:
            report = {
                "æ€»è°ƒç”¨æ¬¡æ•°": sum(metric.call_count for metric in self.call_metrics.values()),
                "å¹³å‡å“åº”æ—¶é—´": sum(metric.avg_time for metric in self.call_metrics.values()) / len(self.call_metrics) if self.call_metrics else 0,
                "ç¼“å­˜å‘½ä¸­ç‡": self._calculate_cache_hit_rate(),
                "æ¨¡å—æ€§èƒ½": {},
                "ç¼“å­˜ç»Ÿè®¡": self.cache_manager.get_cache_stats(),
                "ç”Ÿæˆæ—¶é—´": datetime.now().isoformat()
            }
            
            # è¯¦ç»†æ¨¡å—æ€§èƒ½
            for key, metric in self.call_metrics.items():
                report["æ¨¡å—æ€§èƒ½"][key] = {
                    "è°ƒç”¨æ¬¡æ•°": metric.call_count,
                    "å¹³å‡æ—¶é—´": round(metric.avg_time, 4),
                    "æ€»æ—¶é—´": round(metric.total_time, 4),
                    "ç¼“å­˜å‘½ä¸­ç‡": round(metric.cache_hits / (metric.cache_hits + metric.cache_misses) * 100, 2) if (metric.cache_hits + metric.cache_misses) > 0 else 0,
                    "æœ€åè°ƒç”¨": metric.last_called.isoformat() if metric.last_called else None
                }
            
            return report
    
    def _calculate_cache_hit_rate(self) -> float:
        """è®¡ç®—æ€»ä½“ç¼“å­˜å‘½ä¸­ç‡"""
        total_hits = sum(metric.cache_hits for metric in self.call_metrics.values())
        total_requests = sum(metric.cache_hits + metric.cache_misses for metric in self.call_metrics.values())
        
        return round(total_hits / total_requests * 100, 2) if total_requests > 0 else 0
    
    def clear_all_caches(self) -> None:
        """æ¸…é™¤æ‰€æœ‰ç¼“å­˜"""
        self.cache_manager.clear()
        with self.shared_data_lock:
            self.shared_data.clear()
        print("ğŸ§¹ æ‰€æœ‰ç¼“å­˜å·²æ¸…é™¤")
    
    def reset_metrics(self) -> None:
        """é‡ç½®æ€§èƒ½æŒ‡æ ‡"""
        with self.metrics_lock:
            self.call_metrics.clear()
        print("ğŸ“Š æ€§èƒ½æŒ‡æ ‡å·²é‡ç½®")


# ================================
# ğŸ¯ ä¾¿æ·è°ƒç”¨æ¥å£
# ================================

class ModuleCallProxy:
    """æ¨¡å—è°ƒç”¨ä»£ç† - æä¾›ä¾¿æ·çš„è°ƒç”¨æ¥å£"""
    
    def __init__(self, data_flow_manager: DataFlowManager):
        self.dfm = data_flow_manager
    
    def ai_analyzer(self, method: str, *args, **kwargs):
        """AIåˆ†æå™¨è°ƒç”¨ä»£ç†"""
        return self.dfm.call_module_method("ai_analyzer", method, *args, **kwargs)
    
    def big_data(self, method: str, *args, **kwargs):
        """å¤§æ•°æ®åˆ†æå™¨è°ƒç”¨ä»£ç†"""
        return self.dfm.call_module_method("big_data", method, *args, **kwargs)
    
    def platform_integration(self, method: str, *args, **kwargs):
        """å¹³å°é›†æˆè°ƒç”¨ä»£ç†"""
        return self.dfm.call_module_method("platform_integration", method, *args, **kwargs)
    
    def smart_decision(self, method: str, *args, **kwargs):
        """æ™ºèƒ½å†³ç­–è°ƒç”¨ä»£ç†"""
        return self.dfm.call_module_method("smart_decision", method, *args, **kwargs)


# ================================
# ğŸ§ª æµ‹è¯•å‡½æ•°
# ================================

def test_data_flow_manager():
    """æµ‹è¯•æ•°æ®æµç®¡ç†å™¨"""
    print("ğŸ§ª æµ‹è¯•æ•°æ®æµç®¡ç†å™¨...")
    
    # åˆ›å»ºç®¡ç†å™¨å®ä¾‹
    dfm = DataFlowManager()
    
    # æµ‹è¯•å•ä¾‹æ¨¡å¼
    dfm2 = DataFlowManager()
    assert dfm is dfm2, "å•ä¾‹æ¨¡å¼æµ‹è¯•å¤±è´¥"
    print("âœ… å•ä¾‹æ¨¡å¼æµ‹è¯•é€šè¿‡")
    
    # æµ‹è¯•æ•°æ®å…±äº«
    dfm.share_data("test_key", {"message": "Hello World"})
    shared_data = dfm.get_shared_data("test_key")
    assert shared_data["message"] == "Hello World", "æ•°æ®å…±äº«æµ‹è¯•å¤±è´¥"
    print("âœ… æ•°æ®å…±äº«æµ‹è¯•é€šè¿‡")
    
    # æµ‹è¯•ç¼“å­˜
    cache_stats = dfm.cache_manager.get_cache_stats()
    print(f"âœ… ç¼“å­˜ç»Ÿè®¡: {cache_stats}")
    
    # æµ‹è¯•æ€§èƒ½æŠ¥å‘Š
    performance_report = dfm.get_performance_report()
    print(f"âœ… æ€§èƒ½æŠ¥å‘Šç”ŸæˆæˆåŠŸ")
    
    print("ğŸ‰ æ•°æ®æµç®¡ç†å™¨æµ‹è¯•å®Œæˆï¼")


if __name__ == "__main__":
    test_data_flow_manager()