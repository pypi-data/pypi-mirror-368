#!/usr/bin/env python3
"""
ğŸ”— å¹³å°é›†æˆæ¨¡å—
æ•´åˆå„å¤§æ±‚èŒå¹³å°å’Œç¤¾äº¤ç½‘ç»œçš„æ•°æ®å’ŒåŠŸèƒ½

åŠŸèƒ½ç‰¹æ€§ï¼š
- ğŸ’¼ LinkedInæ•°æ®åˆ†æå’Œä¼˜åŒ–
- ğŸ“± å¤šå¹³å°æ±‚èŒè¿›åº¦è¿½è¸ª
- ğŸ“§ æ™ºèƒ½é‚®ä»¶æ¨¡æ¿ç”Ÿæˆ
- ğŸ“… é¢è¯•æ—¥ç¨‹ç®¡ç†ç³»ç»Ÿ
- ğŸ” èŒä½ä¿¡æ¯èšåˆåˆ†æ
- ğŸ“Š ç¤¾äº¤ç½‘ç»œå½±å“åŠ›è¯„ä¼°
"""

import json
import re
from typing import Dict, List, Optional, Tuple
from datetime import datetime, timedelta
from collections import defaultdict

# ================================
# ğŸ’¼ LinkedInåˆ†ææ•°æ®
# ================================

LINKEDIN_OPTIMIZATION_RULES = {
    "æ ‡é¢˜ä¼˜åŒ–": {
        "å…³é”®è¯": ["AI", "æœºå™¨å­¦ä¹ ", "äº‘è®¡ç®—", "å…¨æ ˆ", "DevOps", "åŒºå—é“¾"],
        "æ ¼å¼": "{èŒä½} | {æ ¸å¿ƒæŠ€èƒ½} | {å¹´é™}å¹´ç»éªŒ",
        "é•¿åº¦": (50, 120),
        "å»ºè®®": [
            "åŒ…å«æ ¸å¿ƒæŠ€èƒ½å…³é”®è¯",
            "çªå‡ºå¹´é™å’Œä¸“ä¸šé¢†åŸŸ",
            "ä½¿ç”¨è¡Œä¸šæœ¯è¯­",
            "é¿å…è¿‡äºé€šç”¨çš„æè¿°"
        ]
    },
    "æ‘˜è¦ä¼˜åŒ–": {
        "ç»“æ„": ["å¼€åœºç™½", "æ ¸å¿ƒæŠ€èƒ½", "å·¥ä½œç»å†äº®ç‚¹", "èŒä¸šç›®æ ‡"],
        "é•¿åº¦": (200, 2000),
        "å…³é”®å…ƒç´ ": [
            "é‡åŒ–æˆæœ",
            "æŠ€æœ¯æ ˆåˆ—è¡¨",
            "è¡Œä¸šç»éªŒ",
            "ä¸ªäººç‰¹è‰²"
        ]
    },
    "æŠ€èƒ½æ ‡ç­¾": {
        "çƒ­é—¨æŠ€èƒ½": [
            "Python", "JavaScript", "React", "AWS", "Docker",
            "Kubernetes", "æœºå™¨å­¦ä¹ ", "æ•°æ®åˆ†æ", "é¡¹ç›®ç®¡ç†"
        ],
        "æ–°å…´æŠ€èƒ½": [
            "ChatGPT", "LangChain", "Stable Diffusion", "Web3",
            "Solidity", "Terraform", "GraphQL"
        ]
    }
}

# ================================
# ğŸ“± æ±‚èŒå¹³å°æ•°æ®
# ================================

JOB_PLATFORMS = {
    "LinkedIn": {
        "ç±»å‹": "å›½é™…ä¸“ä¸šç¤¾äº¤",
        "ä¼˜åŠ¿": ["å…¨çƒèŒä½", "ä¸“ä¸šç½‘ç»œ", "è¡Œä¸šæ´å¯Ÿ"],
        "é€‚åˆäººç¾¤": ["å¤–ä¼", "æµ·å¤–å·¥ä½œ", "é«˜çº§èŒä½"],
        "ä½¿ç”¨æŠ€å·§": [
            "å®Œå–„ä¸ªäººèµ„æ–™",
            "ä¸»åŠ¨å»ºç«‹è¿æ¥",
            "å‘å¸ƒä¸“ä¸šå†…å®¹",
            "å‚ä¸è¡Œä¸šè®¨è®º"
        ]
    },
    "BOSSç›´è˜": {
        "ç±»å‹": "ç›´èŠæ‹›è˜",
        "ä¼˜åŠ¿": ["ç›´æ¥æ²Ÿé€š", "å“åº”å¿«é€Ÿ", "èŒä½ä¸°å¯Œ"],
        "é€‚åˆäººç¾¤": ["äº’è”ç½‘", "å¿«é€Ÿæ±‚èŒ", "ä¸­é«˜çº§èŒä½"],
        "ä½¿ç”¨æŠ€å·§": [
            "ä¼˜åŒ–ç®€å†å…³é”®è¯",
            "ä¸»åŠ¨æ‰“æ‹›å‘¼",
            "åŠæ—¶å›å¤æ¶ˆæ¯",
            "å±•ç¤ºä¸“ä¸šèƒ½åŠ›"
        ]
    },
    "æ‹‰å‹¾ç½‘": {
        "ç±»å‹": "äº’è”ç½‘ä¸“ä¸š",
        "ä¼˜åŠ¿": ["äº’è”ç½‘èŒä½", "è–ªèµ„é€æ˜", "å…¬å¸è¯¦æƒ…"],
        "é€‚åˆäººç¾¤": ["äº’è”ç½‘è¡Œä¸š", "æŠ€æœ¯å²—ä½"],
        "ä½¿ç”¨æŠ€å·§": [
            "çªå‡ºæŠ€æœ¯èƒ½åŠ›",
            "å…³æ³¨å…¬å¸åŠ¨æ€",
            "å‚ä¸æŠ€æœ¯åˆ†äº«"
        ]
    },
    "æ™ºè”æ‹›è˜": {
        "ç±»å‹": "ç»¼åˆæ‹›è˜",
        "ä¼˜åŠ¿": ["èŒä½å…¨é¢", "ä¼ ç»Ÿä¼ä¸šå¤š", "æœåŠ¡å®Œå–„"],
        "é€‚åˆäººç¾¤": ["ä¼ ç»Ÿè¡Œä¸š", "åº”å±Šç”Ÿ", "å…¨èŒä½ç±»å‹"],
        "ä½¿ç”¨æŠ€å·§": [
            "è¯¦ç»†å¡«å†™ç®€å†",
            "ä½¿ç”¨æ±‚èŒæ„å‘",
            "å…³æ³¨ä¼ä¸šå®£è®²"
        ]
    },
    "çŒè˜": {
        "ç±»å‹": "ä¸­é«˜ç«¯æ‹›è˜",
        "ä¼˜åŠ¿": ["é«˜ç«¯èŒä½", "çŒå¤´æœåŠ¡", "è–ªèµ„é«˜"],
        "é€‚åˆäººç¾¤": ["ç®¡ç†å²—ä½", "é«˜çº§æŠ€æœ¯", "è·³æ§½äººç¾¤"],
        "ä½¿ç”¨æŠ€å·§": [
            "å±•ç¤ºç®¡ç†ç»éªŒ",
            "çªå‡ºæ ¸å¿ƒæˆå°±",
            "ä¿æŒç®€å†æ›´æ–°"
        ]
    }
}

# ================================
# ğŸ“§ é‚®ä»¶æ¨¡æ¿åº“
# ================================

EMAIL_TEMPLATES = {
    "æ±‚èŒç”³è¯·": {
        "ä¸»é¢˜": "åº”è˜{èŒä½åç§°} - {å§“å}",
        "æ¨¡æ¿": """å°Šæ•¬çš„HR/æ‹›è˜è´Ÿè´£äººï¼š

æ‚¨å¥½ï¼æˆ‘æ˜¯{å§“å}ï¼Œå¯¹è´µå…¬å¸çš„{èŒä½åç§°}èŒä½éå¸¸æ„Ÿå…´è¶£ã€‚

ã€ä¸ªäººèƒŒæ™¯ã€‘
æˆ‘æœ‰{å·¥ä½œå¹´é™}å¹´çš„{ä¸“ä¸šé¢†åŸŸ}ç»éªŒï¼Œæ“…é•¿{æ ¸å¿ƒæŠ€èƒ½}ã€‚åœ¨ä¹‹å‰çš„å·¥ä½œä¸­ï¼Œæˆ‘{ä¸»è¦æˆå°±}ã€‚

ã€åŒ¹é…åº¦åˆ†æã€‘
æ ¹æ®èŒä½è¦æ±‚ï¼Œæˆ‘çš„ä¼˜åŠ¿åŒ…æ‹¬ï¼š
{åŒ¹é…ç‚¹åˆ—è¡¨}

ã€æœŸæœ›ã€‘
å¸Œæœ›èƒ½æœ‰æœºä¼šè¿›ä¸€æ­¥äº¤æµï¼Œæˆ‘çš„è”ç³»æ–¹å¼ï¼š{è”ç³»æ–¹å¼}

æœŸå¾…æ‚¨çš„å›å¤ï¼

æ­¤è‡´
æ•¬ç¤¼ï¼

{å§“å}
{æ—¥æœŸ}""",
        "å˜é‡": ["å§“å", "èŒä½åç§°", "å·¥ä½œå¹´é™", "ä¸“ä¸šé¢†åŸŸ", "æ ¸å¿ƒæŠ€èƒ½", "ä¸»è¦æˆå°±", "åŒ¹é…ç‚¹åˆ—è¡¨", "è”ç³»æ–¹å¼", "æ—¥æœŸ"]
    },
    
    "é¢è¯•æ„Ÿè°¢": {
        "ä¸»é¢˜": "æ„Ÿè°¢é¢è¯•æœºä¼š - {èŒä½åç§°} - {å§“å}",
        "æ¨¡æ¿": """å°Šæ•¬çš„{é¢è¯•å®˜å§“å}ï¼š

æ‚¨å¥½ï¼

æ„Ÿè°¢æ‚¨ä»Šå¤©æŠ½å‡ºå®è´µæ—¶é—´ä¸ºæˆ‘è¿›è¡Œ{èŒä½åç§°}çš„é¢è¯•ã€‚é€šè¿‡ä»Šå¤©çš„äº¤æµï¼Œæˆ‘å¯¹è´µå…¬å¸å’Œè¿™ä¸ªèŒä½æœ‰äº†æ›´æ·±å…¥çš„äº†è§£ã€‚

ã€é¢è¯•æ”¶è·ã€‘
{é¢è¯•æ”¶è·å†…å®¹}

ã€è¡¥å……è¯´æ˜ã€‘
å…³äºé¢è¯•ä¸­æåˆ°çš„{æŠ€æœ¯é—®é¢˜}ï¼Œæˆ‘æƒ³è¡¥å……è¯´æ˜ï¼š
{è¡¥å……å†…å®¹}

ã€å†æ¬¡è¡¨è¾¾å…´è¶£ã€‘
æˆ‘å¯¹åŠ å…¥è´µå…¬å¸å›¢é˜Ÿéå¸¸æœŸå¾…ï¼Œç›¸ä¿¡æˆ‘çš„{æ ¸å¿ƒä¼˜åŠ¿}èƒ½ä¸ºå›¢é˜Ÿå¸¦æ¥ä»·å€¼ã€‚

æœŸå¾…æ‚¨çš„å¥½æ¶ˆæ¯ï¼

æ­¤è‡´
æ•¬ç¤¼ï¼

{å§“å}
{è”ç³»æ–¹å¼}
{æ—¥æœŸ}""",
        "å˜é‡": ["é¢è¯•å®˜å§“å", "èŒä½åç§°", "å§“å", "é¢è¯•æ”¶è·å†…å®¹", "æŠ€æœ¯é—®é¢˜", "è¡¥å……å†…å®¹", "æ ¸å¿ƒä¼˜åŠ¿", "è”ç³»æ–¹å¼", "æ—¥æœŸ"]
    },
    
    "è–ªèµ„è°ˆåˆ¤": {
        "ä¸»é¢˜": "å…³äº{èŒä½åç§°}è–ªèµ„å¾…é‡çš„è®¨è®º - {å§“å}",
        "æ¨¡æ¿": """å°Šæ•¬çš„{HRå§“å}ï¼š

æ‚¨å¥½ï¼

éå¸¸æ„Ÿè°¢è´µå…¬å¸å¯¹æˆ‘çš„è®¤å¯ï¼Œæˆ‘å¯¹{èŒä½åç§°}è¿™ä¸ªæœºä¼šéå¸¸çæƒœã€‚

ã€å¸‚åœºè°ƒç ”ã€‘
æ ¹æ®æˆ‘çš„å¸‚åœºè°ƒç ”ï¼Œ{èŒä½åç§°}åœ¨{åŸå¸‚}çš„è–ªèµ„èŒƒå›´é€šå¸¸åœ¨{å¸‚åœºè–ªèµ„èŒƒå›´}ã€‚

ã€ä¸ªäººä»·å€¼ã€‘
åŸºäºæˆ‘çš„{æ ¸å¿ƒä¼˜åŠ¿}ï¼Œæˆ‘ç›¸ä¿¡èƒ½ä¸ºå…¬å¸åˆ›é€ {é¢„æœŸä»·å€¼}ã€‚

ã€æœŸæœ›è–ªèµ„ã€‘
ç»¼åˆè€ƒè™‘æˆ‘çš„ç»éªŒå’Œå¸‚åœºæƒ…å†µï¼Œæˆ‘çš„æœŸæœ›è–ªèµ„æ˜¯{æœŸæœ›è–ªèµ„}ã€‚

ã€çµæ´»æ€§ã€‘
æˆ‘ä¹Ÿç†è§£å…¬å¸çš„é¢„ç®—è€ƒè™‘ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨{å…¶ä»–ç¦åˆ©}æ–¹é¢è¿›è¡Œè®¨è®ºã€‚

æœŸå¾…è¿›ä¸€æ­¥æ²Ÿé€šï¼

æ­¤è‡´
æ•¬ç¤¼ï¼

{å§“å}
{è”ç³»æ–¹å¼}
{æ—¥æœŸ}""",
        "å˜é‡": ["HRå§“å", "èŒä½åç§°", "å§“å", "åŸå¸‚", "å¸‚åœºè–ªèµ„èŒƒå›´", "æ ¸å¿ƒä¼˜åŠ¿", "é¢„æœŸä»·å€¼", "æœŸæœ›è–ªèµ„", "å…¶ä»–ç¦åˆ©", "è”ç³»æ–¹å¼", "æ—¥æœŸ"]
    }
}

# ================================
# ğŸ“… é¢è¯•ç®¡ç†æ•°æ®
# ================================

INTERVIEW_TYPES = {
    "ç”µè¯é¢è¯•": {
        "æ—¶é•¿": "30-45åˆ†é’Ÿ",
        "å‡†å¤‡è¦ç‚¹": ["ç®€å†ç†Ÿæ‚‰", "åŸºç¡€é—®é¢˜", "è¯­è¨€è¡¨è¾¾"],
        "å¸¸è§é—®é¢˜": [
            "è‡ªæˆ‘ä»‹ç»",
            "ä¸ºä»€ä¹ˆé€‰æ‹©æˆ‘ä»¬å…¬å¸",
            "èŒä¸šè§„åˆ’",
            "è–ªèµ„æœŸæœ›"
        ]
    },
    "æŠ€æœ¯é¢è¯•": {
        "æ—¶é•¿": "60-90åˆ†é’Ÿ",
        "å‡†å¤‡è¦ç‚¹": ["æŠ€æœ¯æ ˆå¤ä¹ ", "é¡¹ç›®ç»éªŒ", "ç®—æ³•ç»ƒä¹ "],
        "å¸¸è§é—®é¢˜": [
            "æŠ€æœ¯æ ˆæ·±åº¦é—®é¢˜",
            "é¡¹ç›®æ¶æ„è®¾è®¡",
            "ä»£ç å®ç°",
            "æ€§èƒ½ä¼˜åŒ–"
        ]
    },
    "HRé¢è¯•": {
        "æ—¶é•¿": "30-60åˆ†é’Ÿ",
        "å‡†å¤‡è¦ç‚¹": ["å…¬å¸äº†è§£", "æ–‡åŒ–åŒ¹é…", "è½¯æŠ€èƒ½"],
        "å¸¸è§é—®é¢˜": [
            "å›¢é˜Ÿåˆä½œç»éªŒ",
            "å‹åŠ›å¤„ç†èƒ½åŠ›",
            "å­¦ä¹ èƒ½åŠ›",
            "èŒä¸šç¨³å®šæ€§"
        ]
    },
    "ç»ˆé¢": {
        "æ—¶é•¿": "45-90åˆ†é’Ÿ",
        "å‡†å¤‡è¦ç‚¹": ["ç»¼åˆèƒ½åŠ›", "é¢†å¯¼åŠ›", "æˆ˜ç•¥æ€ç»´"],
        "å¸¸è§é—®é¢˜": [
            "ç®¡ç†ç»éªŒ",
            "å†³ç­–èƒ½åŠ›",
            "åˆ›æ–°æ€ç»´",
            "é•¿æœŸè§„åˆ’"
        ]
    }
}

# ================================
# ğŸ”— å¹³å°é›†æˆåˆ†æç±»
# ================================

class PlatformIntegrator:
    def __init__(self):
        self.platforms = JOB_PLATFORMS
        self.email_templates = EMAIL_TEMPLATES
        self.interview_types = INTERVIEW_TYPES
        self.linkedin_rules = LINKEDIN_OPTIMIZATION_RULES
    
    def analyze_linkedin_profile(self, profile_data: Dict) -> Dict:
        """åˆ†æLinkedInä¸ªäººèµ„æ–™"""
        analysis = {
            "ä¼˜åŒ–å»ºè®®": [],
            "è¯„åˆ†": {},
            "å…³é”®è¯åˆ†æ": {},
            "æ”¹è¿›æ–¹æ¡ˆ": {}
        }
        
        # åˆ†ææ ‡é¢˜
        headline = profile_data.get("headline", "")
        headline_score = self._analyze_headline(headline)
        analysis["è¯„åˆ†"]["æ ‡é¢˜"] = headline_score
        
        # åˆ†ææ‘˜è¦
        summary = profile_data.get("summary", "")
        summary_score = self._analyze_summary(summary)
        analysis["è¯„åˆ†"]["æ‘˜è¦"] = summary_score
        
        # åˆ†ææŠ€èƒ½
        skills = profile_data.get("skills", [])
        skills_analysis = self._analyze_skills(skills)
        analysis["å…³é”®è¯åˆ†æ"] = skills_analysis
        
        # ç”Ÿæˆä¼˜åŒ–å»ºè®®
        analysis["ä¼˜åŒ–å»ºè®®"] = self._generate_linkedin_suggestions(
            headline_score, summary_score, skills_analysis
        )
        
        # æ”¹è¿›æ–¹æ¡ˆ
        analysis["æ”¹è¿›æ–¹æ¡ˆ"] = self._create_improvement_plan(profile_data)
        
        return analysis
    
    def track_job_applications(self, applications: List[Dict]) -> Dict:
        """è¿½è¸ªæ±‚èŒç”³è¯·è¿›åº¦"""
        tracking = {
            "æ€»ä½“ç»Ÿè®¡": {},
            "å¹³å°åˆ†æ": {},
            "çŠ¶æ€åˆ†å¸ƒ": {},
            "æ—¶é—´çº¿": [],
            "å»ºè®®": []
        }
        
        # æ€»ä½“ç»Ÿè®¡
        total_apps = len(applications)
        platforms_used = set(app.get("platform", "æœªçŸ¥") for app in applications)
        
        tracking["æ€»ä½“ç»Ÿè®¡"] = {
            "æ€»ç”³è¯·æ•°": total_apps,
            "ä½¿ç”¨å¹³å°": list(platforms_used),
            "å¹³å‡å“åº”ç‡": self._calculate_response_rate(applications),
            "é¢è¯•è½¬åŒ–ç‡": self._calculate_interview_rate(applications)
        }
        
        # å¹³å°åˆ†æ
        platform_stats = defaultdict(list)
        for app in applications:
            platform = app.get("platform", "æœªçŸ¥")
            platform_stats[platform].append(app)
        
        for platform, apps in platform_stats.items():
            tracking["å¹³å°åˆ†æ"][platform] = {
                "ç”³è¯·æ•°é‡": len(apps),
                "å“åº”æ•°é‡": len([a for a in apps if a.get("status") != "å·²æŠ•é€’"]),
                "é¢è¯•æ•°é‡": len([a for a in apps if "é¢è¯•" in a.get("status", "")]),
                "æˆåŠŸç‡": self._calculate_platform_success_rate(apps)
            }
        
        # çŠ¶æ€åˆ†å¸ƒ
        status_count = defaultdict(int)
        for app in applications:
            status_count[app.get("status", "æœªçŸ¥")] += 1
        tracking["çŠ¶æ€åˆ†å¸ƒ"] = dict(status_count)
        
        # ç”Ÿæˆå»ºè®®
        tracking["å»ºè®®"] = self._generate_tracking_suggestions(tracking)
        
        return tracking
    
    def generate_email(self, template_type: str, variables: Dict) -> Dict:
        """ç”Ÿæˆé‚®ä»¶å†…å®¹"""
        if template_type not in self.email_templates:
            return {"é”™è¯¯": f"ä¸æ”¯æŒçš„é‚®ä»¶ç±»å‹: {template_type}"}
        
        template = self.email_templates[template_type]
        
        # æ£€æŸ¥å¿…éœ€å˜é‡
        missing_vars = []
        for var in template["å˜é‡"]:
            if var not in variables:
                missing_vars.append(var)
        
        if missing_vars:
            return {
                "é”™è¯¯": "ç¼ºå°‘å¿…éœ€å˜é‡",
                "ç¼ºå°‘å˜é‡": missing_vars,
                "æ‰€éœ€å˜é‡": template["å˜é‡"]
            }
        
        # ç”Ÿæˆé‚®ä»¶å†…å®¹
        subject = template["ä¸»é¢˜"].format(**variables)
        content = template["æ¨¡æ¿"].format(**variables)
        
        return {
            "é‚®ä»¶ç±»å‹": template_type,
            "ä¸»é¢˜": subject,
            "å†…å®¹": content,
            "ä¼˜åŒ–å»ºè®®": self._get_email_optimization_tips(template_type)
        }
    
    def manage_interview_schedule(self, interviews: List[Dict]) -> Dict:
        """ç®¡ç†é¢è¯•æ—¥ç¨‹"""
        schedule = {
            "å³å°†é¢è¯•": [],
            "é¢è¯•å‡†å¤‡": {},
            "æ—¶é—´å†²çª": [],
            "å‡†å¤‡å»ºè®®": []
        }
        
        now = datetime.now()
        
        for interview in interviews:
            interview_time = datetime.fromisoformat(interview.get("time", now.isoformat()))
            time_diff = interview_time - now
            
            # å³å°†é¢è¯•ï¼ˆ7å¤©å†…ï¼‰
            if 0 <= time_diff.days <= 7:
                schedule["å³å°†é¢è¯•"].append({
                    "å…¬å¸": interview.get("company", ""),
                    "èŒä½": interview.get("position", ""),
                    "æ—¶é—´": interview.get("time", ""),
                    "ç±»å‹": interview.get("type", ""),
                    "å‰©ä½™å¤©æ•°": time_diff.days
                })
        
        # æŒ‰æ—¶é—´æ’åº
        schedule["å³å°†é¢è¯•"].sort(key=lambda x: x["å‰©ä½™å¤©æ•°"])
        
        # é¢è¯•å‡†å¤‡å»ºè®®
        for interview in schedule["å³å°†é¢è¯•"]:
            interview_type = interview["ç±»å‹"]
            if interview_type in self.interview_types:
                schedule["é¢è¯•å‡†å¤‡"][interview["å…¬å¸"]] = {
                    "å‡†å¤‡è¦ç‚¹": self.interview_types[interview_type]["å‡†å¤‡è¦ç‚¹"],
                    "å¸¸è§é—®é¢˜": self.interview_types[interview_type]["å¸¸è§é—®é¢˜"],
                    "å»ºè®®æ—¶é•¿": self.interview_types[interview_type]["æ—¶é•¿"]
                }
        
        # æ£€æŸ¥æ—¶é—´å†²çª
        schedule["æ—¶é—´å†²çª"] = self._check_time_conflicts(interviews)
        
        # ç”Ÿæˆå‡†å¤‡å»ºè®®
        schedule["å‡†å¤‡å»ºè®®"] = self._generate_interview_prep_advice(schedule["å³å°†é¢è¯•"])
        
        return schedule
    
    def analyze_job_market_trends(self, job_data: List[Dict]) -> Dict:
        """åˆ†æèŒä½å¸‚åœºè¶‹åŠ¿"""
        trends = {
            "çƒ­é—¨æŠ€èƒ½": {},
            "è–ªèµ„è¶‹åŠ¿": {},
            "å…¬å¸ç±»å‹": {},
            "åœ°åŒºåˆ†å¸ƒ": {},
            "è¡Œä¸šåˆ†æ": {},
            "æŠ€èƒ½ç»„åˆ": {},
            "å¢é•¿è¶‹åŠ¿": {}
        }
        
        # æŠ€èƒ½ç»Ÿè®¡
        skill_count = defaultdict(int)
        salary_by_skill = defaultdict(list)
        company_types = defaultdict(int)
        locations = defaultdict(int)
        industries = defaultdict(int)
        skill_combinations = defaultdict(int)
        
        for job in job_data:
            skills = job.get("required_skills", [])
            salary = job.get("salary", 0)
            company_type = job.get("company_type", "æœªçŸ¥")
            location = job.get("location", "æœªçŸ¥")
            industry = job.get("industry", "æœªçŸ¥")
            
            # æŠ€èƒ½ç»Ÿè®¡
            for skill in skills:
                skill_count[skill] += 1
                if salary > 0:
                    salary_by_skill[skill].append(salary)
            
            # æŠ€èƒ½ç»„åˆåˆ†æï¼ˆ2-3ä¸ªæŠ€èƒ½çš„ç»„åˆï¼‰
            if len(skills) >= 2:
                for i in range(len(skills)):
                    for j in range(i+1, len(skills)):
                        combo = f"{skills[i]}+{skills[j]}"
                        skill_combinations[combo] += 1
            
            # å…¶ä»–ç»´åº¦ç»Ÿè®¡
            company_types[company_type] += 1
            locations[location] += 1
            industries[industry] += 1
        
        # çƒ­é—¨æŠ€èƒ½æ’è¡Œ
        trends["çƒ­é—¨æŠ€èƒ½"] = dict(sorted(skill_count.items(), key=lambda x: x[1], reverse=True)[:10])
        
        # è–ªèµ„è¶‹åŠ¿
        for skill, salaries in salary_by_skill.items():
            if len(salaries) >= 2:  # é™ä½é—¨æ§›åˆ°2ä¸ªæ•°æ®ç‚¹
                trends["è–ªèµ„è¶‹åŠ¿"][skill] = {
                    "å¹³å‡è–ªèµ„": round(sum(salaries) / len(salaries), 0),
                    "æœ€é«˜è–ªèµ„": max(salaries),
                    "æœ€ä½è–ªèµ„": min(salaries),
                    "èŒä½æ•°é‡": len(salaries),
                    "è–ªèµ„ä¸­ä½æ•°": sorted(salaries)[len(salaries)//2]
                }
        
        # å…¬å¸ç±»å‹åˆ†å¸ƒ
        trends["å…¬å¸ç±»å‹"] = dict(sorted(company_types.items(), key=lambda x: x[1], reverse=True)[:5])
        
        # åœ°åŒºåˆ†å¸ƒ
        trends["åœ°åŒºåˆ†å¸ƒ"] = dict(sorted(locations.items(), key=lambda x: x[1], reverse=True)[:5])
        
        # è¡Œä¸šåˆ†æ
        trends["è¡Œä¸šåˆ†æ"] = dict(sorted(industries.items(), key=lambda x: x[1], reverse=True)[:5])
        
        # æŠ€èƒ½ç»„åˆåˆ†æ
        trends["æŠ€èƒ½ç»„åˆ"] = dict(sorted(skill_combinations.items(), key=lambda x: x[1], reverse=True)[:5])
        
        # å¢é•¿è¶‹åŠ¿é¢„æµ‹ï¼ˆåŸºäºæŠ€èƒ½çƒ­åº¦ï¼‰
        trends["å¢é•¿è¶‹åŠ¿"] = self._predict_skill_growth(skill_count)
        
        return trends
    
    def generate_resume_optimization_report(self, resume_data: Dict, target_jobs: List[Dict]) -> Dict:
        """ç”Ÿæˆç®€å†ä¼˜åŒ–æŠ¥å‘Š"""
        report = {
            "åŒ¹é…åº¦åˆ†æ": {},
            "æŠ€èƒ½å·®è·": {},
            "å…³é”®è¯ä¼˜åŒ–": {},
            "ç»“æ„å»ºè®®": {},
            "è¡ŒåŠ¨è®¡åˆ’": {}
        }
        
        # æå–ç®€å†æŠ€èƒ½
        resume_skills = set(resume_data.get("skills", []))
        
        # åˆ†æç›®æ ‡èŒä½è¦æ±‚
        required_skills = set()
        preferred_skills = set()
        
        for job in target_jobs:
            required_skills.update(job.get("required_skills", []))
            preferred_skills.update(job.get("preferred_skills", []))
        
        # åŒ¹é…åº¦åˆ†æ
        matched_skills = resume_skills & required_skills
        missing_skills = required_skills - resume_skills
        extra_skills = resume_skills - required_skills
        
        report["åŒ¹é…åº¦åˆ†æ"] = {
            "æ€»ä½“åŒ¹é…åº¦": round(len(matched_skills) / len(required_skills) * 100, 1) if required_skills else 0,
            "åŒ¹é…æŠ€èƒ½": list(matched_skills),
            "ç¼ºå¤±æŠ€èƒ½": list(missing_skills),
            "é¢å¤–æŠ€èƒ½": list(extra_skills),
            "ä¼˜åŠ¿æŠ€èƒ½": list(resume_skills & preferred_skills)
        }
        
        # æŠ€èƒ½å·®è·åˆ†æ
        report["æŠ€èƒ½å·®è·"] = self._analyze_skill_gaps(missing_skills, target_jobs)
        
        # å…³é”®è¯ä¼˜åŒ–
        report["å…³é”®è¯ä¼˜åŒ–"] = self._generate_keyword_suggestions(resume_data, target_jobs)
        
        # ç»“æ„å»ºè®®
        report["ç»“æ„å»ºè®®"] = self._analyze_resume_structure(resume_data)
        
        # è¡ŒåŠ¨è®¡åˆ’
        report["è¡ŒåŠ¨è®¡åˆ’"] = self._create_resume_action_plan(report)
        
        return report
    
    def analyze_platform_effectiveness(self, application_history: List[Dict]) -> Dict:
        """åˆ†æå„å¹³å°æ±‚èŒæ•ˆæœ"""
        effectiveness = {
            "å¹³å°æ’å": {},
            "æœ€ä½³æŠ•é€’æ—¶é—´": {},
            "æˆåŠŸæ¨¡å¼": {},
            "ä¼˜åŒ–å»ºè®®": {}
        }
        
        platform_stats = defaultdict(lambda: {
            "æ€»æŠ•é€’": 0,
            "æŸ¥çœ‹ç‡": 0,
            "å›å¤ç‡": 0,
            "é¢è¯•ç‡": 0,
            "æˆåŠŸç‡": 0,
            "å¹³å‡å“åº”æ—¶é—´": []
        })
        
        for app in application_history:
            platform = app.get("platform", "æœªçŸ¥")
            status = app.get("status", "å·²æŠ•é€’")
            response_time = app.get("response_time_hours", 0)
            
            stats = platform_stats[platform]
            stats["æ€»æŠ•é€’"] += 1
            
            if status != "å·²æŠ•é€’":
                stats["æŸ¥çœ‹ç‡"] += 1
                if response_time > 0:
                    stats["å¹³å‡å“åº”æ—¶é—´"].append(response_time)
            
            if status in ["å·²å›å¤", "é¢è¯•é‚€è¯·", "æŠ€æœ¯é¢è¯•", "HRé¢è¯•", "ç»ˆé¢"]:
                stats["å›å¤ç‡"] += 1
            
            if "é¢è¯•" in status:
                stats["é¢è¯•ç‡"] += 1
            
            if status in ["å·²å½•ç”¨", "å¾…å…¥èŒ"]:
                stats["æˆåŠŸç‡"] += 1
        
        # è®¡ç®—å„å¹³å°æ•ˆæœè¯„åˆ†
        for platform, stats in platform_stats.items():
            if stats["æ€»æŠ•é€’"] > 0:
                æŸ¥çœ‹ç‡ = stats["æŸ¥çœ‹ç‡"] / stats["æ€»æŠ•é€’"]
                å›å¤ç‡ = stats["å›å¤ç‡"] / stats["æ€»æŠ•é€’"]
                é¢è¯•ç‡ = stats["é¢è¯•ç‡"] / stats["æ€»æŠ•é€’"]
                æˆåŠŸç‡ = stats["æˆåŠŸç‡"] / stats["æ€»æŠ•é€’"]
                
                # ç»¼åˆè¯„åˆ†ï¼ˆæƒé‡ï¼šæˆåŠŸç‡40%ï¼Œé¢è¯•ç‡30%ï¼Œå›å¤ç‡20%ï¼ŒæŸ¥çœ‹ç‡10%ï¼‰
                ç»¼åˆè¯„åˆ† = (æˆåŠŸç‡ * 0.4 + é¢è¯•ç‡ * 0.3 + å›å¤ç‡ * 0.2 + æŸ¥çœ‹ç‡ * 0.1) * 100
                
                effectiveness["å¹³å°æ’å"][platform] = {
                    "ç»¼åˆè¯„åˆ†": round(ç»¼åˆè¯„åˆ†, 1),
                    "æŸ¥çœ‹ç‡": round(æŸ¥çœ‹ç‡ * 100, 1),
                    "å›å¤ç‡": round(å›å¤ç‡ * 100, 1),
                    "é¢è¯•ç‡": round(é¢è¯•ç‡ * 100, 1),
                    "æˆåŠŸç‡": round(æˆåŠŸç‡ * 100, 1),
                    "å¹³å‡å“åº”æ—¶é—´": round(sum(stats["å¹³å‡å“åº”æ—¶é—´"]) / len(stats["å¹³å‡å“åº”æ—¶é—´"]), 1) if stats["å¹³å‡å“åº”æ—¶é—´"] else 0
                }
        
        # åˆ†ææœ€ä½³æŠ•é€’æ—¶é—´
        effectiveness["æœ€ä½³æŠ•é€’æ—¶é—´"] = self._analyze_best_application_time(application_history)
        
        # è¯†åˆ«æˆåŠŸæ¨¡å¼
        effectiveness["æˆåŠŸæ¨¡å¼"] = self._identify_success_patterns(application_history)
        
        # ç”Ÿæˆä¼˜åŒ–å»ºè®®
        effectiveness["ä¼˜åŒ–å»ºè®®"] = self._generate_platform_optimization_advice(effectiveness)
        
        return effectiveness
    
    def _analyze_headline(self, headline: str) -> Dict:
        """åˆ†æLinkedInæ ‡é¢˜"""
        rules = self.linkedin_rules["æ ‡é¢˜ä¼˜åŒ–"]
        score = 0
        feedback = []
        
        # é•¿åº¦æ£€æŸ¥
        if rules["é•¿åº¦"][0] <= len(headline) <= rules["é•¿åº¦"][1]:
            score += 25
        else:
            feedback.append(f"æ ‡é¢˜é•¿åº¦å»ºè®®åœ¨{rules['é•¿åº¦'][0]}-{rules['é•¿åº¦'][1]}å­—ç¬¦ä¹‹é—´")
        
        # å…³é”®è¯æ£€æŸ¥
        keyword_count = sum(1 for keyword in rules["å…³é”®è¯"] if keyword.lower() in headline.lower())
        if keyword_count > 0:
            score += min(keyword_count * 15, 50)
        else:
            feedback.append("å»ºè®®åŒ…å«ç›¸å…³æŠ€æœ¯å…³é”®è¯")
        
        # æ ¼å¼æ£€æŸ¥
        if "|" in headline or "Â·" in headline:
            score += 25
        else:
            feedback.append("å»ºè®®ä½¿ç”¨åˆ†éš”ç¬¦ç»„ç»‡å†…å®¹ç»“æ„")
        
        return {"è¯„åˆ†": score, "åé¦ˆ": feedback}
    
    def _analyze_summary(self, summary: str) -> Dict:
        """åˆ†æLinkedInæ‘˜è¦"""
        rules = self.linkedin_rules["æ‘˜è¦ä¼˜åŒ–"]
        score = 0
        feedback = []
        
        # é•¿åº¦æ£€æŸ¥
        if rules["é•¿åº¦"][0] <= len(summary) <= rules["é•¿åº¦"][1]:
            score += 30
        else:
            feedback.append(f"æ‘˜è¦é•¿åº¦å»ºè®®åœ¨{rules['é•¿åº¦'][0]}-{rules['é•¿åº¦'][1]}å­—ç¬¦ä¹‹é—´")
        
        # å…³é”®å…ƒç´ æ£€æŸ¥
        elements_found = 0
        for element in rules["å…³é”®å…ƒç´ "]:
            if any(keyword in summary for keyword in [element, element.lower()]):
                elements_found += 1
        
        score += min(elements_found * 17, 70)
        
        if elements_found < len(rules["å…³é”®å…ƒç´ "]):
            feedback.append("å»ºè®®åŒ…å«æ›´å¤šå…³é”®å…ƒç´ ï¼šé‡åŒ–æˆæœã€æŠ€æœ¯æ ˆã€è¡Œä¸šç»éªŒç­‰")
        
        return {"è¯„åˆ†": score, "åé¦ˆ": feedback}
    
    def _analyze_skills(self, skills: List[str]) -> Dict:
        """åˆ†ææŠ€èƒ½æ ‡ç­¾"""
        rules = self.linkedin_rules["æŠ€èƒ½æ ‡ç­¾"]
        
        hot_skills = [s for s in skills if s in rules["çƒ­é—¨æŠ€èƒ½"]]
        emerging_skills = [s for s in skills if s in rules["æ–°å…´æŠ€èƒ½"]]
        
        return {
            "æ€»æŠ€èƒ½æ•°": len(skills),
            "çƒ­é—¨æŠ€èƒ½": hot_skills,
            "æ–°å…´æŠ€èƒ½": emerging_skills,
            "çƒ­é—¨æŠ€èƒ½å æ¯”": len(hot_skills) / len(skills) if skills else 0,
            "å»ºè®®æ·»åŠ ": [s for s in rules["çƒ­é—¨æŠ€èƒ½"] if s not in skills][:5]
        }
    
    def _generate_linkedin_suggestions(self, headline_score: Dict, summary_score: Dict, skills_analysis: Dict) -> List[str]:
        """ç”ŸæˆLinkedInä¼˜åŒ–å»ºè®®"""
        suggestions = []
        
        if headline_score["è¯„åˆ†"] < 70:
            suggestions.append("ä¼˜åŒ–ä¸ªäººæ ‡é¢˜ï¼Œå¢åŠ å…³é”®è¯å’Œä¸“ä¸šæè¿°")
        
        if summary_score["è¯„åˆ†"] < 70:
            suggestions.append("å®Œå–„ä¸ªäººæ‘˜è¦ï¼Œçªå‡ºæ ¸å¿ƒæŠ€èƒ½å’Œæˆå°±")
        
        if skills_analysis["çƒ­é—¨æŠ€èƒ½å æ¯”"] < 0.3:
            suggestions.append("å¢åŠ æ›´å¤šçƒ­é—¨æŠ€èƒ½æ ‡ç­¾")
        
        if len(skills_analysis["æ–°å…´æŠ€èƒ½"]) == 0:
            suggestions.append("å…³æ³¨æ–°å…´æŠ€æœ¯ï¼Œæ·»åŠ å‰æ²¿æŠ€èƒ½")
        
        return suggestions
    
    def _create_improvement_plan(self, profile_data: Dict) -> Dict:
        """åˆ›å»ºæ”¹è¿›è®¡åˆ’"""
        plan = {
            "çŸ­æœŸç›®æ ‡ï¼ˆ1å‘¨å†…ï¼‰": [
                "ä¼˜åŒ–ä¸ªäººæ ‡é¢˜",
                "æ›´æ–°æŠ€èƒ½æ ‡ç­¾",
                "å®Œå–„è”ç³»ä¿¡æ¯"
            ],
            "ä¸­æœŸç›®æ ‡ï¼ˆ1ä¸ªæœˆå†…ï¼‰": [
                "é‡å†™ä¸ªäººæ‘˜è¦",
                "æ·»åŠ é¡¹ç›®ç»å†",
                "å‘å¸ƒä¸“ä¸šå†…å®¹"
            ],
            "é•¿æœŸç›®æ ‡ï¼ˆ3ä¸ªæœˆå†…ï¼‰": [
                "å»ºç«‹è¡Œä¸šè¿æ¥",
                "å‚ä¸ä¸“ä¸šè®¨è®º",
                "è·å¾—æŠ€èƒ½è®¤è¯"
            ]
        }
        
        return plan
    
    def _calculate_response_rate(self, applications: List[Dict]) -> float:
        """è®¡ç®—å“åº”ç‡"""
        total = len(applications)
        if total == 0:
            return 0.0
        
        responded = len([app for app in applications if app.get("status") != "å·²æŠ•é€’"])
        return round(responded / total * 100, 1)
    
    def _calculate_interview_rate(self, applications: List[Dict]) -> float:
        """è®¡ç®—é¢è¯•è½¬åŒ–ç‡"""
        total = len(applications)
        if total == 0:
            return 0.0
        
        interviews = len([app for app in applications if "é¢è¯•" in app.get("status", "")])
        return round(interviews / total * 100, 1)
    
    def _calculate_platform_success_rate(self, apps: List[Dict]) -> float:
        """è®¡ç®—å¹³å°æˆåŠŸç‡"""
        if not apps:
            return 0.0
        
        success = len([app for app in apps if app.get("status") in ["å·²å½•ç”¨", "å¾…å…¥èŒ"]])
        return round(success / len(apps) * 100, 1)
    
    def _generate_tracking_suggestions(self, tracking: Dict) -> List[str]:
        """ç”Ÿæˆè¿½è¸ªå»ºè®®"""
        suggestions = []
        
        response_rate = tracking["æ€»ä½“ç»Ÿè®¡"]["å¹³å‡å“åº”ç‡"]
        if response_rate < 20:
            suggestions.append("å“åº”ç‡è¾ƒä½ï¼Œå»ºè®®ä¼˜åŒ–ç®€å†å’Œæ±‚èŒä¿¡")
        
        interview_rate = tracking["æ€»ä½“ç»Ÿè®¡"]["é¢è¯•è½¬åŒ–ç‡"]
        if interview_rate < 10:
            suggestions.append("é¢è¯•è½¬åŒ–ç‡åä½ï¼Œå»ºè®®æå‡ä¸ªäººæŠ€èƒ½å±•ç¤º")
        
        platforms_count = len(tracking["æ€»ä½“ç»Ÿè®¡"]["ä½¿ç”¨å¹³å°"])
        if platforms_count < 3:
            suggestions.append("å»ºè®®ä½¿ç”¨æ›´å¤šæ±‚èŒå¹³å°ï¼Œå¢åŠ æœºä¼š")
        
        return suggestions
    
    def _get_email_optimization_tips(self, template_type: str) -> List[str]:
        """è·å–é‚®ä»¶ä¼˜åŒ–å»ºè®®"""
        tips = {
            "æ±‚èŒç”³è¯·": [
                "ä¸»é¢˜è¡Œè¦ç®€æ´æ˜äº†",
                "çªå‡ºä¸èŒä½çš„åŒ¹é…åº¦",
                "é‡åŒ–ä¸ªäººæˆå°±",
                "ä¿æŒä¸“ä¸šè¯­è°ƒ"
            ],
            "é¢è¯•æ„Ÿè°¢": [
                "24å°æ—¶å†…å‘é€",
                "æåŠå…·ä½“é¢è¯•å†…å®¹",
                "è¡¥å……é—æ¼ä¿¡æ¯",
                "å†æ¬¡è¡¨è¾¾å…´è¶£"
            ],
            "è–ªèµ„è°ˆåˆ¤": [
                "åŸºäºå¸‚åœºæ•°æ®",
                "å¼ºè°ƒä¸ªäººä»·å€¼",
                "ä¿æŒçµæ´»æ€§",
                "ä¸“ä¸šç¤¼è²Œ"
            ]
        }
        
        return tips.get(template_type, ["ä¿æŒä¸“ä¸š", "å†…å®¹ç®€æ´", "é€»è¾‘æ¸…æ™°"])
    
    def _check_time_conflicts(self, interviews: List[Dict]) -> List[Dict]:
        """æ£€æŸ¥æ—¶é—´å†²çª"""
        conflicts = []
        
        for i, interview1 in enumerate(interviews):
            for j, interview2 in enumerate(interviews[i+1:], i+1):
                time1 = datetime.fromisoformat(interview1.get("time", ""))
                time2 = datetime.fromisoformat(interview2.get("time", ""))
                
                # æ£€æŸ¥æ˜¯å¦åœ¨åŒä¸€å¤©çš„2å°æ—¶å†…
                if abs((time1 - time2).total_seconds()) < 7200:  # 2å°æ—¶
                    conflicts.append({
                        "å†²çªé¢è¯•": [
                            f"{interview1.get('company')} - {interview1.get('time')}",
                            f"{interview2.get('company')} - {interview2.get('time')}"
                        ]
                    })
        
        return conflicts
    
    def _generate_interview_prep_advice(self, upcoming_interviews: List[Dict]) -> List[str]:
        """ç”Ÿæˆé¢è¯•å‡†å¤‡å»ºè®®"""
        advice = []
        
        if not upcoming_interviews:
            return ["æš‚æ— å³å°†åˆ°æ¥çš„é¢è¯•"]
        
        # æŒ‰å‰©ä½™å¤©æ•°ç»™å»ºè®®
        for interview in upcoming_interviews[:3]:  # åªçœ‹æœ€è¿‘3ä¸ª
            days_left = interview["å‰©ä½™å¤©æ•°"]
            company = interview["å…¬å¸"]
            
            if days_left == 0:
                advice.append(f"ä»Šå¤©é¢è¯•{company}ï¼Œç¡®è®¤æ—¶é—´åœ°ç‚¹ï¼Œå‡†å¤‡ç›¸å…³ææ–™")
            elif days_left == 1:
                advice.append(f"æ˜å¤©é¢è¯•{company}ï¼Œæœ€åæ£€æŸ¥ç®€å†ï¼Œå‡†å¤‡å¸¸è§é—®é¢˜")
            elif days_left <= 3:
                advice.append(f"{days_left}å¤©åé¢è¯•{company}ï¼Œæ·±å…¥äº†è§£å…¬å¸å’ŒèŒä½")
            else:
                advice.append(f"{days_left}å¤©åé¢è¯•{company}ï¼Œå¼€å§‹å‡†å¤‡æŠ€æœ¯å¤ä¹ ")
        
        return advice
    
    def _predict_skill_growth(self, skill_count: Dict) -> Dict:
        """é¢„æµ‹æŠ€èƒ½å¢é•¿è¶‹åŠ¿"""
        # åŸºäºå½“å‰çƒ­åº¦å’ŒæŠ€æœ¯å‘å±•è¶‹åŠ¿é¢„æµ‹
        growth_predictions = {}
        
        # å®šä¹‰æŠ€æœ¯å‘å±•è¶‹åŠ¿æƒé‡
        tech_trends = {
            "AI": 1.5, "æœºå™¨å­¦ä¹ ": 1.4, "æ·±åº¦å­¦ä¹ ": 1.3,
            "äº‘è®¡ç®—": 1.3, "Docker": 1.2, "Kubernetes": 1.2,
            "React": 1.1, "Vue": 1.1, "TypeScript": 1.2,
            "Python": 1.1, "Go": 1.3, "Rust": 1.4,
            "åŒºå—é“¾": 1.2, "Web3": 1.3
        }
        
        for skill, count in skill_count.items():
            trend_weight = tech_trends.get(skill, 1.0)
            predicted_growth = round((count * trend_weight - count) / count * 100, 1) if count > 0 else 0
            
            growth_predictions[skill] = {
                "å½“å‰çƒ­åº¦": count,
                "é¢„æµ‹å¢é•¿ç‡": f"{predicted_growth}%",
                "è¶‹åŠ¿": "ä¸Šå‡" if predicted_growth > 10 else "ç¨³å®š" if predicted_growth > -5 else "ä¸‹é™"
            }
        
        # åªè¿”å›æœ‰å¢é•¿æ½œåŠ›çš„æŠ€èƒ½
        return {k: v for k, v in growth_predictions.items() if v["é¢„æµ‹å¢é•¿ç‡"] != "0.0%"}
    
    def _analyze_skill_gaps(self, missing_skills: set, target_jobs: List[Dict]) -> Dict:
        """åˆ†ææŠ€èƒ½å·®è·"""
        gap_analysis = {
            "å…³é”®æŠ€èƒ½": [],
            "å¯é€‰æŠ€èƒ½": [],
            "å­¦ä¹ ä¼˜å…ˆçº§": {},
            "å­¦ä¹ å»ºè®®": {}
        }
        
        # ç»Ÿè®¡æŠ€èƒ½åœ¨ç›®æ ‡èŒä½ä¸­çš„å‡ºç°é¢‘ç‡
        skill_frequency = defaultdict(int)
        for job in target_jobs:
            for skill in job.get("required_skills", []):
                if skill in missing_skills:
                    skill_frequency[skill] += 1
        
        total_jobs = len(target_jobs)
        
        for skill, freq in skill_frequency.items():
            frequency_rate = freq / total_jobs
            
            if frequency_rate >= 0.7:  # 70%ä»¥ä¸ŠèŒä½è¦æ±‚
                gap_analysis["å…³é”®æŠ€èƒ½"].append(skill)
                gap_analysis["å­¦ä¹ ä¼˜å…ˆçº§"][skill] = "é«˜"
            elif frequency_rate >= 0.3:  # 30-70%èŒä½è¦æ±‚
                gap_analysis["å¯é€‰æŠ€èƒ½"].append(skill)
                gap_analysis["å­¦ä¹ ä¼˜å…ˆçº§"][skill] = "ä¸­"
            else:
                gap_analysis["å­¦ä¹ ä¼˜å…ˆçº§"][skill] = "ä½"
        
        # ç”Ÿæˆå­¦ä¹ å»ºè®®
        for skill in gap_analysis["å…³é”®æŠ€èƒ½"]:
            gap_analysis["å­¦ä¹ å»ºè®®"][skill] = self._get_learning_suggestion(skill)
        
        return gap_analysis
    
    def _generate_keyword_suggestions(self, resume_data: Dict, target_jobs: List[Dict]) -> Dict:
        """ç”Ÿæˆå…³é”®è¯ä¼˜åŒ–å»ºè®®"""
        suggestions = {
            "ç¼ºå¤±å…³é”®è¯": [],
            "ä¼˜åŒ–å»ºè®®": [],
            "è¡Œä¸šæœ¯è¯­": [],
            "æŠ€èƒ½å…³é”®è¯": []
        }
        
        # æ”¶é›†ç›®æ ‡èŒä½çš„å…³é”®è¯
        job_keywords = set()
        for job in target_jobs:
            # ä»èŒä½æè¿°ä¸­æå–å…³é”®è¯
            description = job.get("description", "")
            requirements = job.get("requirements", [])
            
            # ç®€å•çš„å…³é”®è¯æå–ï¼ˆå®é™…åº”ç”¨ä¸­å¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„NLPï¼‰
            for req in requirements:
                job_keywords.update(req.split())
        
        # åˆ†æç®€å†ä¸­ç¼ºå¤±çš„å…³é”®è¯
        resume_text = str(resume_data.get("summary", "")) + " " + " ".join(resume_data.get("skills", []))
        
        missing_keywords = []
        for keyword in job_keywords:
            if len(keyword) > 2 and keyword.lower() not in resume_text.lower():
                missing_keywords.append(keyword)
        
        suggestions["ç¼ºå¤±å…³é”®è¯"] = missing_keywords[:10]  # åªæ˜¾ç¤ºå‰10ä¸ª
        
        # ç”Ÿæˆä¼˜åŒ–å»ºè®®
        if missing_keywords:
            suggestions["ä¼˜åŒ–å»ºè®®"] = [
                "åœ¨æŠ€èƒ½éƒ¨åˆ†æ·»åŠ ç›¸å…³æŠ€æœ¯å…³é”®è¯",
                "åœ¨å·¥ä½œç»å†ä¸­ä½¿ç”¨è¡Œä¸šæœ¯è¯­",
                "åœ¨é¡¹ç›®æè¿°ä¸­çªå‡ºæ ¸å¿ƒæŠ€èƒ½",
                "ä¿æŒå…³é”®è¯å¯†åº¦é€‚ä¸­ï¼Œé¿å…å †ç Œ"
            ]
        
        return suggestions
    
    def _analyze_resume_structure(self, resume_data: Dict) -> Dict:
        """åˆ†æç®€å†ç»“æ„"""
        structure_analysis = {
            "å®Œæ•´æ€§è¯„åˆ†": 0,
            "ç¼ºå¤±éƒ¨åˆ†": [],
            "ä¼˜åŒ–å»ºè®®": [],
            "ç»“æ„è¯„ä¼°": {}
        }
        
        # æ£€æŸ¥å¿…è¦éƒ¨åˆ†
        required_sections = {
            "ä¸ªäººä¿¡æ¯": ["name", "contact"],
            "å·¥ä½œç»å†": ["experience"],
            "æ•™è‚²èƒŒæ™¯": ["education"],
            "æŠ€èƒ½": ["skills"],
            "é¡¹ç›®ç»å†": ["projects"]
        }
        
        score = 0
        for section, fields in required_sections.items():
            if any(field in resume_data for field in fields):
                score += 20
                structure_analysis["ç»“æ„è¯„ä¼°"][section] = "âœ… å·²åŒ…å«"
            else:
                structure_analysis["ç¼ºå¤±éƒ¨åˆ†"].append(section)
                structure_analysis["ç»“æ„è¯„ä¼°"][section] = "âŒ ç¼ºå¤±"
        
        structure_analysis["å®Œæ•´æ€§è¯„åˆ†"] = score
        
        # ç”Ÿæˆä¼˜åŒ–å»ºè®®
        if score < 100:
            structure_analysis["ä¼˜åŒ–å»ºè®®"] = [
                f"è¡¥å……{section}éƒ¨åˆ†" for section in structure_analysis["ç¼ºå¤±éƒ¨åˆ†"]
            ]
        else:
            structure_analysis["ä¼˜åŒ–å»ºè®®"] = [
                "ç®€å†ç»“æ„å®Œæ•´ï¼Œå»ºè®®ä¼˜åŒ–å†…å®¹è´¨é‡",
                "ç¡®ä¿å„éƒ¨åˆ†å†…å®¹è¯¦å®ä¸”ç›¸å…³",
                "ä¿æŒæ ¼å¼ç»Ÿä¸€å’Œæ’ç‰ˆç¾è§‚"
            ]
        
        return structure_analysis
    
    def _create_resume_action_plan(self, report: Dict) -> Dict:
        """åˆ›å»ºç®€å†ä¼˜åŒ–è¡ŒåŠ¨è®¡åˆ’"""
        action_plan = {
            "ç«‹å³è¡ŒåŠ¨ï¼ˆä»Šå¤©ï¼‰": [],
            "çŸ­æœŸç›®æ ‡ï¼ˆ1å‘¨å†…ï¼‰": [],
            "ä¸­æœŸç›®æ ‡ï¼ˆ1ä¸ªæœˆå†…ï¼‰": [],
            "é•¿æœŸç›®æ ‡ï¼ˆ3ä¸ªæœˆå†…ï¼‰": []
        }
        
        # åŸºäºåˆ†æç»“æœç”Ÿæˆè¡ŒåŠ¨è®¡åˆ’
        match_rate = report["åŒ¹é…åº¦åˆ†æ"]["æ€»ä½“åŒ¹é…åº¦"]
        
        if match_rate < 50:
            action_plan["ç«‹å³è¡ŒåŠ¨ï¼ˆä»Šå¤©ï¼‰"] = [
                "é‡æ–°å®¡è§†ç›®æ ‡èŒä½è¦æ±‚",
                "æ›´æ–°æŠ€èƒ½åˆ—è¡¨",
                "ä¼˜åŒ–ä¸ªäººæ‘˜è¦"
            ]
        
        missing_skills = report["åŒ¹é…åº¦åˆ†æ"]["ç¼ºå¤±æŠ€èƒ½"]
        if missing_skills:
            action_plan["çŸ­æœŸç›®æ ‡ï¼ˆ1å‘¨å†…ï¼‰"] = [
                f"å­¦ä¹ å…³é”®æŠ€èƒ½ï¼š{', '.join(missing_skills[:3])}",
                "æ›´æ–°LinkedInèµ„æ–™",
                "å‡†å¤‡æŠ€èƒ½è¯æ˜ææ–™"
            ]
        
        return action_plan
    
    def _analyze_best_application_time(self, application_history: List[Dict]) -> Dict:
        """åˆ†ææœ€ä½³æŠ•é€’æ—¶é—´"""
        time_analysis = {
            "æœ€ä½³æŠ•é€’æ—¥": {},
            "æœ€ä½³æŠ•é€’æ—¶é—´": {},
            "å“åº”ç‡ç»Ÿè®¡": {}
        }
        
        # è¿™é‡Œå¯ä»¥åŸºäºå†å²æ•°æ®åˆ†æï¼Œç°åœ¨æä¾›ä¸€èˆ¬æ€§å»ºè®®
        time_analysis["æœ€ä½³æŠ•é€’æ—¥"] = {
            "å‘¨äºŒ": "å“åº”ç‡æœ€é«˜",
            "å‘¨ä¸‰": "HRæŸ¥çœ‹ç‡é«˜", 
            "å‘¨å››": "é¢è¯•å®‰æ’æ´»è·ƒ"
        }
        
        time_analysis["æœ€ä½³æŠ•é€’æ—¶é—´"] = {
            "ä¸Šåˆ9-11ç‚¹": "HRåˆšä¸Šç­ï¼Œæ³¨æ„åŠ›é›†ä¸­",
            "ä¸‹åˆ2-4ç‚¹": "åˆä¼‘åï¼Œç²¾åŠ›å……æ²›",
            "é¿å…æ—¶é—´": "å‘¨ä¸€æ—©ä¸Šã€å‘¨äº”ä¸‹åˆ"
        }
        
        return time_analysis
    
    def _identify_success_patterns(self, application_history: List[Dict]) -> Dict:
        """è¯†åˆ«æˆåŠŸæ¨¡å¼"""
        patterns = {
            "æˆåŠŸå› ç´ ": [],
            "å¤±è´¥åŸå› ": [],
            "æœ€ä½³å®è·µ": []
        }
        
        # åˆ†ææˆåŠŸçš„ç”³è¯·
        successful_apps = [app for app in application_history if app.get("status") in ["å·²å½•ç”¨", "å¾…å…¥èŒ"]]
        
        if successful_apps:
            patterns["æˆåŠŸå› ç´ "] = [
                "ç®€å†å…³é”®è¯åŒ¹é…åº¦é«˜",
                "ç”³è¯·æ—¶é—´é€‰æ‹©åˆé€‚",
                "ä¸ªäººèµ„æ–™å®Œæ•´ä¸“ä¸š",
                "åŠæ—¶è·Ÿè¿›å’Œå›å¤"
            ]
        
        patterns["æœ€ä½³å®è·µ"] = [
            "æŠ•é€’å‰ä»”ç»†ç ”ç©¶å…¬å¸å’ŒèŒä½",
            "å®šåˆ¶åŒ–ç®€å†å’Œæ±‚èŒä¿¡",
            "ä¿æŒä¸“ä¸šçš„æ²Ÿé€šæ€åº¦",
            "åŠæ—¶æ›´æ–°æ±‚èŒçŠ¶æ€"
        ]
        
        return patterns
    
    def _generate_platform_optimization_advice(self, effectiveness: Dict) -> List[str]:
        """ç”Ÿæˆå¹³å°ä¼˜åŒ–å»ºè®®"""
        advice = []
        
        # åŸºäºå¹³å°æ’åç»™å»ºè®®
        platform_ranking = effectiveness.get("å¹³å°æ’å", {})
        
        if platform_ranking:
            best_platform = max(platform_ranking.items(), key=lambda x: x[1]["ç»¼åˆè¯„åˆ†"])
            advice.append(f"é‡ç‚¹ä½¿ç”¨{best_platform[0]}å¹³å°ï¼Œç»¼åˆæ•ˆæœæœ€ä½³")
            
            worst_platforms = [p for p, stats in platform_ranking.items() if stats["ç»¼åˆè¯„åˆ†"] < 20]
            if worst_platforms:
                advice.append(f"è€ƒè™‘å‡å°‘åœ¨{', '.join(worst_platforms)}çš„æŠ•å…¥")
        
        advice.extend([
            "å®šæœŸåˆ†æå’Œè°ƒæ•´å¹³å°ç­–ç•¥",
            "å…³æ³¨å¹³å°ç‰¹è‰²åŠŸèƒ½å’Œæœ€æ–°å˜åŒ–",
            "ä¿æŒå¤šå¹³å°å¹¶è¡Œï¼Œåˆ†æ•£é£é™©"
        ])
        
        return advice
    
    def _get_learning_suggestion(self, skill: str) -> str:
        """è·å–æŠ€èƒ½å­¦ä¹ å»ºè®®"""
        learning_suggestions = {
            "Python": "æ¨èé€šè¿‡å®é™…é¡¹ç›®å­¦ä¹ ï¼Œå…³æ³¨æ•°æ®åˆ†æå’ŒWebå¼€å‘æ–¹å‘",
            "JavaScript": "ä»åŸºç¡€è¯­æ³•å¼€å§‹ï¼Œé€æ­¥å­¦ä¹ ES6+å’Œå‰ç«¯æ¡†æ¶",
            "React": "å…ˆæŒæ¡JavaScriptåŸºç¡€ï¼Œç„¶åå­¦ä¹ ç»„ä»¶åŒ–å¼€å‘æ€æƒ³",
            "æœºå™¨å­¦ä¹ ": "å»ºè®®å…ˆå­¦ä¹ Pythonå’Œæ•°å­¦åŸºç¡€ï¼Œå†å­¦ä¹ ç®—æ³•ç†è®º",
            "Docker": "ä»å®¹å™¨æ¦‚å¿µå¼€å§‹ï¼Œé€šè¿‡å®é™…éƒ¨ç½²é¡¹ç›®æ¥å­¦ä¹ ",
            "AWS": "è€ƒè™‘è€ƒå–AWSè®¤è¯ï¼Œé€šè¿‡å®˜æ–¹åŸ¹è®­ææ–™å­¦ä¹ "
        }
        
        return learning_suggestions.get(skill, f"å»ºè®®é€šè¿‡åœ¨çº¿è¯¾ç¨‹å’Œå®é™…é¡¹ç›®æ¥å­¦ä¹ {skill}")

# ================================
# ğŸ”§ å·¥å…·å‡½æ•°
# ================================

def create_platform_integrator() -> PlatformIntegrator:
    """åˆ›å»ºå¹³å°é›†æˆå™¨"""
    return PlatformIntegrator()

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    integrator = create_platform_integrator()
    
    print("ğŸ”— å¹³å°é›†æˆæµ‹è¯•")
    
    # æµ‹è¯•LinkedInåˆ†æ
    test_profile = {
        "headline": "Pythonå¼€å‘å·¥ç¨‹å¸ˆ | AI/æœºå™¨å­¦ä¹  | 5å¹´ç»éªŒ",
        "summary": "ä¸“æ³¨äºAIå’Œæœºå™¨å­¦ä¹ çš„Pythonå¼€å‘å·¥ç¨‹å¸ˆï¼Œæœ‰5å¹´é¡¹ç›®ç»éªŒ...",
        "skills": ["Python", "æœºå™¨å­¦ä¹ ", "TensorFlow"]
    }
    print("LinkedInåˆ†æ:", integrator.analyze_linkedin_profile(test_profile))