#!/usr/bin/env python3
"""
ğŸ”— Platform Integration æ¨¡å—æµ‹è¯•è„šæœ¬
æµ‹è¯•å¹³å°é›†æˆæ¨¡å—çš„å„é¡¹åŠŸèƒ½
"""

import sys
import os
from datetime import datetime, timedelta

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src', 'modules'))

try:
    from modules.platform_integration import PlatformIntegrator
    print("âœ… æˆåŠŸå¯¼å…¥ PlatformIntegrator")
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

def test_linkedin_analysis():
    """æµ‹è¯•LinkedInåˆ†æåŠŸèƒ½"""
    print("\n" + "="*50)
    print("ğŸ” æµ‹è¯•LinkedInåˆ†æåŠŸèƒ½")
    print("="*50)
    
    integrator = PlatformIntegrator()
    
    # æµ‹è¯•æ•°æ®
    test_profile = {
        "headline": "Pythonå¼€å‘å·¥ç¨‹å¸ˆ | AI/æœºå™¨å­¦ä¹  | 5å¹´ç»éªŒ",
        "summary": "ä¸“æ³¨äºAIå’Œæœºå™¨å­¦ä¹ çš„Pythonå¼€å‘å·¥ç¨‹å¸ˆï¼Œæœ‰5å¹´é¡¹ç›®ç»éªŒï¼Œæ“…é•¿TensorFlowå’ŒPyTorchï¼Œæ›¾å‚ä¸å¤šä¸ªå¤§å‹é¡¹ç›®ï¼Œå…·å¤‡ä¸°å¯Œçš„æ•°æ®åˆ†æå’Œæ¨¡å‹ä¼˜åŒ–ç»éªŒã€‚",
        "skills": ["Python", "æœºå™¨å­¦ä¹ ", "TensorFlow", "PyTorch", "æ•°æ®åˆ†æ", "AWS"]
    }
    
    result = integrator.analyze_linkedin_profile(test_profile)
    
    print(f"ğŸ“Š LinkedInåˆ†æç»“æœ:")
    print(f"   æ ‡é¢˜è¯„åˆ†: {result['è¯„åˆ†']['æ ‡é¢˜']['è¯„åˆ†']}/100")
    print(f"   æ‘˜è¦è¯„åˆ†: {result['è¯„åˆ†']['æ‘˜è¦']['è¯„åˆ†']}/100")
    print(f"   çƒ­é—¨æŠ€èƒ½æ•°é‡: {len(result['å…³é”®è¯åˆ†æ']['çƒ­é—¨æŠ€èƒ½'])}")
    print(f"   ä¼˜åŒ–å»ºè®®æ•°é‡: {len(result['ä¼˜åŒ–å»ºè®®'])}")
    
    if result['ä¼˜åŒ–å»ºè®®']:
        print("   å…·ä½“å»ºè®®:")
        for suggestion in result['ä¼˜åŒ–å»ºè®®']:
            print(f"   - {suggestion}")

def test_email_generation():
    """æµ‹è¯•é‚®ä»¶ç”ŸæˆåŠŸèƒ½"""
    print("\n" + "="*50)
    print("ğŸ“§ æµ‹è¯•é‚®ä»¶ç”ŸæˆåŠŸèƒ½")
    print("="*50)
    
    integrator = PlatformIntegrator()
    
    # æµ‹è¯•æ±‚èŒç”³è¯·é‚®ä»¶
    variables = {
        "å§“å": "å¼ ä¸‰",
        "èŒä½åç§°": "Pythonå¼€å‘å·¥ç¨‹å¸ˆ",
        "å·¥ä½œå¹´é™": "5",
        "ä¸“ä¸šé¢†åŸŸ": "AI/æœºå™¨å­¦ä¹ ",
        "æ ¸å¿ƒæŠ€èƒ½": "Pythonã€TensorFlowã€æ•°æ®åˆ†æ",
        "ä¸»è¦æˆå°±": "ä¸»å¯¼å¼€å‘äº†æ™ºèƒ½æ¨èç³»ç»Ÿï¼Œæå‡ç”¨æˆ·è½¬åŒ–ç‡30%",
        "åŒ¹é…ç‚¹åˆ—è¡¨": "â€¢ 5å¹´Pythonå¼€å‘ç»éªŒ\nâ€¢ ç†Ÿç»ƒæŒæ¡æœºå™¨å­¦ä¹ ç®—æ³•\nâ€¢ æœ‰å¤§å‹é¡¹ç›®ç»éªŒ",
        "è”ç³»æ–¹å¼": "æ‰‹æœºï¼š138****8888ï¼Œé‚®ç®±ï¼šzhangsan@email.com",
        "æ—¥æœŸ": datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
    }
    
    result = integrator.generate_email("æ±‚èŒç”³è¯·", variables)
    
    if "é”™è¯¯" not in result:
        print(f"âœ… é‚®ä»¶ç”ŸæˆæˆåŠŸ")
        print(f"   ä¸»é¢˜: {result['ä¸»é¢˜']}")
        print(f"   å†…å®¹é•¿åº¦: {len(result['å†…å®¹'])}å­—ç¬¦")
        print(f"   ä¼˜åŒ–å»ºè®®: {len(result['ä¼˜åŒ–å»ºè®®'])}æ¡")
    else:
        print(f"âŒ é‚®ä»¶ç”Ÿæˆå¤±è´¥: {result['é”™è¯¯']}")

def test_job_tracking():
    """æµ‹è¯•æ±‚èŒè¿½è¸ªåŠŸèƒ½"""
    print("\n" + "="*50)
    print("ğŸ“± æµ‹è¯•æ±‚èŒè¿½è¸ªåŠŸèƒ½")
    print("="*50)
    
    integrator = PlatformIntegrator()
    
    # æ¨¡æ‹Ÿæ±‚èŒç”³è¯·æ•°æ®
    applications = [
        {"platform": "BOSSç›´è˜", "company": "è…¾è®¯", "position": "Pythonå·¥ç¨‹å¸ˆ", "status": "å·²æŠ•é€’"},
        {"platform": "æ‹‰å‹¾ç½‘", "company": "å­—èŠ‚è·³åŠ¨", "position": "AIå·¥ç¨‹å¸ˆ", "status": "å·²æŸ¥çœ‹"},
        {"platform": "LinkedIn", "company": "é˜¿é‡Œå·´å·´", "position": "æ•°æ®å·¥ç¨‹å¸ˆ", "status": "é¢è¯•é‚€è¯·"},
        {"platform": "BOSSç›´è˜", "company": "ç¾å›¢", "position": "åç«¯å·¥ç¨‹å¸ˆ", "status": "æŠ€æœ¯é¢è¯•"},
        {"platform": "çŒè˜", "company": "ç™¾åº¦", "position": "ç®—æ³•å·¥ç¨‹å¸ˆ", "status": "å·²å½•ç”¨"},
    ]
    
    result = integrator.track_job_applications(applications)
    
    print(f"ğŸ“Š æ±‚èŒè¿½è¸ªç»“æœ:")
    print(f"   æ€»ç”³è¯·æ•°: {result['æ€»ä½“ç»Ÿè®¡']['æ€»ç”³è¯·æ•°']}")
    print(f"   ä½¿ç”¨å¹³å°: {', '.join(result['æ€»ä½“ç»Ÿè®¡']['ä½¿ç”¨å¹³å°'])}")
    print(f"   å¹³å‡å“åº”ç‡: {result['æ€»ä½“ç»Ÿè®¡']['å¹³å‡å“åº”ç‡']}%")
    print(f"   é¢è¯•è½¬åŒ–ç‡: {result['æ€»ä½“ç»Ÿè®¡']['é¢è¯•è½¬åŒ–ç‡']}%")
    
    print(f"\n   å¹³å°åˆ†æ:")
    for platform, stats in result['å¹³å°åˆ†æ'].items():
        print(f"   {platform}: {stats['ç”³è¯·æ•°é‡']}ä¸ªç”³è¯·, æˆåŠŸç‡{stats['æˆåŠŸç‡']}%")
    
    if result['å»ºè®®']:
        print(f"\n   æ”¹è¿›å»ºè®®:")
        for suggestion in result['å»ºè®®']:
            print(f"   - {suggestion}")

def test_interview_management():
    """æµ‹è¯•é¢è¯•ç®¡ç†åŠŸèƒ½"""
    print("\n" + "="*50)
    print("ğŸ“… æµ‹è¯•é¢è¯•ç®¡ç†åŠŸèƒ½")
    print("="*50)
    
    integrator = PlatformIntegrator()
    
    # æ¨¡æ‹Ÿé¢è¯•æ•°æ®
    now = datetime.now()
    interviews = [
        {
            "company": "è…¾è®¯",
            "position": "Pythonå·¥ç¨‹å¸ˆ",
            "time": (now + timedelta(days=1)).isoformat(),
            "type": "æŠ€æœ¯é¢è¯•"
        },
        {
            "company": "å­—èŠ‚è·³åŠ¨",
            "position": "AIå·¥ç¨‹å¸ˆ", 
            "time": (now + timedelta(days=3)).isoformat(),
            "type": "HRé¢è¯•"
        },
        {
            "company": "é˜¿é‡Œå·´å·´",
            "position": "æ•°æ®å·¥ç¨‹å¸ˆ",
            "time": (now + timedelta(days=5)).isoformat(),
            "type": "ç»ˆé¢"
        }
    ]
    
    result = integrator.manage_interview_schedule(interviews)
    
    print(f"ğŸ“… é¢è¯•ç®¡ç†ç»“æœ:")
    print(f"   å³å°†é¢è¯•æ•°é‡: {len(result['å³å°†é¢è¯•'])}")
    
    for interview in result['å³å°†é¢è¯•']:
        print(f"   {interview['å…¬å¸']} - {interview['èŒä½']} (è¿˜æœ‰{interview['å‰©ä½™å¤©æ•°']}å¤©)")
    
    if result['å‡†å¤‡å»ºè®®']:
        print(f"\n   å‡†å¤‡å»ºè®®:")
        for advice in result['å‡†å¤‡å»ºè®®']:
            print(f"   - {advice}")

def test_market_trends():
    """æµ‹è¯•å¸‚åœºè¶‹åŠ¿åˆ†æåŠŸèƒ½"""
    print("\n" + "="*50)
    print("ğŸ“Š æµ‹è¯•å¸‚åœºè¶‹åŠ¿åˆ†æåŠŸèƒ½")
    print("="*50)
    
    integrator = PlatformIntegrator()
    
    # æ¨¡æ‹ŸèŒä½æ•°æ®
    job_data = [
        {"required_skills": ["Python", "Django", "MySQL"], "salary": 250000},
        {"required_skills": ["JavaScript", "React", "Node.js"], "salary": 280000},
        {"required_skills": ["Python", "æœºå™¨å­¦ä¹ ", "TensorFlow"], "salary": 350000},
        {"required_skills": ["Java", "Spring", "MySQL"], "salary": 300000},
        {"required_skills": ["Python", "æ•°æ®åˆ†æ", "Pandas"], "salary": 220000},
    ]
    
    result = integrator.analyze_job_market_trends(job_data)
    
    print(f"ğŸ“ˆ å¸‚åœºè¶‹åŠ¿åˆ†æç»“æœ:")
    print(f"   çƒ­é—¨æŠ€èƒ½TOP5:")
    for i, (skill, count) in enumerate(list(result['çƒ­é—¨æŠ€èƒ½'].items())[:5], 1):
        print(f"   {i}. {skill}: {count}æ¬¡æåŠ")
    
    print(f"\n   è–ªèµ„è¶‹åŠ¿:")
    for skill, data in list(result['è–ªèµ„è¶‹åŠ¿'].items())[:3]:
        print(f"   {skill}: å¹³å‡Â¥{data['å¹³å‡è–ªèµ„']:,.0f}, èŒä½æ•°{data['èŒä½æ•°é‡']}")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ”— Platform Integration æ¨¡å—åŠŸèƒ½æµ‹è¯•")
    print("=" * 60)
    
    try:
        test_linkedin_analysis()
        test_email_generation()
        test_job_tracking()
        test_interview_management()
        test_market_trends()
        
        print("\n" + "="*60)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼Platform Integrationæ¨¡å—åŠŸèƒ½æ­£å¸¸")
        print("="*60)
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()