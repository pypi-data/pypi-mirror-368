"""
Test Fixtures for {{ project_name }}

Generated by TestAPIX on {{ timestamp }}

This module provides reusable test fixtures for TestAPIX tests. Fixtures handle
the setup and teardown of test dependencies like API clients, test data
generators, and database connections.

TestAPIX fixtures follow pytest conventions and can be used across all test types.
"""

import pytest
from typing import AsyncGenerator, Generator

from testapix import APIClient, SyncAPIClient
from testapix.core.config import load_config, TestAPIXConfig
from testapix.core.client import BearerTokenAuth, APIKeyAuth
from testapix.generators import BaseGenerator


@pytest.fixture(scope="session")
def config() -> TestAPIXConfig:
    """
    Load TestAPIX configuration for the test session.

    This fixture loads configuration once per test session, making it
    available to all tests. The configuration respects environment
    variables and uses the TESTAPIX_ENVIRONMENT setting.
    """
    return load_config()


@pytest.fixture
async def api_client(config: TestAPIXConfig) -> AsyncGenerator[APIClient, None]:
    """
    Create an authenticated async API client for testing.

    This fixture:
    1. Creates an HTTP client with configuration from files/env
    2. Sets up authentication if configured
    3. Ensures proper cleanup after tests

    Yields:
        Configured and authenticated API client
    """
    # Create client with configuration
    client = APIClient(
        base_url=config.http.base_url,
        default_headers=config.http.headers,
        request_config=config.http
    )

    # Set up authentication if configured
    if config.auth:
        if config.auth.type == "bearer" and config.auth.token:
            client.set_auth(BearerTokenAuth(config.auth.token))
        elif config.auth.type == "api_key" and config.auth.api_key:
            client.set_auth(APIKeyAuth(
                config.auth.api_key,
                config.auth.header_name
            ))
        # Add other auth types as needed

    try:
        yield client
    finally:
        # Ensure client is properly closed
        await client.close()


@pytest.fixture
def sync_api_client(config: TestAPIXConfig) -> Generator[SyncAPIClient, None, None]:
    """
    Create an authenticated synchronous API client.

    This fixture provides a synchronous alternative for simpler tests
    that don't need async functionality.
    """
    client = SyncAPIClient(
        base_url=config.http.base_url,
        default_headers=config.http.headers
    )

    # Set up authentication
    if config.auth:
        if config.auth.type == "bearer" and config.auth.token:
            client.set_auth(BearerTokenAuth(config.auth.token))
        elif config.auth.type == "api_key" and config.auth.api_key:
            client.set_auth(APIKeyAuth(
                config.auth.api_key,
                config.auth.header_name
            ))

    try:
        yield client
    finally:
        client.close()


@pytest.fixture
async def unauthenticated_client(config: TestAPIXConfig) -> AsyncGenerator[APIClient, None]:
    """
    Create an unauthenticated API client.

    Useful for testing authentication requirements and error handling
    when requests are made without proper credentials.
    """
    client = APIClient(
        base_url=config.http.base_url,
        default_headers={k: v for k, v in config.http.headers.items()
                         if k.lower() not in ['authorization', 'x-api-key']}
    )

    try:
        yield client
    finally:
        await client.close()


@pytest.fixture
def data_generator() -> BaseGenerator:
    """
    Create a test data generator.

    Provides realistic test data for various scenarios. The generator
    uses the Mimesis library to create contextually appropriate data
    rather than random strings.
    """
    return BaseGenerator()


@pytest.fixture(autouse=True)
async def cleanup_test_data(request, config: TestAPIXConfig, api_client: APIClient):
    """
    Automatically cleanup test data after each test.

    This fixture runs after each test to ensure test data doesn't
    accumulate. It tracks resources created during tests and removes
    them based on the configured cleanup strategy.
    """
    if not config.test_data_cleanup:
        yield
        return

    # Track created resources
    created_resources = []

    def track_resource(resource_type: str, resource_id: str):
        """Track a resource for cleanup."""
        created_resources.append((resource_type, resource_id))

    # Make tracking function available to tests
    request.track_resource = track_resource

    yield

    # Cleanup after test
    if config.database.cleanup_strategy == "immediate":
        for resource_type, resource_id in reversed(created_resources):
            try:
                # Implement cleanup based on resource type
                # This is a template - customize for your API
                if resource_type == "user":
                    await api_client.delete(f"/users/{resource_id}")
                elif resource_type == "order":
                    await api_client.delete(f"/orders/{resource_id}")
                # Add more resource types as needed
            except Exception as e:
                # Log but don't fail the test
                print(f"Warning: Failed to cleanup {resource_type} {resource_id}: {e}")


# Additional fixtures can be added here for specific test needs
# For example: database connections, message queues, external services, etc.
