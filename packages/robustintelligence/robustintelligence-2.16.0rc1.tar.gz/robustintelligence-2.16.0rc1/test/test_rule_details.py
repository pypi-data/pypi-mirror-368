# coding: utf-8

"""
    Robust Intelligence Firewall REST API

    API methods for Robust Intelligence. Users must authenticate using the `X-Firewall-Auth-Token` header. Your AI Firewall Agent domain forms the base of the URL for REST API calls. To find the Agent domain in the Robust Intelligence UI, click AI Firewall: Settings icon: Firewall Settings. Find your agent in the Firewall Agent Status: Agents Setup page, and copy its URL from the table.

    The version of the OpenAPI document: 1.0
    Contact: dev@robustintelligence.com
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501

import unittest

from ri.fwclient.models.rule_details import RuleDetails

class TestRuleDetails(unittest.TestCase):
    """RuleDetails unit test stubs"""

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def make_instance(self, include_optional) -> RuleDetails:
        """Test RuleDetails
            include_option is a boolean, when False only required
            params are included, when True both required and
            optional params are included """
        # uncomment below to create an instance of `RuleDetails`
        """
        model = RuleDetails()
        if include_optional:
            return RuleDetails(
                action = 'FIREWALL_ACTION_UNSPECIFIED',
                code_detection_details = ri.fwclient.models.code_detection_details.CodeDetectionDetails(
                    flagged_code_substrings = [
                        ri.fwclient.models.code_substring.CodeSubstring(
                            flagged_substring = ri.fwclient.models.flagged_substring.FlaggedSubstring(
                                request_body_component = 'REQUEST_BODY_COMPONENT_UNSPECIFIED', 
                                substring_end_index = 56, 
                                substring_start_index = 56, ), 
                            language = '', )
                        ], ),
                language_detection_details = ri.fwclient.models.language_detection_details.LanguageDetectionDetails(
                    flagged_language_substrings = [
                        ri.fwclient.models.language_substring.LanguageSubstring(
                            flagged_substring = ri.fwclient.models.flagged_substring.FlaggedSubstring(
                                request_body_component = 'REQUEST_BODY_COMPONENT_UNSPECIFIED', 
                                substring_end_index = 56, 
                                substring_start_index = 56, ), 
                            language_code = '', )
                        ], ),
                pii_detection_details = ri.fwclient.models.pii_detection_details.PiiDetectionDetails(
                    flagged_entities = [
                        ri.fwclient.models.flagged_entity.FlaggedEntity(
                            confidence_score = 1.337, 
                            custom_entity_name = '', 
                            entity_type = 'PII_ENTITY_TYPE_UNSPECIFIED', 
                            flagged_substring = ri.fwclient.models.flagged_substring.FlaggedSubstring(
                                request_body_component = 'REQUEST_BODY_COMPONENT_UNSPECIFIED', 
                                substring_end_index = 56, 
                                substring_start_index = 56, ), )
                        ], 
                    sanitized_text = '', ),
                prompt_injection_details = ri.fwclient.models.prompt_injection_details.PromptInjectionDetails(
                    objectives = [
                        'ATTACK_OBJECTIVE_UNSPECIFIED'
                        ], 
                    techniques = [
                        'ATTACK_TECHNIQUE_UNSPECIFIED'
                        ], ),
                rule_name = '',
                security_standards = [
                    ri.fwclient.models.container_for_an_ai_risk_standard_(e/g/_nist).Container for an AI risk standard (e.g. NIST)(
                        description = '', )
                    ],
                toxicity_detection_details = ri.fwclient.models.toxicity_detection_details.ToxicityDetectionDetails(
                    categories = [
                        'TOXICITY_THREAT_CATEGORY_UNSPECIFIED'
                        ], )
            )
        else:
            return RuleDetails(
        )
        """

    def testRuleDetails(self):
        """Test RuleDetails"""
        # inst_req_only = self.make_instance(include_optional=False)
        # inst_req_and_optional = self.make_instance(include_optional=True)

if __name__ == '__main__':
    unittest.main()