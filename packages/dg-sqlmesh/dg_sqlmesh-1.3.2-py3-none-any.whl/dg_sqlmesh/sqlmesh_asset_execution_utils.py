"""
Utilitaires pour l'ex√©cution des assets SQLMesh.
Contient les fonctions extraites de la fonction model_asset pour am√©liorer la lisibilit√© et la testabilit√©.
"""

from dagster import AssetExecutionContext, MaterializeResult, AssetCheckResult, AssetKey
from typing import Dict, List, Any, Tuple
from .resource import SQLMeshResource
from .sqlmesh_asset_utils import get_models_to_materialize


def execute_sqlmesh_materialization(
    context: AssetExecutionContext,
    sqlmesh: SQLMeshResource,
    sqlmesh_results: Any,
    run_id: str,
    selected_asset_keys: List[AssetKey],
) -> Dict[str, Any]:
    """
    Ex√©cute la mat√©rialisation SQLMesh pour tous les assets s√©lectionn√©s.

    Args:
        context: Contexte Dagster
        sqlmesh: Resource SQLMesh
        sqlmesh_results: Resource pour partager les r√©sultats
        run_id: ID du run Dagster
        selected_asset_keys: Assets s√©lectionn√©s

    Returns:
        R√©sultats de l'ex√©cution SQLMesh
    """
    context.log.info(
        "üöÄ First asset in run, launching SQLMesh execution for all selected assets"
    )
    context.log.debug(f"üîç No existing results for run {run_id}")

    context.log.info(f"üîç Selected assets in this run: {selected_asset_keys}")

    # Lancer une seule ex√©cution SQLMesh pour tous les assets s√©lectionn√©s
    models_to_materialize = get_models_to_materialize(
        selected_asset_keys,
        sqlmesh.get_models,
        sqlmesh.translator,
    )

    if not models_to_materialize:
        raise Exception(f"No models found for selected assets: {selected_asset_keys}")

    context.log.info(
        f"üîç Materializing {len(models_to_materialize)} models: {[m.name for m in models_to_materialize]}"
    )

    # Ex√©cution SQLMesh unique
    context.log.debug("üîç Starting SQLMesh materialization...")
    plan = sqlmesh.materialize_assets_threaded(models_to_materialize, context=context)
    context.log.debug("üîç SQLMesh materialization completed")

    # Capturer tous les r√©sultats
    context.log.debug("üîç Processing failed models events...")
    failed_check_results = sqlmesh._process_failed_models_events()
    context.log.debug(f"üîç Failed check results count: {len(failed_check_results)}")

    context.log.debug("üîç Processing skipped models events...")
    skipped_models_events = sqlmesh._console.get_skipped_models_events()
    context.log.debug(f"üîç Skipped models events count: {len(skipped_models_events)}")

    context.log.debug("üîç Processing evaluation events...")
    evaluation_events = sqlmesh._console.get_evaluation_events()
    context.log.debug(f"üîç Evaluation events count: {len(evaluation_events)}")

    # Stocker les r√©sultats dans le resource partag√©
    results = {
        "failed_check_results": failed_check_results,
        "skipped_models_events": skipped_models_events,
        "evaluation_events": evaluation_events,
        "plan": plan,
    }

    sqlmesh_results.store_results(run_id, results)
    context.log.info(f"üíæ Stored SQLMesh results for run {run_id}")

    return results


def process_sqlmesh_results(
    context: AssetExecutionContext, sqlmesh_results: Any, run_id: str
) -> Tuple[List[AssetCheckResult], List[Dict], List[Dict]]:
    """
    R√©cup√®re et traite les r√©sultats SQLMesh partag√©s.

    Args:
        context: Contexte Dagster
        sqlmesh_results: Resource pour partager les r√©sultats
        run_id: ID du run Dagster

    Returns:
        Tuple de (failed_check_results, skipped_models_events, evaluation_events)
    """
    context.log.info(f"üìã Using existing SQLMesh results from run {run_id}")
    context.log.debug(f"üîç Found existing results for run {run_id}")

    # R√©cup√©rer les r√©sultats pour ce run
    results = sqlmesh_results.get_results(run_id)
    failed_check_results = results["failed_check_results"]
    skipped_models_events = results["skipped_models_events"]
    evaluation_events = results["evaluation_events"]

    context.log.debug("üîç Processing results for model")
    context.log.debug(f"üîç Failed check results: {len(failed_check_results)}")
    context.log.debug(f"üîç Skipped models events: {len(skipped_models_events)}")
    context.log.debug(f"üîç Evaluation events: {len(evaluation_events)}")

    return failed_check_results, skipped_models_events, evaluation_events


def check_model_status(
    context: AssetExecutionContext,
    current_model_name: str,
    current_asset_spec: Any,
    failed_check_results: List[AssetCheckResult],
    skipped_models_events: List[Dict],
) -> Tuple[bool, bool]:
    """
    V√©rifie le statut d'un mod√®le sp√©cifique.

    Args:
        context: Contexte Dagster
        current_model_name: Nom du mod√®le actuel
        current_asset_spec: Sp√©cification de l'asset
        failed_check_results: R√©sultats d'audit √©chou√©s
        skipped_models_events: √âv√©nements de mod√®les ignor√©s

    Returns:
        Tuple de (model_was_skipped, model_has_audit_failures)
    """
    model_was_skipped = False
    model_has_audit_failures = False

    # V√©rifier les skips √† cause d'√©checs upstream
    context.log.debug("üîç Checking for skipped models...")
    for event in skipped_models_events:
        skipped_snapshots = event.get("snapshot_names", set())
        context.log.debug(f"üîç Skipped snapshots: {skipped_snapshots}")

        for snapshot_name in skipped_snapshots:
            if snapshot_name:
                parts = snapshot_name.split('"."')
                if len(parts) >= 3:
                    skipped_model_name = parts[1] + "." + parts[2].replace('"', "")
                    context.log.debug(
                        f"üîç Checking skipped model: {skipped_model_name} vs {current_model_name}"
                    )
                    if skipped_model_name == current_model_name:
                        model_was_skipped = True
                        context.log.error(
                            f"‚ùå Model {current_model_name} was skipped due to upstream failures"
                        )
                        break
        if model_was_skipped:
            break

    # V√©rifier les √©checs d'audit (mod√®le ex√©cut√© mais audit failed)
    context.log.debug("üîç Checking for audit failures...")
    for check_result in failed_check_results:
        context.log.debug(
            f"üîç Checking failed check: {check_result.asset_key} vs {current_asset_spec.key}"
        )
        if check_result.asset_key == current_asset_spec.key:
            model_has_audit_failures = True
            context.log.error(
                f"‚ùå Model {current_model_name} has audit failures: {check_result.metadata.get('audit_message', 'Unknown error')}"
            )
            break

    context.log.debug(
        f"üîç Model {current_model_name} - was_skipped: {model_was_skipped}, has_audit_failures: {model_has_audit_failures}"
    )

    return model_was_skipped, model_has_audit_failures


def handle_audit_failures(
    context: AssetExecutionContext,
    current_model_name: str,
    current_asset_spec: Any,
    current_model_checks: List[Any],
    failed_check_results: List[AssetCheckResult],
) -> MaterializeResult:
    """
    G√®re les cas o√π le mod√®le s'est ex√©cut√© mais les audits ont √©chou√©.

    Args:
        context: Contexte Dagster
        current_model_name: Nom du mod√®le
        current_asset_spec: Sp√©cification de l'asset
        current_model_checks: Checks du mod√®le
        failed_check_results: R√©sultats d'audit √©chou√©s

    Returns:
        MaterializeResult avec les checks √©chou√©s
    """
    context.log.info(
        f"‚ö†Ô∏è Model {current_model_name}: MATERIALIZATION SUCCESS but AUDIT FAILED"
    )
    context.log.debug("üîç Returning MaterializeResult with failed checks")

    # Si on a des checks, on doit retourner leurs r√©sultats
    if current_model_checks:
        check_results = []

        # Cr√©er des AssetCheckResult failed pour tous les checks
        for check in current_model_checks:
            # Trouver le message d'erreur sp√©cifique pour ce check
            audit_message = "Model materialization succeeded but audits failed"
            for check_result in failed_check_results:
                if check_result.asset_key == current_asset_spec.key:
                    audit_message = check_result.metadata.get(
                        "audit_message", audit_message
                    )
                    break

            check_result = AssetCheckResult(
                check_name=check.name,
                passed=False,
                metadata={
                    "audit_message": audit_message,
                    "audits_passed": 0,
                    "audits_failed": len(current_model_checks),
                    "sqlmesh_audit_name": check.name,  # Nom de l'audit SQLMesh
                    "sqlmesh_model": current_model_name,  # Nom du mod√®le SQLMesh
                    "error_details": f"SQLMesh audit '{check.name}' failed: {audit_message}",
                },
            )
            check_results.append(check_result)
            context.log.debug(
                f"üîç Created failed check result for: {check.name} with message: {audit_message}"
            )

        context.log.debug(f"üîç Returning {len(check_results)} failed check results")
        return MaterializeResult(
            asset_key=current_asset_spec.key,
            metadata={"status": "materialization_success_audit_failed"},
            check_results=check_results,
        )
    else:
        context.log.warning(
            f"‚ö†Ô∏è No checks defined for model {current_model_name}, returning only MaterializeResult"
        )
        return MaterializeResult(
            asset_key=current_asset_spec.key,
            metadata={"status": "materialization_success_audit_failed"},
        )


def handle_successful_execution(
    context: AssetExecutionContext,
    current_model_name: str,
    current_asset_spec: Any,
    current_model_checks: List[Any],
    evaluation_events: List[Dict],
) -> MaterializeResult:
    """
    G√®re les cas o√π le mod√®le s'est ex√©cut√© avec succ√®s.

    Args:
        context: Contexte Dagster
        current_model_name: Nom du mod√®le
        current_asset_spec: Sp√©cification de l'asset
        current_model_checks: Checks du mod√®le
        evaluation_events: √âv√©nements d'√©valuation

    Returns:
        MaterializeResult avec les checks r√©ussis
    """
    context.log.info(f"‚úÖ Model {current_model_name}: SUCCESS")
    context.log.debug("üîç Returning MaterializeResult with passed checks")

    # Si on a des checks, on doit retourner leurs r√©sultats
    if current_model_checks:
        check_results = []

        context.log.info(
            f"üîç Looking for evaluation events for model: {current_model_name}"
        )
        context.log.info(f"üîç Found {len(evaluation_events)} evaluation events")

        for event in evaluation_events:
            if event.get("event_type") == "update_snapshot_evaluation":
                snapshot_name = event.get("snapshot_name")
                context.log.info(f"üîç Checking snapshot: {snapshot_name}")

                if snapshot_name:
                    parts = snapshot_name.split('"."')
                    if len(parts) >= 3:
                        snapshot_model_name = parts[1] + "." + parts[2].replace('"', "")
                        if snapshot_model_name == current_model_name:
                            num_audits_passed = event.get("num_audits_passed", 0)
                            num_audits_failed = event.get("num_audits_failed", 0)

                            for check in current_model_checks:
                                passed = num_audits_failed == 0
                                check_results.append(
                                    AssetCheckResult(
                                        check_name=check.name,
                                        passed=passed,
                                        metadata={
                                            "audits_passed": num_audits_passed,
                                            "audits_failed": num_audits_failed,
                                        },
                                    )
                                )
                            break

        if not check_results:
            context.log.warning(
                f"‚ö†Ô∏è No evaluation events found for model {current_model_name}, using default check results"
            )
            for check in current_model_checks:
                check_results.append(
                    AssetCheckResult(
                        check_name=check.name,
                        passed=True,
                        metadata={
                            "note": "No evaluation events found, using default result"
                        },
                    )
                )

        context.log.debug(f"üîç Returning {len(check_results)} check results")
        return MaterializeResult(
            asset_key=current_asset_spec.key,
            metadata={"status": "success"},
            check_results=check_results,
        )
    else:
        context.log.debug("üîç No checks defined, returning simple MaterializeResult")
        return MaterializeResult(
            asset_key=current_asset_spec.key, metadata={"status": "success"}
        )


def create_materialize_result(
    context: AssetExecutionContext,
    current_model_name: str,
    current_asset_spec: Any,
    current_model_checks: List[Any],
    model_was_skipped: bool,
    model_has_audit_failures: bool,
    failed_check_results: List[AssetCheckResult],
    evaluation_events: List[Dict],
) -> MaterializeResult:
    """
    Cr√©e le MaterializeResult appropri√© selon le statut du mod√®le.

    Args:
        context: Contexte Dagster
        current_model_name: Nom du mod√®le
        current_asset_spec: Sp√©cification de l'asset
        current_model_checks: Checks du mod√®le
        model_was_skipped: Si le mod√®le a √©t√© ignor√©
        model_has_audit_failures: Si le mod√®le a des √©checs d'audit
        failed_check_results: R√©sultats d'audit √©chou√©s
        evaluation_events: √âv√©nements d'√©valuation

    Returns:
        MaterializeResult appropri√©
    """
    if model_was_skipped:
        # Mod√®le skip ‚Üí Lever une exception (pas de materialization)
        error_msg = f"Model {current_model_name} was skipped due to upstream failures"
        context.log.error(f"‚ùå {error_msg}")
        context.log.debug("üîç Raising exception for skipped model")
        raise Exception(error_msg)
    elif model_has_audit_failures:
        return handle_audit_failures(
            context,
            current_model_name,
            current_asset_spec,
            current_model_checks,
            failed_check_results,
        )
    else:
        return handle_successful_execution(
            context,
            current_model_name,
            current_asset_spec,
            current_model_checks,
            evaluation_events,
        )
