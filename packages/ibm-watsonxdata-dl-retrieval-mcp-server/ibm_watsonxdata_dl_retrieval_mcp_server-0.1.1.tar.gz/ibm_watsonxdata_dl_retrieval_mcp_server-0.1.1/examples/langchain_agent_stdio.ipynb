{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ab48968-2706-4456-8b62-eaa5aec1dd33",
   "metadata": {},
   "source": [
    "# Agent build with LangChain agents and watsonx.data document library retrieval MCP server in stdio transport mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d480c0fe-8278-4100-a65a-b48b4e05fa3c",
   "metadata": {},
   "source": [
    "#### Install the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0571b178-4d63-45b0-b20d-cf03d9a583ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install asyncio langchain langgraph langchain-mcp-adapters ibm-watson-machine-learning langchain-ibm mcp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4abe424-f0e0-4cbb-a415-4e6ed009b00c",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f3f6de42-0e33-493d-a35e-669cee58b06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "from langchain_mcp_adapters.tools import load_mcp_tools\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n",
    "import os\n",
    "from langchain_ibm import ChatWatsonx\n",
    "from pydantic import BaseModel, Field \n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a00c60-85f9-41b6-9ace-7f8a995b2bb5",
   "metadata": {},
   "source": [
    "#### Setting up stdio server parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ec6c52-89a6-427a-8593-0dd0dbdfac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_params = StdioServerParameters(\n",
    "         command=\"python\",\n",
    "   args=[\n",
    "        \"-m\", \"ibm_watsonxdata_dl_retrieval_mcp_server\",\n",
    "        \"--transport\", \"stdio\"\n",
    "    ],\n",
    "    transport = \"stdio\",\n",
    "        env={\n",
    "            \"WATSONX_DATA_API_KEY\": \"\",\n",
    "            \"WATSONX_DATA_RETRIEVAL_ENDPOINT\": \"\",\n",
    "            \"WATSONX_DATA_TOKEN_GENERATION_ENDPOINT\": \"\",\n",
    "            \"DOCUMENT_LIBRARY_API_ENDPOINT\": \"\",\n",
    "            \"LH_CONTEXT\" : \"\",\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ff6b02-c561-457c-bf96-ae9de1dd2b88",
   "metadata": {},
   "source": [
    "#### Initialize IBM watsonx AI model for the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e6f0ee-a44c-45f1-b4aa-ccef47dcf960",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    GenParams.DECODING_METHOD: \"greedy\",\n",
    "    GenParams.MAX_NEW_TOKENS: 1024,\n",
    "    GenParams.MIN_NEW_TOKENS: 10,\n",
    "    GenParams.TEMPERATURE: 0.7,\n",
    "}\n",
    "\n",
    "model = ChatWatsonx(\n",
    "    model_id=\"meta-llama/llama-3-3-70b-instruct\",\n",
    "    apikey=\"\",\n",
    "    project_id=\"\",\n",
    "    url=\"\",\n",
    "    parameters=parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2222e5-5ed9-4d52-8950-4199a9de14a4",
   "metadata": {},
   "source": [
    "#### Agent response structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf24fb4f-a538-41f6-81a8-d9b971a6847b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentResponse(BaseModel):\n",
    "    final_answer: Optional[str] = Field(description=\"Detailed answer for the initial User Query if the answer was found, else provide a clear explanation of why it could not be found and suggest possible next steps or alternatives.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a99eec-4a98-4c9a-a2b8-adf25162cd55",
   "metadata": {},
   "source": [
    "#### Run MCP client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edc27fe-944d-4e19-89b1-624689142d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "async with stdio_client(server_params) as (read, write):\n",
    "    async with ClientSession(read, write) as session:\n",
    "        # Initialize the connection\n",
    "        await session.initialize()\n",
    "        tools = await load_mcp_tools(session)\n",
    "\n",
    "        # Create and run the agent\n",
    "        dl_agent = create_react_agent(model=model, tools=tools,prompt=(\n",
    "                \"You are a helpful question answering agent\\n\"\n",
    "            \"Your task is to answer the user query by calling the relevant tools given to you\\n\"),\n",
    "                response_format=AgentResponse                     \n",
    "                )\n",
    "        \n",
    "        user_input = \"What is the highest invoice amount\"\n",
    "        \n",
    "        agent_response = await dl_agent.ainvoke({\n",
    "                    \"messages\": [\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": user_input\n",
    "                        }\n",
    "                    ]\n",
    "                })\n",
    "        structured_resp = agent_response.get('structured_response')\n",
    "        if structured_resp and hasattr(structured_resp, 'final_answer'):\n",
    "            print(structured_resp.final_answer)\n",
    "        else:\n",
    "            print(structured_resp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
