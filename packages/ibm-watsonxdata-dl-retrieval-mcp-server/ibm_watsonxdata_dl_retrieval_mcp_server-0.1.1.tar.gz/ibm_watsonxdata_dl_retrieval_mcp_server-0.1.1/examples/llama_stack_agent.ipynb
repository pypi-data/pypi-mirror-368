{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent build with Llama Stack and watsonx.data document library retrieval MCP server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more details on llama stack refer below links\n",
    "* https://github.com/meta-llama/llama-stack/tree/main/docs/source/distributions\n",
    "* https://llama-stack.readthedocs.io/en/latest/distributions/importing_as_library.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install uv llama-stack numpy==1.26.4 ibm-watson-machine-learning twilio trycourier termcolor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Llama Stack with watsonx template and venv image type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!llama stack build --template watsonx --image-type venv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MCP_ENDPOINT\"]=\"http://<host:port>/sse\"\n",
    "os.environ[\"INFERENCE_PROVIDER\"]=\"watsonx\"\n",
    "os.environ[\"WATSONX_API_KEY\"]=\"<>\"\n",
    "os.environ[\"WATSONX_PROJECT_ID\"]=\"<>\" \n",
    "os.environ[\"WATSONX_BASE_URL\"]=\"https://eu-de.ml.cloud.ibm.com\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from termcolor import cprint\n",
    "from llama_stack.distribution.library_client import LlamaStackAsLibraryClient\n",
    "from llama_stack_client.types.toolgroup_register_params import McpEndpoint\n",
    "from llama_stack_client import Agent, AgentEventLogger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt for agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a helpful assistant.\n",
    "\n",
    "CORE RESPONSIBILITIES:\n",
    "1. Access required information using the available tools\n",
    "2. Provide clear and accurate information\n",
    "\n",
    "DATA INTEGRITY GUIDELINES:\n",
    "1. Always verify data exists before making decisions or taking actions\n",
    "2. If the tool indicates no information is available, accept this response without making assumptions\n",
    "3. Strictly don't make any assumptions if the tool indicates no information is available\n",
    "4. For any data-driven decisions:\n",
    "   - Always verify the data exists before taking actions\n",
    "   - Never proceed with actions based on assumptions or incomplete data\n",
    "   - If data is missing or unclear, return an answer explaining that you cannot proceed without the required information\n",
    "\n",
    "COMMUNICATION STANDARDS:\n",
    "1. Always be professional, clear, and descriptive\n",
    "2. When providing information, highlight key details (dates, amounts, status)\n",
    "\n",
    "PRIVACY & SECURITY:\n",
    "1. Be cautious with personally identifiable information\n",
    "\n",
    "Follow these guidelines carefully to provide accurate, helpful management assistance.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the Llama Stack client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = LlamaStackAsLibraryClient(os.getenv(\"INFERENCE_PROVIDER\"))\n",
    "client.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registering governed data tools from watsonx.data MCP server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.toolgroups.register(\n",
    "    toolgroup_id=\"mcp::watsonx_data\",\n",
    "    provider_id=\"model-context-protocol\",\n",
    "    mcp_endpoint=McpEndpoint(uri=os.getenv(\"MCP_ENDPOINT\")),\n",
    ")\n",
    "\n",
    "cprint(\"\\n\\n MCP Tools:\", \"blue\")\n",
    "tools = client.tools.list(toolgroup_id=\"mcp::watsonx_data\")\n",
    "for tool in tools:\n",
    "    cprint(f\"TOOL NAME : {tool.identifier}\", \"white\")\n",
    "    cprint(f\"Description: {tool.description}\", \"yellow\")\n",
    "    cprint(f\"Parameters: {tool.parameters}\\n\", \"cyan\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an agent with governed data tools from watsonx.data MCP server and local notification tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(\n",
    "    client, \n",
    "    model=\"meta-llama/Llama-3.3-70B-Instruct\",\n",
    "    instructions=prompt,\n",
    "    tools=[\"mcp::watsonx_data\"],\n",
    "    sampling_params={\n",
    "        \"max_tokens\": 4095\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "session_id = agent.create_session(\"session-alpha\")\n",
    "\n",
    "user_input = '''Find the total number of invoices'''\n",
    "\n",
    "cprint(\"\\n\\nAgent started.\", \"blue\")\n",
    "cprint(f\"\\nTask : {user_input}\")\n",
    "try:\n",
    "    messages = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_input\n",
    "    }]\n",
    "\n",
    "    response = agent.create_turn(\n",
    "        messages=messages,\n",
    "        session_id=session_id,\n",
    "    )\n",
    "    \n",
    "    print()\n",
    "    for log in AgentEventLogger().log(response):\n",
    "        log.print()\n",
    "        \n",
    "except Exception as e:\n",
    "    cprint(f\"\\nError: {str(e)}\", \"red\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
