{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d41e89b-77d8-451e-bcb1-a45121d15095",
   "metadata": {},
   "source": [
    "# Agent build with LangChain agents and watsonx.data document library retrieval MCP server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3cf40d-9c4a-4b43-99f6-0ff3c6233149",
   "metadata": {},
   "source": [
    "#### Install the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10075be7-c22d-4e48-9739-1ed952b89a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ibm-watsonxdata-dl-retrieval-mcp-server langchain-mcp-adapters langgraph langchain ibm_watson_machine_learning langchain_ibm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b7d5b7-3be2-4df7-817c-e2f39dd1bbb9",
   "metadata": {},
   "source": [
    "#### Add the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2722fd-725f-4573-889e-5e97bab91fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"WATSONX_API_KEY\"]=\"<>\"\n",
    "os.environ[\"WATSONX_PROJECT_ID\"]=\"<>\"\n",
    "os.environ[\"WATSONX_MODEL_ID\"] = \"meta-llama/llama-3-3-70b-instruct\"\n",
    "os.environ[\"WATSONX_URL\"]=\"https://eu-de.ml.cloud.ibm.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcaffbb-7875-45c5-8f94-dd17f0ac1bdc",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eecd6ec7-db77-4a0d-94f5-7570e0c1b0ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_mcp_adapters.tools import load_mcp_tools\n",
    "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n",
    "from langchain_ibm import ChatWatsonx\n",
    "import os\n",
    "from pydantic import BaseModel, Field \n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a6aea9-f15d-4af3-9330-d97b420cb99d",
   "metadata": {},
   "source": [
    "#### Setting up ChatWatsonx llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b717416-250b-4171-a0a0-d12b0a40dea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    GenParams.DECODING_METHOD: \"greedy\",\n",
    "    GenParams.MAX_NEW_TOKENS: 8000,\n",
    "    GenParams.MIN_NEW_TOKENS: 1,\n",
    "    GenParams.TEMPERATURE: 0.7,\n",
    "    }\n",
    "\n",
    "model = ChatWatsonx(\n",
    "    model_id=os.getenv(\"WATSONX_MODEL\", \"meta-llama/llama-3-3-70b-instruct\"),\n",
    "    apikey=os.getenv(\"WATSONX_API_KEY\"),\n",
    "    project_id=os.getenv(\"WATSONX_PROJECT_ID\"),\n",
    "    url=os.getenv(\"WATSONX_URL\", \"https://eu-de.ml.cloud.ibm.com\"),\n",
    "    parameters=parameters\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2c3f85-d9b7-4f13-8eac-0cf00e1e1ddf",
   "metadata": {},
   "source": [
    "### MCP client creation (sse transport mode) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a45be9-13e7-4894-bf99-650a3c807b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that the ibm-watsonxdata-dl-retrieval-mcp-server MCP server is already running in port 8000 in the localhost with sse transport\n",
    "client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"dl_retrieval\": {\n",
    "            \"transport\": \"sse\",\n",
    "            \"url\": \"http://localhost:8000/sse\",\n",
    "        },\n",
    "    })\n",
    "\n",
    "print(\"Created the mcp client in sse transport mode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a143b0b-b5f1-4db1-9349-b97f17e2c866",
   "metadata": {},
   "source": [
    "#### List the available tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726be9d6-a950-48dd-beaa-431baee7c908",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def printAvailableTools():  \n",
    "    tools = []\n",
    "    try:\n",
    "        print(\"Attempting to create session...\")\n",
    "        async with client.session(server_name=\"dl_retrieval\") as session:\n",
    "            try:\n",
    "                print(\"session created\")\n",
    "                mcp_tools = await load_mcp_tools(session)\n",
    "                tools.extend(mcp_tools)\n",
    "\n",
    "                print(\"\\nAvailable Tools:\")\n",
    "                for i, tool in enumerate(tools, 1):\n",
    "                    print(f\"{i}. {tool.name}\")\n",
    "                    print(f\"   Description: {tool.description}\")\n",
    "                    print(\"-\" * 50)\n",
    "            except Exception as e:\n",
    "                    print(f\"Failed to load MCP tools: {e}\")\n",
    "                    raise\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to create session: {e}\")\n",
    "        raise\n",
    "\n",
    "await printAvailableTools()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ffc250-12cd-4a6c-8389-cdfabba70424",
   "metadata": {},
   "source": [
    "#### Agent response structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35a4572e-08f7-46de-b681-920d93c653c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentResponse(BaseModel):\n",
    "    final_answer: Optional[str] = Field(description=\"Detailed answer for the initial User Query if the answer was found, else provide a clear explanation of why it could not be found and suggest possible next steps or alternatives.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e671eb5d-0766-43d8-a0f1-af6a77ce1db0",
   "metadata": {},
   "source": [
    "#### Creation of LangChain agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c94a3a54-ba3f-4670-a831-d4b979b41299",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def createLangchainAgent(session):\n",
    "    tools = []\n",
    "    mcp_tools = await load_mcp_tools(session)\n",
    "    tools.extend(mcp_tools)\n",
    "    dl_agent = create_react_agent(\n",
    "        model=model, \n",
    "        tools=tools,\n",
    "        prompt=(\n",
    "            \"You are a helpful question answering agent\\n\"\n",
    "            \"Your task is to answer the user query by calling the relevant tools given to you\\n\"\n",
    "        ),\n",
    "        response_format=AgentResponse,\n",
    "    )\n",
    "    print(\"Agent created. Ready to interact!\")\n",
    "    return dl_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1e2adc-7520-4003-8b5c-96dcff84691d",
   "metadata": {},
   "source": [
    "#### Agent invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70d7b455-9dac-4e86-a28d-d981a688d22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def callAgent(dl_agent,user_input):\n",
    "    try:\n",
    "        result = await dl_agent.ainvoke({\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": user_input\n",
    "                }\n",
    "            ]\n",
    "        })\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error during invocation: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f24d9d-ca28-4446-beb4-f8f214f3ec67",
   "metadata": {},
   "source": [
    "#### Creates a LangChain session, initializes the agent, and processes a query asynchronously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c8a907-7dc2-49d4-932f-20b1dc63ed90",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"What is the highest invoice amount\"\n",
    "async def createAndRunAgent():\n",
    "    try:\n",
    "        print(\"Attempting to create session...\")\n",
    "        async with client.session(server_name=\"dl_retrieval\") as session:\n",
    "            print(\"session created\")\n",
    "            dl_agent = await createLangchainAgent(session)\n",
    "            result = await callAgent(dl_agent,user_input)\n",
    "            structured_resp = result.get('structured_response')\n",
    "            if structured_resp and hasattr(structured_resp, 'final_answer'):\n",
    "                print(structured_resp.final_answer)\n",
    "            else:\n",
    "                print(result)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to create session: {e}\")\n",
    "        raise   \n",
    "await createAndRunAgent()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
