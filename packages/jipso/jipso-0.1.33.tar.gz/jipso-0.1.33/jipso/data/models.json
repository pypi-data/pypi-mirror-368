{
  "gpt-4-0613": {
    "platform": "Openai",
    "id": "gpt-4-0613",
    "created": 1686588896,
    "object": "model",
    "owned_by": "openai"
  },
  "gpt-4": {
    "platform": "Openai",
    "id": "gpt-4",
    "created": 1687882411,
    "object": "model",
    "owned_by": "openai"
  },
  "gpt-3.5-turbo": {
    "platform": "Openai",
    "id": "gpt-3.5-turbo",
    "created": 1677610602,
    "object": "model",
    "owned_by": "openai"
  },
  "o4-mini-deep-research-2025-06-26": {
    "platform": "Openai",
    "id": "o4-mini-deep-research-2025-06-26",
    "created": 1750866121,
    "object": "model",
    "owned_by": "system"
  },
  "codex-mini-latest": {
    "platform": "Openai",
    "id": "codex-mini-latest",
    "created": 1746673257,
    "object": "model",
    "owned_by": "system"
  },
  "gpt-4o-realtime-preview-2025-06-03": {
    "platform": "Openai",
    "id": "gpt-4o-realtime-preview-2025-06-03",
    "created": 1748907838,
    "object": "model",
    "owned_by": "system"
  },
  "gpt-4o-audio-preview-2025-06-03": {
    "platform": "Openai",
    "id": "gpt-4o-audio-preview-2025-06-03",
    "created": 1748908498,
    "object": "model",
    "owned_by": "system"
  },
  "o4-mini-deep-research": {
    "platform": "Openai",
    "id": "o4-mini-deep-research",
    "created": 1749685485,
    "object": "model",
    "owned_by": "system"
  },
  "davinci-002": {
    "platform": "Openai",
    "id": "davinci-002",
    "created": 1692634301,
    "object": "model",
    "owned_by": "system"
  },
  "babbage-002": {
    "platform": "Openai",
    "id": "babbage-002",
    "created": 1692634615,
    "object": "model",
    "owned_by": "system"
  },
  "gpt-3.5-turbo-instruct": {
    "platform": "Openai",
    "id": "gpt-3.5-turbo-instruct",
    "created": 1692901427,
    "object": "model",
    "owned_by": "system"
  },
  "gpt-3.5-turbo-instruct-0914": {
    "platform": "Openai",
    "id": "gpt-3.5-turbo-instruct-0914",
    "created": 1694122472,
    "object": "model",
    "owned_by": "system"
  },
  "dall-e-3": {
    "platform": "Openai",
    "id": "dall-e-3",
    "created": 1698785189,
    "object": "model",
    "owned_by": "system"
  },
  "dall-e-2": {
    "platform": "Openai",
    "id": "dall-e-2",
    "created": 1698798177,
    "object": "model",
    "owned_by": "system"
  },
  "gpt-4-1106-preview": {
    "platform": "Openai",
    "id": "gpt-4-1106-preview",
    "created": 1698957206,
    "object": "model",
    "owned_by": "system"
  },
  "gpt-3.5-turbo-1106": {
    "platform": "Openai",
    "id": "gpt-3.5-turbo-1106",
    "created": 1698959748,
    "object": "model",
    "owned_by": "system"
  },
  "tts-1-hd": {
    "platform": "Openai",
    "id": "tts-1-hd",
    "created": 1699046015,
    "object": "model",
    "owned_by": "system"
  },
  "tts-1-1106": {
    "platform": "Openai",
    "id": "tts-1-1106",
    "created": 1699053241,
    "object": "model",
    "owned_by": "system"
  },
  "tts-1-hd-1106": {
    "platform": "Openai",
    "id": "tts-1-hd-1106",
    "created": 1699053533,
    "object": "model",
    "owned_by": "system"
  },
  "text-embedding-3-small": {
    "platform": "Openai",
    "id": "text-embedding-3-small",
    "created": 1705948997,
    "object": "model",
    "owned_by": "system"
  },
  "text-embedding-3-large": {
    "platform": "Openai",
    "id": "text-embedding-3-large",
    "created": 1705953180,
    "object": "model",
    "owned_by": "system"
  },
  "gpt-4-0125-preview": {
    "platform": "Openai",
    "id": "gpt-4-0125-preview",
    "created": 1706037612,
    "object": "model",
    "owned_by": "system"
  },
  "gpt-4-turbo-preview": {
    "platform": "Openai",
    "id": "gpt-4-turbo-preview",
    "created": 1706037777,
    "object": "model",
    "owned_by": "system"
  },
  "gpt-3.5-turbo-0125": {
    "platform": "Openai",
    "id": "gpt-3.5-turbo-0125",
    "created": 1706048358,
    "object": "model",
    "owned_by": "system"
  },
  "gpt-4-turbo": {
    "platform": "Openai",
    "id": "gpt-4-turbo",
    "created": 1712361441,
    "object": "model",
    "owned_by": "system"
  },
  "gpt-4-turbo-2024-04-09": {
    "platform": "Openai",
    "id": "gpt-4-turbo-2024-04-09",
    "created": 1712601677,
    "object": "model",
    "owned_by": "system"
  },
  "gpt-4o": {
    "platform": "Openai",
    "id": "gpt-4o",
    "created": 1715367049,
    "object": "model",
    "owned_by": "system"
  },
  "gpt-4o-2024-05-13": {
    "platform": "Openai",
    "id": "gpt-4o-2024-05-13",
    "created": 1715368132,
    "object": "model",
    "owned_by": "system"
  },
  "gpt-4o-mini-2024-07-18": {
    "platform": "Openai",
    "id": "gpt-4o-mini-2024-07-18",
    "created": 1721172717,
    "object": "model",
    "owned_by": "system"
  },
  "gpt-4o-mini": {
    "platform": "Openai",
    "id": "gpt-4o-mini",
    "created": 1721172741,
    "object": "model",
    "owned_by": "system"
  },
  "gpt-4o-2024-08-06": {
    "platform": "Openai",
    "id": "gpt-4o-2024-08-06",
    "created": 1722814719,
    "object": "model",
    "owned_by": "system"
  },
  "chatgpt-4o-latest": {
    "platform": "Openai",
    "id": "chatgpt-4o-latest",
    "created": 1723515131,
    "object": "model",
    "owned_by": "system"
  },
  "o1-mini-2024-09-12": {
    "platform": "Openai",
    "id": "o1-mini-2024-09-12",
    "created": 1725648979,
    "object": "model",
    "owned_by": "system"
  },
  "o1-mini": {
    "platform": "Openai",
    "id": "o1-mini",
    "created": 1725649008,
    "object": "model",
    "owned_by": "system"
  },
  "gpt-4o-realtime-preview-2024-10-01": {
    "platform": "Openai",
    "id": "gpt-4o-realtime-preview-2024-10-01",
    "created": 1727131766,
    "object": "model",
    "owned_by": "system"
  },
  "gpt-4o-audio-preview-2024-10-01": {
    "platform": "Openai",
    "id": "gpt-4o-audio-preview-2024-10-01",
    "created": 1727389042,
    "object": "model",
    "owned_by": "system"
  },
  "gpt-4o-audio-preview": {
    "platform": "Openai",
    "id": "gpt-4o-audio-preview",
    "created": 1727460443,
    "object": "model",
    "owned_by": "system"
  },
  "gpt-4o-realtime-preview": {
    "platform": "Openai",
    "id": "gpt-4o-realtime-preview",
    "created": 1727659998,
    "object": "model",
    "owned_by": "system"
  },
  "omni-moderation-latest": {
    "platform": "Openai",
    "id": "omni-moderation-latest",
    "created": 1731689265,
    "object": "model",
    "owned_by": "system"
  },
  "omni-moderation-2024-09-26": {
    "platform": "Openai",
    "id": "omni-moderation-2024-09-26",
    "created": 1732734466,
    "object": "model",
    "owned_by": "system"
  },
  "gpt-4o-realtime-preview-2024-12-17": {
    "platform": "Openai",
    "id": "gpt-4o-realtime-preview-2024-12-17",
    "created": 1733945430,
    "object": "model",
    "owned_by": "system"
  },
  "gpt-4o-audio-preview-2024-12-17": {
    "platform": "Openai",
    "id": "gpt-4o-audio-preview-2024-12-17",
    "created": 1734034239,
    "object": "model",
    "owned_by": "system"
  },
  "gpt-4o-mini-realtime-preview-2024-12-17": {
    "platform": "Openai",
    "id": "gpt-4o-mini-realtime-preview-2024-12-17",
    "created": 1734112601,
    "object": "model",
    "owned_by": "system"
  },
  "gpt-4o-mini-audio-preview-2024-12-17": {
    "platform": "Openai",
    "id": "gpt-4o-mini-audio-preview-2024-12-17",
    "created": 1734115920,
    "object": "model",
    "owned_by": "system"
  },
  "o1-2024-12-17": {
    "platform": "Openai",
    "id": "o1-2024-12-17",
    "created": 1734326976,
    "object": "model",
    "owned_by": "system"
  },
  "o1": {
    "platform": "Openai",
    "id": "o1",
    "created": 1734375816,
    "object": "model",
    "owned_by": "system"
  },
  "gpt-4o-mini-realtime-preview": {
    "platform": "Openai",
    "id": "gpt-4o-mini-realtime-preview",
    "created": 1734387380,
    "object": "model",
    "owned_by": "system"
  },
  "gpt-4o-mini-audio-preview": {
    "platform": "Openai",
    "id": "gpt-4o-mini-audio-preview",
    "created": 1734387424,
    "object": "model",
    "owned_by": "system"
  },
  "o3-mini": {
    "platform": "Openai",
    "id": "o3-mini",
    "created": 1737146383,
    "object": "model",
    "owned_by": "system"
  },
  "o3-mini-2025-01-31": {
    "platform": "Openai",
    "id": "o3-mini-2025-01-31",
    "created": 1738010200,
    "object": "model",
    "owned_by": "system"
  },
  "gpt-4o-2024-11-20": {
    "platform": "Openai",
    "id": "gpt-4o-2024-11-20",
    "created": 1739331543,
    "object": "model",
    "owned_by": "system"
  },
  "gpt-4o-search-preview-2025-03-11": {
    "platform": "Openai",
    "id": "gpt-4o-search-preview-2025-03-11",
    "created": 1741388170,
    "object": "model",
    "owned_by": "system"
  },
  "gpt-4o-search-preview": {
    "platform": "Openai",
    "id": "gpt-4o-search-preview",
    "created": 1741388720,
    "object": "model",
    "owned_by": "system"
  },
  "gpt-4o-mini-search-preview-2025-03-11": {
    "platform": "Openai",
    "id": "gpt-4o-mini-search-preview-2025-03-11",
    "created": 1741390858,
    "object": "model",
    "owned_by": "system"
  },
  "gpt-4o-mini-search-preview": {
    "platform": "Openai",
    "id": "gpt-4o-mini-search-preview",
    "created": 1741391161,
    "object": "model",
    "owned_by": "system"
  },
  "gpt-4o-transcribe": {
    "platform": "Openai",
    "id": "gpt-4o-transcribe",
    "created": 1742068463,
    "object": "model",
    "owned_by": "system"
  },
  "gpt-4o-mini-transcribe": {
    "platform": "Openai",
    "id": "gpt-4o-mini-transcribe",
    "created": 1742068596,
    "object": "model",
    "owned_by": "system"
  },
  "o1-pro-2025-03-19": {
    "platform": "Openai",
    "id": "o1-pro-2025-03-19",
    "created": 1742251504,
    "object": "model",
    "owned_by": "system"
  },
  "o1-pro": {
    "platform": "Openai",
    "id": "o1-pro",
    "created": 1742251791,
    "object": "model",
    "owned_by": "system"
  },
  "gpt-4o-mini-tts": {
    "platform": "Openai",
    "id": "gpt-4o-mini-tts",
    "created": 1742403959,
    "object": "model",
    "owned_by": "system"
  },
  "o4-mini-2025-04-16": {
    "platform": "Openai",
    "id": "o4-mini-2025-04-16",
    "created": 1744133506,
    "object": "model",
    "owned_by": "system"
  },
  "o4-mini": {
    "platform": "Openai",
    "id": "o4-mini",
    "created": 1744225351,
    "object": "model",
    "owned_by": "system"
  },
  "gpt-4.1-2025-04-14": {
    "platform": "Openai",
    "id": "gpt-4.1-2025-04-14",
    "created": 1744315746,
    "object": "model",
    "owned_by": "system"
  },
  "gpt-4.1": {
    "platform": "Openai",
    "id": "gpt-4.1",
    "created": 1744316542,
    "object": "model",
    "owned_by": "system"
  },
  "gpt-4.1-mini-2025-04-14": {
    "platform": "Openai",
    "id": "gpt-4.1-mini-2025-04-14",
    "created": 1744317547,
    "object": "model",
    "owned_by": "system"
  },
  "gpt-4.1-mini": {
    "platform": "Openai",
    "id": "gpt-4.1-mini",
    "created": 1744318173,
    "object": "model",
    "owned_by": "system"
  },
  "gpt-4.1-nano-2025-04-14": {
    "platform": "Openai",
    "id": "gpt-4.1-nano-2025-04-14",
    "created": 1744321025,
    "object": "model",
    "owned_by": "system"
  },
  "gpt-4.1-nano": {
    "platform": "Openai",
    "id": "gpt-4.1-nano",
    "created": 1744321707,
    "object": "model",
    "owned_by": "system"
  },
  "gpt-image-1": {
    "platform": "Openai",
    "id": "gpt-image-1",
    "created": 1745517030,
    "object": "model",
    "owned_by": "system"
  },
  "gpt-3.5-turbo-16k": {
    "platform": "Openai",
    "id": "gpt-3.5-turbo-16k",
    "created": 1683758102,
    "object": "model",
    "owned_by": "openai-internal"
  },
  "tts-1": {
    "platform": "Openai",
    "id": "tts-1",
    "created": 1681940951,
    "object": "model",
    "owned_by": "openai-internal"
  },
  "whisper-1": {
    "platform": "Openai",
    "id": "whisper-1",
    "created": 1677532384,
    "object": "model",
    "owned_by": "openai-internal"
  },
  "text-embedding-ada-002": {
    "platform": "Openai",
    "id": "text-embedding-ada-002",
    "created": 1671217299,
    "object": "model",
    "owned_by": "openai-internal"
  },
  "claude-opus-4-20250514": {
    "platform": "Anthropic",
    "id": "claude-opus-4-20250514",
    "created_at": 1747872000,
    "display_name": "Claude Opus 4",
    "type": "model"
  },
  "claude-sonnet-4-20250514": {
    "platform": "Anthropic",
    "id": "claude-sonnet-4-20250514",
    "created_at": 1747872000,
    "display_name": "Claude Sonnet 4",
    "type": "model"
  },
  "claude-3-7-sonnet-20250219": {
    "platform": "Anthropic",
    "id": "claude-3-7-sonnet-20250219",
    "created_at": 1740355200,
    "display_name": "Claude Sonnet 3.7",
    "type": "model"
  },
  "claude-3-5-sonnet-20241022": {
    "platform": "Anthropic",
    "id": "claude-3-5-sonnet-20241022",
    "created_at": 1729555200,
    "display_name": "Claude Sonnet 3.5 (New)",
    "type": "model"
  },
  "claude-3-5-haiku-20241022": {
    "platform": "Anthropic",
    "id": "claude-3-5-haiku-20241022",
    "created_at": 1729555200,
    "display_name": "Claude Haiku 3.5",
    "type": "model"
  },
  "claude-3-5-sonnet-20240620": {
    "platform": "Anthropic",
    "id": "claude-3-5-sonnet-20240620",
    "created_at": 1718841600,
    "display_name": "Claude Sonnet 3.5 (Old)",
    "type": "model"
  },
  "claude-3-haiku-20240307": {
    "platform": "Anthropic",
    "id": "claude-3-haiku-20240307",
    "created_at": 1709769600,
    "display_name": "Claude Haiku 3",
    "type": "model"
  },
  "claude-3-opus-20240229": {
    "platform": "Anthropic",
    "id": "claude-3-opus-20240229",
    "created_at": 1709164800,
    "display_name": "Claude Opus 3",
    "type": "model"
  },
  "models\/embedding-gecko-001": {
    "platform": "Gemini",
    "name": "models\/embedding-gecko-001",
    "base_model_id": "",
    "version": "001",
    "display_name": "Embedding Gecko",
    "description": "Obtain a distributed representation of a text.",
    "input_token_limit": 1024,
    "output_token_limit": 1,
    "supported_generation_methods": [
      "embedText",
      "countTextTokens"
    ],
    "temperature": null,
    "max_temperature": null,
    "top_p": null,
    "top_k": null
  },
  "models\/gemini-1.5-pro-latest": {
    "platform": "Gemini",
    "name": "models\/gemini-1.5-pro-latest",
    "base_model_id": "",
    "version": "001",
    "display_name": "Gemini 1.5 Pro Latest",
    "description": "Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens.",
    "input_token_limit": 2000000,
    "output_token_limit": 8192,
    "supported_generation_methods": [
      "generateContent",
      "countTokens"
    ],
    "temperature": 1.0,
    "max_temperature": 2.0,
    "top_p": 0.95,
    "top_k": 40
  },
  "models\/gemini-1.5-pro-002": {
    "platform": "Gemini",
    "name": "models\/gemini-1.5-pro-002",
    "base_model_id": "",
    "version": "002",
    "display_name": "Gemini 1.5 Pro 002",
    "description": "Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in September of 2024.",
    "input_token_limit": 2000000,
    "output_token_limit": 8192,
    "supported_generation_methods": [
      "generateContent",
      "countTokens",
      "createCachedContent"
    ],
    "temperature": 1.0,
    "max_temperature": 2.0,
    "top_p": 0.95,
    "top_k": 40
  },
  "models\/gemini-1.5-pro": {
    "platform": "Gemini",
    "name": "models\/gemini-1.5-pro",
    "base_model_id": "",
    "version": "001",
    "display_name": "Gemini 1.5 Pro",
    "description": "Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in May of 2024.",
    "input_token_limit": 2000000,
    "output_token_limit": 8192,
    "supported_generation_methods": [
      "generateContent",
      "countTokens"
    ],
    "temperature": 1.0,
    "max_temperature": 2.0,
    "top_p": 0.95,
    "top_k": 40
  },
  "models\/gemini-1.5-flash-latest": {
    "platform": "Gemini",
    "name": "models\/gemini-1.5-flash-latest",
    "base_model_id": "",
    "version": "001",
    "display_name": "Gemini 1.5 Flash Latest",
    "description": "Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks.",
    "input_token_limit": 1000000,
    "output_token_limit": 8192,
    "supported_generation_methods": [
      "generateContent",
      "countTokens"
    ],
    "temperature": 1.0,
    "max_temperature": 2.0,
    "top_p": 0.95,
    "top_k": 40
  },
  "models\/gemini-1.5-flash": {
    "platform": "Gemini",
    "name": "models\/gemini-1.5-flash",
    "base_model_id": "",
    "version": "001",
    "display_name": "Gemini 1.5 Flash",
    "description": "Alias that points to the most recent stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks.",
    "input_token_limit": 1000000,
    "output_token_limit": 8192,
    "supported_generation_methods": [
      "generateContent",
      "countTokens"
    ],
    "temperature": 1.0,
    "max_temperature": 2.0,
    "top_p": 0.95,
    "top_k": 40
  },
  "models\/gemini-1.5-flash-002": {
    "platform": "Gemini",
    "name": "models\/gemini-1.5-flash-002",
    "base_model_id": "",
    "version": "002",
    "display_name": "Gemini 1.5 Flash 002",
    "description": "Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in September of 2024.",
    "input_token_limit": 1000000,
    "output_token_limit": 8192,
    "supported_generation_methods": [
      "generateContent",
      "countTokens",
      "createCachedContent"
    ],
    "temperature": 1.0,
    "max_temperature": 2.0,
    "top_p": 0.95,
    "top_k": 40
  },
  "models\/gemini-1.5-flash-8b": {
    "platform": "Gemini",
    "name": "models\/gemini-1.5-flash-8b",
    "base_model_id": "",
    "version": "001",
    "display_name": "Gemini 1.5 Flash-8B",
    "description": "Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.",
    "input_token_limit": 1000000,
    "output_token_limit": 8192,
    "supported_generation_methods": [
      "createCachedContent",
      "generateContent",
      "countTokens"
    ],
    "temperature": 1.0,
    "max_temperature": 2.0,
    "top_p": 0.95,
    "top_k": 40
  },
  "models\/gemini-1.5-flash-8b-001": {
    "platform": "Gemini",
    "name": "models\/gemini-1.5-flash-8b-001",
    "base_model_id": "",
    "version": "001",
    "display_name": "Gemini 1.5 Flash-8B 001",
    "description": "Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.",
    "input_token_limit": 1000000,
    "output_token_limit": 8192,
    "supported_generation_methods": [
      "createCachedContent",
      "generateContent",
      "countTokens"
    ],
    "temperature": 1.0,
    "max_temperature": 2.0,
    "top_p": 0.95,
    "top_k": 40
  },
  "models\/gemini-1.5-flash-8b-latest": {
    "platform": "Gemini",
    "name": "models\/gemini-1.5-flash-8b-latest",
    "base_model_id": "",
    "version": "001",
    "display_name": "Gemini 1.5 Flash-8B Latest",
    "description": "Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.",
    "input_token_limit": 1000000,
    "output_token_limit": 8192,
    "supported_generation_methods": [
      "createCachedContent",
      "generateContent",
      "countTokens"
    ],
    "temperature": 1.0,
    "max_temperature": 2.0,
    "top_p": 0.95,
    "top_k": 40
  },
  "models\/gemini-2.5-pro-preview-03-25": {
    "platform": "Gemini",
    "name": "models\/gemini-2.5-pro-preview-03-25",
    "base_model_id": "",
    "version": "2.5-preview-03-25",
    "display_name": "Gemini 2.5 Pro Preview 03-25",
    "description": "Gemini 2.5 Pro Preview 03-25",
    "input_token_limit": 1048576,
    "output_token_limit": 65536,
    "supported_generation_methods": [
      "generateContent",
      "countTokens",
      "createCachedContent",
      "batchGenerateContent"
    ],
    "temperature": 1.0,
    "max_temperature": 2.0,
    "top_p": 0.95,
    "top_k": 64
  },
  "models\/gemini-2.5-flash-preview-05-20": {
    "platform": "Gemini",
    "name": "models\/gemini-2.5-flash-preview-05-20",
    "base_model_id": "",
    "version": "2.5-preview-05-20",
    "display_name": "Gemini 2.5 Flash Preview 05-20",
    "description": "Preview release (April 17th, 2025) of Gemini 2.5 Flash",
    "input_token_limit": 1048576,
    "output_token_limit": 65536,
    "supported_generation_methods": [
      "generateContent",
      "countTokens",
      "createCachedContent",
      "batchGenerateContent"
    ],
    "temperature": 1.0,
    "max_temperature": 2.0,
    "top_p": 0.95,
    "top_k": 64
  },
  "models\/gemini-2.5-flash": {
    "platform": "Gemini",
    "name": "models\/gemini-2.5-flash",
    "base_model_id": "",
    "version": "001",
    "display_name": "Gemini 2.5 Flash",
    "description": "Stable version of Gemini 2.5 Flash, our mid-size multimodal model that supports up to 1 million tokens, released in June of 2025.",
    "input_token_limit": 1048576,
    "output_token_limit": 65536,
    "supported_generation_methods": [
      "generateContent",
      "countTokens",
      "createCachedContent",
      "batchGenerateContent"
    ],
    "temperature": 1.0,
    "max_temperature": 2.0,
    "top_p": 0.95,
    "top_k": 64
  },
  "models\/gemini-2.5-flash-lite-preview-06-17": {
    "platform": "Gemini",
    "name": "models\/gemini-2.5-flash-lite-preview-06-17",
    "base_model_id": "",
    "version": "2.5-preview-06-17",
    "display_name": "Gemini 2.5 Flash-Lite Preview 06-17",
    "description": "Preview release (June 11th, 2025) of Gemini 2.5 Flash-Lite",
    "input_token_limit": 1048576,
    "output_token_limit": 65536,
    "supported_generation_methods": [
      "generateContent",
      "countTokens",
      "createCachedContent",
      "batchGenerateContent"
    ],
    "temperature": 1.0,
    "max_temperature": 2.0,
    "top_p": 0.95,
    "top_k": 64
  },
  "models\/gemini-2.5-pro-preview-05-06": {
    "platform": "Gemini",
    "name": "models\/gemini-2.5-pro-preview-05-06",
    "base_model_id": "",
    "version": "2.5-preview-05-06",
    "display_name": "Gemini 2.5 Pro Preview 05-06",
    "description": "Preview release (May 6th, 2025) of Gemini 2.5 Pro",
    "input_token_limit": 1048576,
    "output_token_limit": 65536,
    "supported_generation_methods": [
      "generateContent",
      "countTokens",
      "createCachedContent",
      "batchGenerateContent"
    ],
    "temperature": 1.0,
    "max_temperature": 2.0,
    "top_p": 0.95,
    "top_k": 64
  },
  "models\/gemini-2.5-pro-preview-06-05": {
    "platform": "Gemini",
    "name": "models\/gemini-2.5-pro-preview-06-05",
    "base_model_id": "",
    "version": "2.5-preview-06-05",
    "display_name": "Gemini 2.5 Pro Preview",
    "description": "Preview release (June 5th, 2025) of Gemini 2.5 Pro",
    "input_token_limit": 1048576,
    "output_token_limit": 65536,
    "supported_generation_methods": [
      "generateContent",
      "countTokens",
      "createCachedContent",
      "batchGenerateContent"
    ],
    "temperature": 1.0,
    "max_temperature": 2.0,
    "top_p": 0.95,
    "top_k": 64
  },
  "models\/gemini-2.5-pro": {
    "platform": "Gemini",
    "name": "models\/gemini-2.5-pro",
    "base_model_id": "",
    "version": "2.5",
    "display_name": "Gemini 2.5 Pro",
    "description": "Stable release (June 17th, 2025) of Gemini 2.5 Pro",
    "input_token_limit": 1048576,
    "output_token_limit": 65536,
    "supported_generation_methods": [
      "generateContent",
      "countTokens",
      "createCachedContent",
      "batchGenerateContent"
    ],
    "temperature": 1.0,
    "max_temperature": 2.0,
    "top_p": 0.95,
    "top_k": 64
  },
  "models\/gemini-2.0-flash-exp": {
    "platform": "Gemini",
    "name": "models\/gemini-2.0-flash-exp",
    "base_model_id": "",
    "version": "2.0",
    "display_name": "Gemini 2.0 Flash Experimental",
    "description": "Gemini 2.0 Flash Experimental",
    "input_token_limit": 1048576,
    "output_token_limit": 8192,
    "supported_generation_methods": [
      "generateContent",
      "countTokens",
      "bidiGenerateContent"
    ],
    "temperature": 1.0,
    "max_temperature": 2.0,
    "top_p": 0.95,
    "top_k": 40
  },
  "models\/gemini-2.0-flash": {
    "platform": "Gemini",
    "name": "models\/gemini-2.0-flash",
    "base_model_id": "",
    "version": "2.0",
    "display_name": "Gemini 2.0 Flash",
    "description": "Gemini 2.0 Flash",
    "input_token_limit": 1048576,
    "output_token_limit": 8192,
    "supported_generation_methods": [
      "generateContent",
      "countTokens",
      "createCachedContent",
      "batchGenerateContent"
    ],
    "temperature": 1.0,
    "max_temperature": 2.0,
    "top_p": 0.95,
    "top_k": 40
  },
  "models\/gemini-2.0-flash-001": {
    "platform": "Gemini",
    "name": "models\/gemini-2.0-flash-001",
    "base_model_id": "",
    "version": "2.0",
    "display_name": "Gemini 2.0 Flash 001",
    "description": "Stable version of Gemini 2.0 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in January of 2025.",
    "input_token_limit": 1048576,
    "output_token_limit": 8192,
    "supported_generation_methods": [
      "generateContent",
      "countTokens",
      "createCachedContent",
      "batchGenerateContent"
    ],
    "temperature": 1.0,
    "max_temperature": 2.0,
    "top_p": 0.95,
    "top_k": 40
  },
  "models\/gemini-2.0-flash-exp-image-generation": {
    "platform": "Gemini",
    "name": "models\/gemini-2.0-flash-exp-image-generation",
    "base_model_id": "",
    "version": "2.0",
    "display_name": "Gemini 2.0 Flash (Image Generation) Experimental",
    "description": "Gemini 2.0 Flash (Image Generation) Experimental",
    "input_token_limit": 1048576,
    "output_token_limit": 8192,
    "supported_generation_methods": [
      "generateContent",
      "countTokens",
      "bidiGenerateContent"
    ],
    "temperature": 1.0,
    "max_temperature": 2.0,
    "top_p": 0.95,
    "top_k": 40
  },
  "models\/gemini-2.0-flash-lite-001": {
    "platform": "Gemini",
    "name": "models\/gemini-2.0-flash-lite-001",
    "base_model_id": "",
    "version": "2.0",
    "display_name": "Gemini 2.0 Flash-Lite 001",
    "description": "Stable version of Gemini 2.0 Flash-Lite",
    "input_token_limit": 1048576,
    "output_token_limit": 8192,
    "supported_generation_methods": [
      "generateContent",
      "countTokens",
      "createCachedContent",
      "batchGenerateContent"
    ],
    "temperature": 1.0,
    "max_temperature": 2.0,
    "top_p": 0.95,
    "top_k": 40
  },
  "models\/gemini-2.0-flash-lite": {
    "platform": "Gemini",
    "name": "models\/gemini-2.0-flash-lite",
    "base_model_id": "",
    "version": "2.0",
    "display_name": "Gemini 2.0 Flash-Lite",
    "description": "Gemini 2.0 Flash-Lite",
    "input_token_limit": 1048576,
    "output_token_limit": 8192,
    "supported_generation_methods": [
      "generateContent",
      "countTokens",
      "createCachedContent",
      "batchGenerateContent"
    ],
    "temperature": 1.0,
    "max_temperature": 2.0,
    "top_p": 0.95,
    "top_k": 40
  },
  "models\/gemini-2.0-flash-preview-image-generation": {
    "platform": "Gemini",
    "name": "models\/gemini-2.0-flash-preview-image-generation",
    "base_model_id": "",
    "version": "2.0",
    "display_name": "Gemini 2.0 Flash Preview Image Generation",
    "description": "Gemini 2.0 Flash Preview Image Generation",
    "input_token_limit": 32768,
    "output_token_limit": 8192,
    "supported_generation_methods": [
      "generateContent",
      "countTokens"
    ],
    "temperature": 1.0,
    "max_temperature": 2.0,
    "top_p": 0.95,
    "top_k": 64
  },
  "models\/gemini-2.0-flash-lite-preview-02-05": {
    "platform": "Gemini",
    "name": "models\/gemini-2.0-flash-lite-preview-02-05",
    "base_model_id": "",
    "version": "preview-02-05",
    "display_name": "Gemini 2.0 Flash-Lite Preview 02-05",
    "description": "Preview release (February 5th, 2025) of Gemini 2.0 Flash-Lite",
    "input_token_limit": 1048576,
    "output_token_limit": 8192,
    "supported_generation_methods": [
      "generateContent",
      "countTokens",
      "createCachedContent",
      "batchGenerateContent"
    ],
    "temperature": 1.0,
    "max_temperature": 2.0,
    "top_p": 0.95,
    "top_k": 40
  },
  "models\/gemini-2.0-flash-lite-preview": {
    "platform": "Gemini",
    "name": "models\/gemini-2.0-flash-lite-preview",
    "base_model_id": "",
    "version": "preview-02-05",
    "display_name": "Gemini 2.0 Flash-Lite Preview",
    "description": "Preview release (February 5th, 2025) of Gemini 2.0 Flash-Lite",
    "input_token_limit": 1048576,
    "output_token_limit": 8192,
    "supported_generation_methods": [
      "generateContent",
      "countTokens",
      "createCachedContent",
      "batchGenerateContent"
    ],
    "temperature": 1.0,
    "max_temperature": 2.0,
    "top_p": 0.95,
    "top_k": 40
  },
  "models\/gemini-2.0-pro-exp": {
    "platform": "Gemini",
    "name": "models\/gemini-2.0-pro-exp",
    "base_model_id": "",
    "version": "2.5-exp-03-25",
    "display_name": "Gemini 2.0 Pro Experimental",
    "description": "Experimental release (March 25th, 2025) of Gemini 2.5 Pro",
    "input_token_limit": 1048576,
    "output_token_limit": 65536,
    "supported_generation_methods": [
      "generateContent",
      "countTokens",
      "createCachedContent",
      "batchGenerateContent"
    ],
    "temperature": 1.0,
    "max_temperature": 2.0,
    "top_p": 0.95,
    "top_k": 64
  },
  "models\/gemini-2.0-pro-exp-02-05": {
    "platform": "Gemini",
    "name": "models\/gemini-2.0-pro-exp-02-05",
    "base_model_id": "",
    "version": "2.5-exp-03-25",
    "display_name": "Gemini 2.0 Pro Experimental 02-05",
    "description": "Experimental release (March 25th, 2025) of Gemini 2.5 Pro",
    "input_token_limit": 1048576,
    "output_token_limit": 65536,
    "supported_generation_methods": [
      "generateContent",
      "countTokens",
      "createCachedContent",
      "batchGenerateContent"
    ],
    "temperature": 1.0,
    "max_temperature": 2.0,
    "top_p": 0.95,
    "top_k": 64
  },
  "models\/gemini-exp-1206": {
    "platform": "Gemini",
    "name": "models\/gemini-exp-1206",
    "base_model_id": "",
    "version": "2.5-exp-03-25",
    "display_name": "Gemini Experimental 1206",
    "description": "Experimental release (March 25th, 2025) of Gemini 2.5 Pro",
    "input_token_limit": 1048576,
    "output_token_limit": 65536,
    "supported_generation_methods": [
      "generateContent",
      "countTokens",
      "createCachedContent",
      "batchGenerateContent"
    ],
    "temperature": 1.0,
    "max_temperature": 2.0,
    "top_p": 0.95,
    "top_k": 64
  },
  "models\/gemini-2.0-flash-thinking-exp-01-21": {
    "platform": "Gemini",
    "name": "models\/gemini-2.0-flash-thinking-exp-01-21",
    "base_model_id": "",
    "version": "2.5-preview-05-20",
    "display_name": "Gemini 2.5 Flash Preview 05-20",
    "description": "Preview release (April 17th, 2025) of Gemini 2.5 Flash",
    "input_token_limit": 1048576,
    "output_token_limit": 65536,
    "supported_generation_methods": [
      "generateContent",
      "countTokens",
      "createCachedContent",
      "batchGenerateContent"
    ],
    "temperature": 1.0,
    "max_temperature": 2.0,
    "top_p": 0.95,
    "top_k": 64
  },
  "models\/gemini-2.0-flash-thinking-exp": {
    "platform": "Gemini",
    "name": "models\/gemini-2.0-flash-thinking-exp",
    "base_model_id": "",
    "version": "2.5-preview-05-20",
    "display_name": "Gemini 2.5 Flash Preview 05-20",
    "description": "Preview release (April 17th, 2025) of Gemini 2.5 Flash",
    "input_token_limit": 1048576,
    "output_token_limit": 65536,
    "supported_generation_methods": [
      "generateContent",
      "countTokens",
      "createCachedContent",
      "batchGenerateContent"
    ],
    "temperature": 1.0,
    "max_temperature": 2.0,
    "top_p": 0.95,
    "top_k": 64
  },
  "models\/gemini-2.0-flash-thinking-exp-1219": {
    "platform": "Gemini",
    "name": "models\/gemini-2.0-flash-thinking-exp-1219",
    "base_model_id": "",
    "version": "2.5-preview-05-20",
    "display_name": "Gemini 2.5 Flash Preview 05-20",
    "description": "Preview release (April 17th, 2025) of Gemini 2.5 Flash",
    "input_token_limit": 1048576,
    "output_token_limit": 65536,
    "supported_generation_methods": [
      "generateContent",
      "countTokens",
      "createCachedContent",
      "batchGenerateContent"
    ],
    "temperature": 1.0,
    "max_temperature": 2.0,
    "top_p": 0.95,
    "top_k": 64
  },
  "models\/gemini-2.5-flash-preview-tts": {
    "platform": "Gemini",
    "name": "models\/gemini-2.5-flash-preview-tts",
    "base_model_id": "",
    "version": "gemini-2.5-flash-exp-tts-2025-05-19",
    "display_name": "Gemini 2.5 Flash Preview TTS",
    "description": "Gemini 2.5 Flash Preview TTS",
    "input_token_limit": 8192,
    "output_token_limit": 16384,
    "supported_generation_methods": [
      "countTokens",
      "generateContent"
    ],
    "temperature": 1.0,
    "max_temperature": 2.0,
    "top_p": 0.95,
    "top_k": 64
  },
  "models\/gemini-2.5-pro-preview-tts": {
    "platform": "Gemini",
    "name": "models\/gemini-2.5-pro-preview-tts",
    "base_model_id": "",
    "version": "gemini-2.5-pro-preview-tts-2025-05-19",
    "display_name": "Gemini 2.5 Pro Preview TTS",
    "description": "Gemini 2.5 Pro Preview TTS",
    "input_token_limit": 8192,
    "output_token_limit": 16384,
    "supported_generation_methods": [
      "countTokens",
      "generateContent"
    ],
    "temperature": 1.0,
    "max_temperature": 2.0,
    "top_p": 0.95,
    "top_k": 64
  },
  "models\/learnlm-2.0-flash-experimental": {
    "platform": "Gemini",
    "name": "models\/learnlm-2.0-flash-experimental",
    "base_model_id": "",
    "version": "2.0",
    "display_name": "LearnLM 2.0 Flash Experimental",
    "description": "LearnLM 2.0 Flash Experimental",
    "input_token_limit": 1048576,
    "output_token_limit": 32768,
    "supported_generation_methods": [
      "generateContent",
      "countTokens"
    ],
    "temperature": 1.0,
    "max_temperature": 2.0,
    "top_p": 0.95,
    "top_k": 64
  },
  "models\/gemma-3-1b-it": {
    "platform": "Gemini",
    "name": "models\/gemma-3-1b-it",
    "base_model_id": "",
    "version": "001",
    "display_name": "Gemma 3 1B",
    "description": "",
    "input_token_limit": 32768,
    "output_token_limit": 8192,
    "supported_generation_methods": [
      "generateContent",
      "countTokens"
    ],
    "temperature": 1.0,
    "max_temperature": null,
    "top_p": 0.95,
    "top_k": 64
  },
  "models\/gemma-3-4b-it": {
    "platform": "Gemini",
    "name": "models\/gemma-3-4b-it",
    "base_model_id": "",
    "version": "001",
    "display_name": "Gemma 3 4B",
    "description": "",
    "input_token_limit": 32768,
    "output_token_limit": 8192,
    "supported_generation_methods": [
      "generateContent",
      "countTokens"
    ],
    "temperature": 1.0,
    "max_temperature": null,
    "top_p": 0.95,
    "top_k": 64
  },
  "models\/gemma-3-12b-it": {
    "platform": "Gemini",
    "name": "models\/gemma-3-12b-it",
    "base_model_id": "",
    "version": "001",
    "display_name": "Gemma 3 12B",
    "description": "",
    "input_token_limit": 32768,
    "output_token_limit": 8192,
    "supported_generation_methods": [
      "generateContent",
      "countTokens"
    ],
    "temperature": 1.0,
    "max_temperature": null,
    "top_p": 0.95,
    "top_k": 64
  },
  "models\/gemma-3-27b-it": {
    "platform": "Gemini",
    "name": "models\/gemma-3-27b-it",
    "base_model_id": "",
    "version": "001",
    "display_name": "Gemma 3 27B",
    "description": "",
    "input_token_limit": 131072,
    "output_token_limit": 8192,
    "supported_generation_methods": [
      "generateContent",
      "countTokens"
    ],
    "temperature": 1.0,
    "max_temperature": null,
    "top_p": 0.95,
    "top_k": 64
  },
  "models\/gemma-3n-e4b-it": {
    "platform": "Gemini",
    "name": "models\/gemma-3n-e4b-it",
    "base_model_id": "",
    "version": "001",
    "display_name": "Gemma 3n E4B",
    "description": "",
    "input_token_limit": 8192,
    "output_token_limit": 2048,
    "supported_generation_methods": [
      "generateContent",
      "countTokens"
    ],
    "temperature": 1.0,
    "max_temperature": null,
    "top_p": 0.95,
    "top_k": 64
  },
  "models\/gemma-3n-e2b-it": {
    "platform": "Gemini",
    "name": "models\/gemma-3n-e2b-it",
    "base_model_id": "",
    "version": "001",
    "display_name": "Gemma 3n E2B",
    "description": "",
    "input_token_limit": 8192,
    "output_token_limit": 2048,
    "supported_generation_methods": [
      "generateContent",
      "countTokens"
    ],
    "temperature": 1.0,
    "max_temperature": null,
    "top_p": 0.95,
    "top_k": 64
  },
  "models\/gemini-2.5-flash-lite": {
    "platform": "Gemini",
    "name": "models\/gemini-2.5-flash-lite",
    "base_model_id": "",
    "version": "001",
    "display_name": "Gemini 2.5 Flash-Lite",
    "description": "Stable verion of Gemini 2.5 Flash-Lite, released in July of 2025",
    "input_token_limit": 1048576,
    "output_token_limit": 65536,
    "supported_generation_methods": [
      "generateContent",
      "countTokens",
      "createCachedContent",
      "batchGenerateContent"
    ],
    "temperature": 1.0,
    "max_temperature": 2.0,
    "top_p": 0.95,
    "top_k": 64
  },
  "models\/embedding-001": {
    "platform": "Gemini",
    "name": "models\/embedding-001",
    "base_model_id": "",
    "version": "001",
    "display_name": "Embedding 001",
    "description": "Obtain a distributed representation of a text.",
    "input_token_limit": 2048,
    "output_token_limit": 1,
    "supported_generation_methods": [
      "embedContent"
    ],
    "temperature": null,
    "max_temperature": null,
    "top_p": null,
    "top_k": null
  },
  "models\/text-embedding-004": {
    "platform": "Gemini",
    "name": "models\/text-embedding-004",
    "base_model_id": "",
    "version": "004",
    "display_name": "Text Embedding 004",
    "description": "Obtain a distributed representation of a text.",
    "input_token_limit": 2048,
    "output_token_limit": 1,
    "supported_generation_methods": [
      "embedContent"
    ],
    "temperature": null,
    "max_temperature": null,
    "top_p": null,
    "top_k": null
  },
  "models\/gemini-embedding-exp-03-07": {
    "platform": "Gemini",
    "name": "models\/gemini-embedding-exp-03-07",
    "base_model_id": "",
    "version": "exp-03-07",
    "display_name": "Gemini Embedding Experimental 03-07",
    "description": "Obtain a distributed representation of a text.",
    "input_token_limit": 8192,
    "output_token_limit": 1,
    "supported_generation_methods": [
      "embedContent",
      "countTextTokens",
      "countTokens"
    ],
    "temperature": null,
    "max_temperature": null,
    "top_p": null,
    "top_k": null
  },
  "models\/gemini-embedding-exp": {
    "platform": "Gemini",
    "name": "models\/gemini-embedding-exp",
    "base_model_id": "",
    "version": "exp-03-07",
    "display_name": "Gemini Embedding Experimental",
    "description": "Obtain a distributed representation of a text.",
    "input_token_limit": 8192,
    "output_token_limit": 1,
    "supported_generation_methods": [
      "embedContent",
      "countTextTokens",
      "countTokens"
    ],
    "temperature": null,
    "max_temperature": null,
    "top_p": null,
    "top_k": null
  },
  "models\/gemini-embedding-001": {
    "platform": "Gemini",
    "name": "models\/gemini-embedding-001",
    "base_model_id": "",
    "version": "001",
    "display_name": "Gemini Embedding 001",
    "description": "Obtain a distributed representation of a text.",
    "input_token_limit": 2048,
    "output_token_limit": 1,
    "supported_generation_methods": [
      "embedContent",
      "countTextTokens",
      "countTokens"
    ],
    "temperature": null,
    "max_temperature": null,
    "top_p": null,
    "top_k": null
  },
  "models\/aqa": {
    "platform": "Gemini",
    "name": "models\/aqa",
    "base_model_id": "",
    "version": "001",
    "display_name": "Model that performs Attributed Question Answering.",
    "description": "Model trained to return answers to questions that are grounded in provided sources, along with estimating answerable probability.",
    "input_token_limit": 7168,
    "output_token_limit": 1024,
    "supported_generation_methods": [
      "generateAnswer"
    ],
    "temperature": 0.2,
    "max_temperature": null,
    "top_p": 1.0,
    "top_k": 40
  },
  "models\/imagen-3.0-generate-002": {
    "platform": "Gemini",
    "name": "models\/imagen-3.0-generate-002",
    "base_model_id": "",
    "version": "002",
    "display_name": "Imagen 3.0 002 model",
    "description": "Vertex served Imagen 3.0 002 model",
    "input_token_limit": 480,
    "output_token_limit": 8192,
    "supported_generation_methods": [
      "predict"
    ],
    "temperature": null,
    "max_temperature": null,
    "top_p": null,
    "top_k": null
  },
  "models\/imagen-4.0-generate-preview-06-06": {
    "platform": "Gemini",
    "name": "models\/imagen-4.0-generate-preview-06-06",
    "base_model_id": "",
    "version": "01",
    "display_name": "Imagen 4 (Preview)",
    "description": "Vertex served Imagen 4.0 model",
    "input_token_limit": 480,
    "output_token_limit": 8192,
    "supported_generation_methods": [
      "predict"
    ],
    "temperature": null,
    "max_temperature": null,
    "top_p": null,
    "top_k": null
  },
  "models\/imagen-4.0-ultra-generate-preview-06-06": {
    "platform": "Gemini",
    "name": "models\/imagen-4.0-ultra-generate-preview-06-06",
    "base_model_id": "",
    "version": "01",
    "display_name": "Imagen 4 Ultra (Preview)",
    "description": "Vertex served Imagen 4.0 ultra model",
    "input_token_limit": 480,
    "output_token_limit": 8192,
    "supported_generation_methods": [
      "predict"
    ],
    "temperature": null,
    "max_temperature": null,
    "top_p": null,
    "top_k": null
  },
  "models\/veo-2.0-generate-001": {
    "platform": "Gemini",
    "name": "models\/veo-2.0-generate-001",
    "base_model_id": "",
    "version": "2.0",
    "display_name": "Veo 2",
    "description": "Vertex served Veo 2 model. Access to this model requires billing to be enabled on the associated Google Cloud Platform account. Please visit https:\/\/console.cloud.google.com\/billing to enable it.",
    "input_token_limit": 480,
    "output_token_limit": 8192,
    "supported_generation_methods": [
      "predictLongRunning"
    ],
    "temperature": null,
    "max_temperature": null,
    "top_p": null,
    "top_k": null
  },
  "models\/veo-3.0-generate-preview": {
    "platform": "Gemini",
    "name": "models\/veo-3.0-generate-preview",
    "base_model_id": "",
    "version": "3.0",
    "display_name": "Veo 3",
    "description": "Veo 3 preview. Access to this model requires billing to be enabled on the associated Google Cloud Platform account. Please visit https:\/\/console.cloud.google.com\/billing to enable it.",
    "input_token_limit": 480,
    "output_token_limit": 8192,
    "supported_generation_methods": [
      "predictLongRunning"
    ],
    "temperature": null,
    "max_temperature": null,
    "top_p": null,
    "top_k": null
  },
  "models\/veo-3.0-fast-generate-preview": {
    "platform": "Gemini",
    "name": "models\/veo-3.0-fast-generate-preview",
    "base_model_id": "",
    "version": "3.0",
    "display_name": "Veo 3 fast",
    "description": "Veo 3 fast preview. Access to this model requires billing to be enabled on the associated Google Cloud Platform account. Please visit https:\/\/console.cloud.google.com\/billing to enable it.",
    "input_token_limit": 480,
    "output_token_limit": 8192,
    "supported_generation_methods": [
      "predictLongRunning"
    ],
    "temperature": null,
    "max_temperature": null,
    "top_p": null,
    "top_k": null
  },
  "models\/gemini-2.5-flash-preview-native-audio-dialog": {
    "platform": "Gemini",
    "name": "models\/gemini-2.5-flash-preview-native-audio-dialog",
    "base_model_id": "",
    "version": "gemini-2.5-flash-preview-native-audio-dialog-2025-05-19",
    "display_name": "Gemini 2.5 Flash Preview Native Audio Dialog",
    "description": "Gemini 2.5 Flash Preview Native Audio Dialog",
    "input_token_limit": 131072,
    "output_token_limit": 8192,
    "supported_generation_methods": [
      "countTokens",
      "bidiGenerateContent"
    ],
    "temperature": 1.0,
    "max_temperature": 2.0,
    "top_p": 0.95,
    "top_k": 64
  },
  "models\/gemini-2.5-flash-exp-native-audio-thinking-dialog": {
    "platform": "Gemini",
    "name": "models\/gemini-2.5-flash-exp-native-audio-thinking-dialog",
    "base_model_id": "",
    "version": "gemini-2.5-flash-exp-native-audio-thinking-dialog-2025-05-19",
    "display_name": "Gemini 2.5 Flash Exp Native Audio Thinking Dialog",
    "description": "Gemini 2.5 Flash Exp Native Audio Thinking Dialog",
    "input_token_limit": 131072,
    "output_token_limit": 8192,
    "supported_generation_methods": [
      "countTokens",
      "bidiGenerateContent"
    ],
    "temperature": 1.0,
    "max_temperature": 2.0,
    "top_p": 0.95,
    "top_k": 64
  },
  "models\/gemini-2.0-flash-live-001": {
    "platform": "Gemini",
    "name": "models\/gemini-2.0-flash-live-001",
    "base_model_id": "",
    "version": "001",
    "display_name": "Gemini 2.0 Flash 001",
    "description": "Gemini 2.0 Flash 001",
    "input_token_limit": 131072,
    "output_token_limit": 8192,
    "supported_generation_methods": [
      "bidiGenerateContent",
      "countTokens"
    ],
    "temperature": 1.0,
    "max_temperature": 2.0,
    "top_p": 0.95,
    "top_k": 64
  },
  "models\/gemini-live-2.5-flash-preview": {
    "platform": "Gemini",
    "name": "models\/gemini-live-2.5-flash-preview",
    "base_model_id": "",
    "version": "001",
    "display_name": "Gemini Live 2.5 Flash Preview",
    "description": "Gemini Live 2.5 Flash Preview",
    "input_token_limit": 1048576,
    "output_token_limit": 65536,
    "supported_generation_methods": [
      "bidiGenerateContent",
      "countTokens"
    ],
    "temperature": 1.0,
    "max_temperature": 2.0,
    "top_p": 0.95,
    "top_k": 64
  },
  "models\/gemini-2.5-flash-live-preview": {
    "platform": "Gemini",
    "name": "models\/gemini-2.5-flash-live-preview",
    "base_model_id": "",
    "version": "001",
    "display_name": "Gemini 2.5 Flash Live Preview",
    "description": "Gemini 2.5 Flash Live Preview",
    "input_token_limit": 1048576,
    "output_token_limit": 65536,
    "supported_generation_methods": [
      "bidiGenerateContent",
      "countTokens"
    ],
    "temperature": 1.0,
    "max_temperature": 2.0,
    "top_p": 0.95,
    "top_k": 64
  },
  "qwen2-7b-instruct": {
    "platform": "Alibabacloud",
    "id": "qwen2-7b-instruct",
    "created": 1753881763,
    "object": "model",
    "owned_by": "system"
  },
  "qwen-max": {
    "platform": "Alibabacloud",
    "id": "qwen-max",
    "created": 1728632029,
    "object": "model",
    "owned_by": "system"
  },
  "qwen-plus": {
    "platform": "Alibabacloud",
    "id": "qwen-plus",
    "created": 1728632023,
    "object": "model",
    "owned_by": "system"
  },
  "qwen-turbo": {
    "platform": "Alibabacloud",
    "id": "qwen-turbo",
    "created": 1728632018,
    "object": "model",
    "owned_by": "system"
  },
  "grok-4-0709": {
    "platform": "Xai",
    "id": "grok-4-0709"
  },
  "grok-3": {
    "platform": "Xai",
    "id": "grok-3"
  },
  "grok-3-mini": {
    "platform": "Xai",
    "id": "grok-3-mini"
  },
  "grok-3-fast": {
    "platform": "Xai",
    "id": "grok-3-fast"
  },
  "grok-3-mini-fast": {
    "platform": "Xai",
    "id": "grok-3-mini-fast"
  },
  "skylark-pro": {
    "platform": "Byteplus",
    "id": "skylark-pro"
  },
  "skylark-lite": {
    "platform": "Byteplus",
    "id": "skylark-lite"
  },
  "gigachat-large": {
    "platform": "Sberbank",
    "id": "gigachat-large"
  },
  "gigachat-base": {
    "platform": "Sberbank",
    "id": "gigachat-base"
  }
}