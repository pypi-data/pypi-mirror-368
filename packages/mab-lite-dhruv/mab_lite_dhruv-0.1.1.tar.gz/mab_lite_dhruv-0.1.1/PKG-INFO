Metadata-Version: 2.4
Name: mab-lite-dhruv
Version: 0.1.1
Summary: Minimal multi-armed bandit helpers: pure exploration & pure exploitation.
Project-URL: Homepage, https://github.com/dhruvpithadia/mab-lite-dhruv
Project-URL: Issues, https://github.com/dhruvpithadia/mab-lite-dhruv/issues
Author: Dhruv Pithadia
License: MIT
License-File: LICENSE
Keywords: bandit,exploitation,exploration,multi-armed-bandit,reinforcement-learning
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: >=3.8
Description-Content-Type: text/markdown

# mab-lite-dhruv

Minimal multi-armed bandit helpers for **pure exploration** and **pure exploitation**.  
Perfect for teaching, quick baselines, and sanity checks.

---

## âœ¨ Features
- ğŸ­ **Pure exploration**: uniform random arm pulls for `t` trials  
- âš™ï¸ **Pure exploitation**: always pull one arm (optionally specify which)  
- ğŸ” **Reproducible**: optional `seed`  
- ğŸ“œ **History**: returns per-arm counts, rewards, and (arm, reward) history

---

## ğŸ“¦ Installation
```bash
pip install mab-lite-dhruv