[project]
name = "llm-api-server"
version = "0.1.0"
description = "LLM plugin to expose a FastAPI server with compatible APIs for popular LLM clients"
readme = "README.md"
requires-python = ">=3.9"
license = { text = "MIT" }
authors = [{ name = "Daniel Corin", email = "dan@wvlen.llc" }]
classifiers = [
    "Development Status :: 3 - Alpha",
    "Intended Audience :: Developers",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Topic :: Software Development :: Libraries :: Python Modules",
    "Framework :: FastAPI",
]
keywords = ["llm", "api", "server", "fastapi", "openai"]
dependencies = [
    "llm>=0.15",
    "fastapi>=0.104.0",
    "uvicorn>=0.24.0",
    "httpx>=0.25.0",
    "pydantic>=2.0",
]

[project.urls]
Homepage = "https://github.com/danielcorin/llm-api"
Documentation = "https://github.com/danielcorin/llm-api#readme"
Repository = "https://github.com/danielcorin/llm-api"
Issues = "https://github.com/danielcorin/llm-api/issues"

[project.entry-points.llm]
llm_api = "llm_api_server"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["."]

[dependency-groups]
dev = [
    "ruff>=0.1.0",
    "pytest>=7.0.0",
    "pytest-asyncio>=0.21.0",
    "pytest-cov>=4.0.0",
    "pytest-mock>=3.10.0",
    "openai>=1.0.0",
    "llm-anthropic>=0.17",
    "llm-gemini>=0.24",
]
