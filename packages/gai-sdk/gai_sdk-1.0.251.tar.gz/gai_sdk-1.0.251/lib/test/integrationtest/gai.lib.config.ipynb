{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Gai Master Config"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "a) Get Master Config\n",
                "\n",
                "<div style=\"background: #949494; padding: 10px; color:black\">\n",
                "    gai_config = config_helper.get_gai_config()\n",
                "</div>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from gai.lib.tests import get_local_datadir\n",
                "from gai.lib.config import config_helper, GaiClientConfig, GaiGeneratorConfig\n",
                "\n",
                "# Get from explicit path ./data/gai.yml\n",
                "\n",
                "file_path =  os.path.join(get_local_datadir(),\"gai.yml\")\n",
                "master_config = config_helper.get_gai_config(file_path)\n",
                "\n",
                "# Assert can load client configs\n",
                "\n",
                "assert len(master_config.clients) == 5  # type: ignore\n",
                "assert isinstance(master_config.clients.get(\"ttt\"),GaiClientConfig)\n",
                "assert isinstance(master_config.clients.get(\"dolphin3.0_llama3.1:4.25bpw:exl2\"),GaiClientConfig)\n",
                "\n",
                "# Assert can load generator configs\n",
                "\n",
                "assert len(master_config.generators) == 2  # type: ignore\n",
                "assert isinstance(master_config.generators.get(\"ttt\"), GaiGeneratorConfig)\n",
                "assert isinstance(master_config.generators.get(\"dolphin3.0_llama3.1:4.25bpw:exl2\"), GaiGeneratorConfig)\n",
                "\n",
                "# Assert can load tool configs\n",
                "\n",
                "assert len(master_config.generators) == 2  # type: ignore\n",
                "assert isinstance(master_config.generators.get(\"ttt\"), GaiGeneratorConfig)\n",
                "assert isinstance(master_config.generators.get(\"dolphin3.0_llama3.1:4.25bpw:exl2\"), GaiGeneratorConfig)\n",
                "\n",
                "# Get from dict\n",
                "\n",
                "master_config = config_helper.get_gai_config({\n",
                "    \"version\": \"1.0\",\n",
                "    \"clients\": {\n",
                "        \"ttt\": {\n",
                "            \"ref\": \"dolphin3.0_llama3.1:4.25bpw:exl2\",\n",
                "        },\n",
                "        \"dolphin3.0_llama3.1:4.25bpw:exl2\": {\n",
                "            \"client_type\": \"gai\",\n",
                "            \"type\": \"ttt\",\n",
                "            \"url\": \"http://gai-llm-svr:12031/gen/v1/chat/completions\",\n",
                "        }\n",
                "    }\n",
                "})\n",
                "assert len(master_config.clients) == 2  # type: ignore\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 2. Client Config\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "a) Get Client Config\n",
                "\n",
                "<div style=\"background: #949494; padding: 10px; color:black\">\n",
                "    client_config = config_helper.get_client_config(\"dolphin\")\n",
                "</div>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "client_type='gai' type='ttt' engine=None model=None name=None url='http://gai-ttt-svr:12031/gen/v1/chat/completions' env=None extra=None hyperparameters={}\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "from gai.lib.tests import get_local_datadir\n",
                "from gai.lib.config import config_helper\n",
                "\n",
                "file_path =  os.path.join(get_local_datadir(),\"gai.yml\")\n",
                "\n",
                "client_config = config_helper.get_client_config(\"ttt\",file_path=file_path)\n",
                "print(client_config)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "b) Get from Dict\n",
                "\n",
                "<div style=\"background: #949494; padding: 10px; color:black\">\n",
                "    client_config = config_helper.get_client_config({\n",
                "        \"type\": \"ttt\",\n",
                "        \"client_type\":\"gai\",\n",
                "        \"url\":\"http://gai-ttt-svr:12031/gen/v1/chat/completions\"\n",
                "    })\n",
                "</div>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "client_type='gai' type='ttt' engine='exllamav2' model='dolphin' name='dolphin' url='http://gai-ttt-svr:12031/gen/v1/chat/completions' env=None extra=None hyperparameters={}\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "from gai.lib.tests import get_local_datadir\n",
                "from gai.lib.config import config_helper\n",
                "file_path =  os.path.join(get_local_datadir(),\"gai.yml\")\n",
                "\n",
                "client_config = config_helper.get_client_config({\n",
                "    \"type\":\"ttt\",\n",
                "    \"engine\":\"exllamav2\",\n",
                "    \"model\":\"dolphin\",\n",
                "    \"name\":\"dolphin\",\n",
                "    \"client_type\":\"gai\",\n",
                "    \"url\":\"http://gai-ttt-svr:12031/gen/v1/chat/completions\"\n",
                "})\n",
                "\n",
                "print(client_config)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 3. Generator Config\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "a) Prepare Test Data (./tmp/gai.yml)\n",
                "\n",
                "Copy from ./data/generator_config/gai.yml into ./tmp/gai.yml"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "gai.yml:\n",
                        " {}\n",
                        "generator_config/gai.yml:\n",
                        " {'ttt': GaiGeneratorConfig(type='ttt', engine='exllamav2', model='dolphin3.0_llama3.1:4.25bpw', name='dolphin3.0_llama3.1:4.25bpw:exl2', hyperparameters={'temperature': 0.85, 'top_p': 0.8, 'top_k': 50, 'max_tokens': 1000, 'tool_choice': 'auto', 'max_retries': 5, 'stop': ['<|im_end|>', '</s>', '[/INST]']}, extra={'model_path': 'models/Dolphin3.0-Llama3.1-8B-4_25bpw-exl2', 'max_seq_len': 8192, 'prompt_format': 'llama', 'no_flash_attn': True, 'seed': None, 'decode_special_tokens': False}, module=ModuleConfig(name='gai.llm.server.gai_exllamav2', class_='GaiExLlamav2'), source=HuggingfaceDownloadConfig(local_dir='Dolphin3.0-Llama3.1-8B-4_25bpw-exl2', type='huggingface', repo_id='bartowski/Dolphin3.0-Llama3.1-8B-exl2', revision='896301e945342d032ef0b3a81b57f0d5a8bac6fe', file=None)), 'dolphin3.0_llama3.1:4.25bpw:exl2': GaiGeneratorConfig(type='ttt', engine='exllamav2', model='dolphin3.0_llama3.1:4.25bpw', name='dolphin3.0_llama3.1:4.25bpw:exl2', hyperparameters={'temperature': 0.85, 'top_p': 0.8, 'top_k': 50, 'max_tokens': 1000, 'tool_choice': 'auto', 'max_retries': 5, 'stop': ['<|im_end|>', '</s>', '[/INST]']}, extra={'model_path': 'models/Dolphin3.0-Llama3.1-8B-4_25bpw-exl2', 'max_seq_len': 8192, 'prompt_format': 'llama', 'no_flash_attn': True, 'seed': None, 'decode_special_tokens': False}, module=ModuleConfig(name='gai.llm.server.gai_exllamav2', class_='GaiExLlamav2'), source=HuggingfaceDownloadConfig(local_dir='Dolphin3.0-Llama3.1-8B-4_25bpw-exl2', type='huggingface', repo_id='bartowski/Dolphin3.0-Llama3.1-8B-exl2', revision='896301e945342d032ef0b3a81b57f0d5a8bac6fe', file=None))}\n"
                    ]
                }
            ],
            "source": [
                "# Reset ./tmp/gai.yml\n",
                "\n",
                "import os\n",
                "import shutil\n",
                "from gai.lib.tests import make_local_tmp,get_local_datadir\n",
                "from gai.lib.config import config_helper\n",
                "from gai.lib.tests import get_local_datadir\n",
                "\n",
                "data_path = get_local_datadir()\n",
                "app_path=make_local_tmp()\n",
                "\n",
                "source_gai_config_path = os.path.join(data_path,\"gai.yml\")\n",
                "gai_config_path = os.path.join(app_path,\"gai.yml\")\n",
                "\n",
                "shutil.copyfile(source_gai_config_path,gai_config_path)\n",
                "\n",
                "## \"./tmp/gai.yml\" should have no generators\n",
                "\n",
                "\n",
                "gai_generators = config_helper.list_generator_configs(file_path=gai_config_path)\n",
                "print(\"gai.yml:\\n\", gai_generators)\n",
                "assert len(gai_generators) == 0\n",
                "\n",
                "## \"./data/generators_config/gai.yml\" should have 2 generators\n",
                "\n",
                "data_path = get_local_datadir()\n",
                "server_config_path = os.path.join(data_path,\"generator_config\",\"gai.yml\")\n",
                "\n",
                "server_generators = config_helper.list_generator_configs(file_path=server_config_path)\n",
                "print(\"generator_config/gai.yml:\\n\", server_generators)\n",
                "assert len(server_generators) == 2\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "b) Update Gai Config (./tmp/gai.yml)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "gai.yml:\n",
                        " {'ttt': GaiGeneratorConfig(type='ttt', engine='exllamav2', model='dolphin3.0_llama3.1:4.25bpw', name='dolphin3.0_llama3.1:4.25bpw:exl2', hyperparameters={'temperature': 0.85, 'top_p': 0.8, 'top_k': 50, 'max_tokens': 1000, 'tool_choice': 'auto', 'max_retries': 5, 'stop': ['<|im_end|>', '</s>', '[/INST]']}, extra={'model_path': 'models/Dolphin3.0-Llama3.1-8B-4_25bpw-exl2', 'max_seq_len': 8192, 'prompt_format': 'llama', 'no_flash_attn': True, 'seed': None, 'decode_special_tokens': False}, module=ModuleConfig(name='gai.llm.server.gai_exllamav2', class_='GaiExLlamav2'), source=HuggingfaceDownloadConfig(local_dir='Dolphin3.0-Llama3.1-8B-4_25bpw-exl2', type='huggingface', repo_id='bartowski/Dolphin3.0-Llama3.1-8B-exl2', revision='896301e945342d032ef0b3a81b57f0d5a8bac6fe', file=None)), 'dolphin3.0_llama3.1:4.25bpw:exl2': GaiGeneratorConfig(type='ttt', engine='exllamav2', model='dolphin3.0_llama3.1:4.25bpw', name='dolphin3.0_llama3.1:4.25bpw:exl2', hyperparameters={'temperature': 0.85, 'top_p': 0.8, 'top_k': 50, 'max_tokens': 1000, 'tool_choice': 'auto', 'max_retries': 5, 'stop': ['<|im_end|>', '</s>', '[/INST]']}, extra={'model_path': 'models/Dolphin3.0-Llama3.1-8B-4_25bpw-exl2', 'max_seq_len': 8192, 'prompt_format': 'llama', 'no_flash_attn': True, 'seed': None, 'decode_special_tokens': False}, module=ModuleConfig(name='gai.llm.server.gai_exllamav2', class_='GaiExLlamav2'), source=HuggingfaceDownloadConfig(local_dir='Dolphin3.0-Llama3.1-8B-4_25bpw-exl2', type='huggingface', repo_id='bartowski/Dolphin3.0-Llama3.1-8B-exl2', revision='896301e945342d032ef0b3a81b57f0d5a8bac6fe', file=None))}\n"
                    ]
                }
            ],
            "source": [
                "config_helper.update_gai_config(\"generators\", builtin_config_path=server_config_path,global_config_path=gai_config_path)\n",
                "gai_generators = config_helper.list_generator_configs(file_path=gai_config_path)\n",
                "assert len(gai_generators) == 2\n",
                "print(\"gai.yml:\\n\", gai_generators)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "c) Get from Dict"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "type='ttt' engine='exllamav2' model='dolphin' name='dolphin3.0_llama3.1:4.25bpw:exl2' hyperparameters={} extra=None module=ModuleConfig(name='gai.ttt.exllamav2.gai_exllamav2', class_='GaiExllamav2') source=None\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "from  gai.lib.config import config_helper\n",
                "here = os.getcwd()\n",
                "file_path =  os.path.abspath(os.path.join(here,\"..\",\"..\",\"..\",\"lib\",\"src\",\"gai\",\"scripts\",\"data\",\"gai.yml\"))\n",
                "\n",
                "generator_config = config_helper.get_generator_config(generator_config={\n",
                "    \"type\":\"ttt\",\n",
                "    \"engine\":\"exllamav2\",\n",
                "    \"model\":\"dolphin\",\n",
                "    \"name\":\"dolphin3.0_llama3.1:4.25bpw:exl2\",\n",
                "    \"module\": {\n",
                "        \"name\":\"gai.ttt.exllamav2.gai_exllamav2\",\n",
                "        \"class\":\"GaiExllamav2\"\n",
                "    }\n",
                "})\n",
                "\n",
                "print(generator_config)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Get from Name"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "type='ttt' engine='exllamav2' model='dolphin3.0_llama3.1:4.25bpw' name='dolphin3.0_llama3.1:4.25bpw:exl2' hyperparameters={'temperature': 0.85, 'top_p': 0.8, 'top_k': 50, 'max_tokens': 1000, 'tool_choice': 'auto', 'max_retries': 5, 'stop': ['<|im_end|>', '</s>', '[/INST]']} extra={'model_path': 'models/Dolphin3.0-Llama3.1-8B-4_25bpw-exl2', 'max_seq_len': 8192, 'prompt_format': 'llama', 'no_flash_attn': True, 'seed': None, 'decode_special_tokens': False} module=ModuleConfig(name='gai.llm.server.gai_exllamav2', class_='GaiExLlamav2') source=HuggingfaceDownloadConfig(local_dir='Dolphin3.0-Llama3.1-8B-4_25bpw-exl2', type='huggingface', repo_id='bartowski/Dolphin3.0-Llama3.1-8B-exl2', revision='896301e945342d032ef0b3a81b57f0d5a8bac6fe', file=None)\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "from gai.lib.tests import get_local_datadir\n",
                "from gai.lib.config import config_helper\n",
                "file_path =  os.path.join(get_local_datadir(),\"generator_config\",\"gai.yml\")\n",
                "\n",
                "generator_config = config_helper.get_generator_config(name=\"dolphin3.0_llama3.1:4.25bpw:exl2\",file_path=file_path)\n",
                "print(generator_config)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "d) Get from Ref\n",
                "\n",
                "Note: This generator config is an alias. The objective is to prove that the alias is resolved correctly.\n",
                "\n",
                "```yaml\n",
                "    ttt:\n",
                "        ref: dolphin3.0_llama3.1:4.25bpw:exl2\n",
                "\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "type='ttt' engine='exllamav2' model='dolphin3.0_llama3.1:4.25bpw' name='dolphin3.0_llama3.1:4.25bpw:exl2' hyperparameters={'temperature': 0.85, 'top_p': 0.8, 'top_k': 50, 'max_tokens': 1000, 'tool_choice': 'auto', 'max_retries': 5, 'stop': ['<|im_end|>', '</s>', '[/INST]']} extra={'model_path': 'models/Dolphin3.0-Llama3.1-8B-4_25bpw-exl2', 'max_seq_len': 8192, 'prompt_format': 'llama', 'no_flash_attn': True, 'seed': None, 'decode_special_tokens': False} module=ModuleConfig(name='gai.llm.server.gai_exllamav2', class_='GaiExLlamav2') source=HuggingfaceDownloadConfig(local_dir='Dolphin3.0-Llama3.1-8B-4_25bpw-exl2', type='huggingface', repo_id='bartowski/Dolphin3.0-Llama3.1-8B-exl2', revision='896301e945342d032ef0b3a81b57f0d5a8bac6fe', file=None)\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "from gai.lib.tests import get_local_datadir\n",
                "from gai.lib.config import config_helper\n",
                "file_path =  os.path.join(get_local_datadir(),\"generator_config\",\"gai.yml\")\n",
                "\n",
                "generator_config = config_helper.get_generator_config(name=\"ttt\",file_path=file_path)\n",
                "print(generator_config)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 4. Download Config"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "local_dir='Dolphin3.0-Llama3.1-8B-4_25bpw-exl2' type='huggingface' repo_id='bartowski/Dolphin3.0-Llama3.1-8B-exl2' revision='896301e945342d032ef0b3a81b57f0d5a8bac6fe' file=None\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "from gai.lib.config import config_helper\n",
                "from gai.lib.config.download_config import HuggingfaceDownloadConfig\n",
                "from gai.lib.tests import get_local_datadir\n",
                "file_path =  os.path.join(get_local_datadir(),\"generator_config\",\"gai.yml\")\n",
                "\n",
                "download_config = config_helper.get_download_config(name_or_config=\"dolphin3.0_llama3.1:4.25bpw:exl2\",file_path=file_path)\n",
                "print(download_config)\n",
                "assert isinstance(download_config, HuggingfaceDownloadConfig)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "local_dir='Llama-3.2-3B-Instruct-exl2' type='huggingface' repo_id='bartowski/Llama-3.2-3B-Instruct-exl2' revision='c08d657b27cf0450deaddc3e582be20beec3e62d' file=None\n"
                    ]
                }
            ],
            "source": [
                "from gai.lib.config import config_helper\n",
                "from gai.lib.config.download_config import HuggingfaceDownloadConfig\n",
                "download_config = config_helper.get_download_config({\n",
                "    \"type\": \"huggingface\",\n",
                "    \"repo_id\": \"bartowski/Llama-3.2-3B-Instruct-exl2\",\n",
                "    \"local_dir\": \"Llama-3.2-3B-Instruct-exl2\",\n",
                "    \"revision\": \"c08d657b27cf0450deaddc3e582be20beec3e62d\"\n",
                "})\n",
                "print(download_config)\n",
                "assert isinstance(download_config, HuggingfaceDownloadConfig)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 5. Tool Config\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "a) Get tool config"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "type='tool' name='web' extra={'scraper': {'headless': True, 'scraper_type': 'playwright', 'no_cache': False, 'max_content_length': 250000, 'max_links': 100, 'max_depth': 1, 'max_retries': 3}}\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "from gai.lib.tests import get_local_datadir\n",
                "from gai.lib.config import config_helper\n",
                "data_dir = get_local_datadir()\n",
                "source_config_path=os.path.join(data_dir,\"tool_config\",\"gai.yml\")\n",
                "config=config_helper.get_tool_config(name=\"web\",file_path=source_config_path)\n",
                "print(config)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "a) Prepare Test Data (./tmp/gai.yml)\n",
                "\n",
                "Copy from ./data/tool_config/gai.yml into ./tmp/gai.yml"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "gai.yml:\n",
                        " {}\n",
                        "tool_config/gai.yml:\n",
                        " {'web': GaiToolConfig(type='tool', name='web', extra={'scraper': {'headless': True, 'scraper_type': 'playwright', 'no_cache': False, 'max_content_length': 250000, 'max_links': 100, 'max_depth': 1, 'max_retries': 3}})}\n"
                    ]
                }
            ],
            "source": [
                "# Reset ./tmp/gai.yml\n",
                "\n",
                "import os\n",
                "import shutil\n",
                "from gai.lib.tests import make_local_tmp,get_local_datadir\n",
                "\n",
                "from gai.lib.config import config_helper\n",
                "data_path = get_local_datadir()\n",
                "app_path=make_local_tmp()\n",
                "\n",
                "source_gai_config_path = os.path.join(data_path,\"gai.yml\")\n",
                "gai_config_path = os.path.join(app_path,\"gai.yml\")\n",
                "\n",
                "shutil.copyfile(source_gai_config_path,gai_config_path)\n",
                "\n",
                "## \"./tmp/gai.yml\" should have no generators\n",
                "\n",
                "gai_tools = config_helper.list_tool_configs(file_path=gai_config_path)\n",
                "print(\"gai.yml:\\n\", gai_tools)\n",
                "assert len(gai_tools) == 0\n",
                "\n",
                "## \"./data/tools_config/gai.yml\" should have 2 generators\n",
                "\n",
                "data_path = get_local_datadir()\n",
                "server_config_path = os.path.join(data_path,\"tool_config\",\"gai.yml\")\n",
                "\n",
                "server_tools = config_helper.list_tool_configs(file_path=server_config_path)\n",
                "print(\"tool_config/gai.yml:\\n\", server_tools)\n",
                "assert len(server_tools) == 1\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "b) Update Gai Config (./tmp/gai.yml)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "gai.yml:\n",
                        " {'web': GaiToolConfig(type='tool', name='web', extra={'scraper': {'headless': True, 'scraper_type': 'playwright', 'no_cache': False, 'max_content_length': 250000, 'max_links': 100, 'max_depth': 1, 'max_retries': 3}})}\n"
                    ]
                }
            ],
            "source": [
                "config_helper.update_gai_config(\"tools\", builtin_config_path=server_config_path,global_config_path=gai_config_path)\n",
                "gai_tools = config_helper.list_tool_configs(file_path=gai_config_path)\n",
                "assert len(gai_tools) == 1\n",
                "print(\"gai.yml:\\n\", gai_tools)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "c) Get from Dict"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'type': 'tool', 'name': 'web', 'extra': {'scraper': {'headless': True, 'timeout': 60, 'max_content_length': 1000000}}}\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "from  gai.lib.config import config_helper\n",
                "tool_config = config_helper.get_tool_config(tool_config={\n",
                "    \"type\":\"tool\",\n",
                "    \"name\":\"web\",\n",
                "    \"extra\": {\n",
                "        \"scraper\":{\n",
                "            \"headless\":True,\n",
                "            \"timeout\":60,\n",
                "            \"max_content_length\":1000000,\n",
                "        }\n",
                "    }\n",
                "})\n",
                "\n",
                "print(tool_config)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 5. MCP Config\n",
                "\n",
                "MCP config is a special type of client config.\n",
                "\n",
                "Example:\n",
                "\n",
                "```yaml\n",
                "mcp-web:\n",
                "    type: mcp\n",
                "    client_type: gai\n",
                "    url: file://../../src/gai/mcp/web/mcp_server/mcp_server.py\n",
                "```\n",
                "\n",
                "In this case, the url represents the file path of the mcp_server.py file relative to **MCP Client**.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "mcp_server_path= file://../../src/gai/mcp/web/mcp_server/mcp_server.py\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "from gai.lib.tests import get_local_datadir\n",
                "from gai.lib.config import config_helper\n",
                "file_path =  os.path.join(get_local_datadir(),\"gai.yml\")\n",
                "\n",
                "mcp_config = config_helper.get_client_config(\"mcp-web\",file_path=file_path)\n",
                "print(\"mcp_server_path=\",mcp_config.url)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.18"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
