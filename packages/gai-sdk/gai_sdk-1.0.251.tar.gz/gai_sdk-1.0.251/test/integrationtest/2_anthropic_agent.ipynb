{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "313285d3",
   "metadata": {},
   "source": [
    "# Anthropic Agent\n",
    "\n",
    "### State Diagram (Agent View)\n",
    "```mermaid\n",
    "stateDiagram-v2\n",
    "direction TB\n",
    "    INIT --> IS_TOOL_CALL\n",
    "    IS_TOOL_CALL --> CHAT: condition_false\n",
    "    IS_TOOL_CALL --> TOOL_USE: condition_true\n",
    "    \n",
    "    CHAT --> IS_TERMINATE\n",
    "    TOOL_USE --> IS_TERMINATE\n",
    "    \n",
    "    IS_TERMINATE --> IS_TOOL_CALL: condition_false\n",
    "    IS_TERMINATE --> FINAL: condition_true\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b1b24f",
   "metadata": {},
   "source": [
    "## Setup: Create Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46a8947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"LOG_LEVEL\"] = \"WARNING\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b49099a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from gai.lib.constants import DEFAULT_GUID\n",
    "from gai.asm.agents import ToolUseAgent\n",
    "from gai.mcp.client.mcp_client import McpAggregatedClient\n",
    "from gai.lib.config import config_helper\n",
    "from gai.messages import FileMonologue\n",
    "from gai.lib.tests import make_local_tmp\n",
    "\n",
    "# Configure Monologue\n",
    "\n",
    "here = make_local_tmp()\n",
    "file_path = os.path.join(here, \"monologue.json\")\n",
    "monologue = FileMonologue(agent_name=\"ToolUseAgent\",file_path=file_path)\n",
    "\n",
    "# Configure MCP\n",
    "\n",
    "aggregated_client = McpAggregatedClient([\"mcp-pseudo\",\"mcp-time\"])\n",
    "tools = await aggregated_client.list_tools()\n",
    "\n",
    "# Configure LLM\n",
    "\n",
    "llm_config = config_helper.get_client_config(\n",
    "    {\n",
    "        \"client_type\": \"anthropic\",\n",
    "        \"model\": \"claude-sonnet-4-20250514\",\n",
    "        \"extra\": {\n",
    "            \"max_tokens\": 32000,\n",
    "            \"temperature\": 0.7,\n",
    "            \"top_p\": 0.95,\n",
    "            \"tools\": True,\n",
    "            \"stream\": True,\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "def print_chunk(chunk):\n",
    "    \"\"\"\n",
    "    Helper function to print the chunk of data received from the agent.\n",
    "    \"\"\"\n",
    "    if chunk:\n",
    "        if isinstance(chunk, str):\n",
    "            print(chunk, end=\"\", flush=True)\n",
    "        else:\n",
    "            if isinstance(chunk, list):\n",
    "                for item in chunk:\n",
    "                    if item.get(\"name\"):\n",
    "                        print(f'Tool: \"{item[\"name\"]}\"')\n",
    "                    if item.get(\"input\"):\n",
    "                        inputs = item.get(\"input\")\n",
    "                        if isinstance(inputs, dict):\n",
    "                            for key, value in inputs.items():\n",
    "                                if isinstance(value, str):\n",
    "                                    if len(value) > 100:\n",
    "                                        print(\n",
    "                                            f\"\\tInput: {key} = {value[:100]}... (truncated)\"\n",
    "                                        )\n",
    "                                    else:\n",
    "                                        print(f\"\\tInput: {key} = {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2ccf49",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Scenario 1: Good Flow\n",
    "\n",
    "Let us construct a hypothetical conversation below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc21a073",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gai.messages import FileDialogue, MessagePydantic\n",
    "\n",
    "# Create an artificial dialogue history for testing\n",
    "\n",
    "messages = [\n",
    "    MessagePydantic(\n",
    "        **{\n",
    "            \"id\": \"b1e5f98c-f6eb-47de-a6e2-387510d970f9\",\n",
    "            \"header\": {\n",
    "                \"sender\": \"User\",\n",
    "                \"recipient\": \"Sara\",\n",
    "                \"timestamp\": 1751308157.270983,\n",
    "                \"order\": 0,\n",
    "            },\n",
    "            \"body\": {\n",
    "                \"type\": \"chat.send\",\n",
    "                \"dialogue_id\": \"00000000-0000-0000-0000-000000000000\",\n",
    "                \"round_no\": 0,\n",
    "                \"step_no\": 0,\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"It is a very nice weather in Singapore right now.\",\n",
    "            },\n",
    "        }\n",
    "    ),\n",
    "    MessagePydantic(\n",
    "        **{\n",
    "            \"id\": \"abbc7961-45dc-4973-aaf4-a6224ed35d37\",\n",
    "            \"header\": {\n",
    "                \"sender\": \"Sara\",\n",
    "                \"recipient\": \"User\",\n",
    "                \"timestamp\": 1751308167.3488164,\n",
    "                \"order\": 1,\n",
    "            },\n",
    "            \"body\": {\n",
    "                \"type\": \"chat.reply\",\n",
    "                \"dialogue_id\": \"00000000-0000-0000-0000-000000000000\",\n",
    "                \"round_no\": 0,\n",
    "                \"step_no\": 1,\n",
    "                \"chunk_no\": 10,\n",
    "                \"chunk\": \"<eom>\",\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"Yes, it is! The weather in Singapore is typically warm and humid, with occasional rain showers. It's a great time to enjoy outdoor activities or relax indoors with a cool drink. How can I assist you today?\",\n",
    "            },\n",
    "        }\n",
    "    ),\n",
    "]\n",
    "file_path = os.path.join(here, f\"{DEFAULT_GUID}.json\")\n",
    "dialogue = FileDialogue(messages=messages, file_path=file_path)\n",
    "recap = dialogue.extract_recap()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df65107c",
   "metadata": {},
   "source": [
    "### a) Start Agent\n",
    "\n",
    "Extract the conversation as recap from dialogue and pass it to the agent. Agent can infer the timezone from the recap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58b9fd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'll help you get the current time in Singapore. Let me check that for you.\n",
      "Tool: \"current_time\"\n",
      "\tInput: format = YYYY-MM-DD HH:mm:ss\n",
      "\tInput: timezone = Asia/Singapore\n"
     ]
    }
   ],
   "source": [
    "\n",
    "agent = ToolUseAgent(\n",
    "    agent_name=\"ToolUseAgent\",\n",
    "    llm_config=llm_config,\n",
    "    aggregated_client=aggregated_client,\n",
    "    monologue=monologue\n",
    ")\n",
    "\n",
    "user_message = \"What is the current time here?\"\n",
    "\n",
    "resp = agent.start(user_message=user_message, recap=recap)\n",
    "async for chunk in resp:\n",
    "    print_chunk(chunk)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462bdd49",
   "metadata": {},
   "source": [
    "### b) Tool Call\n",
    "\n",
    "Call the MCP and return the result. Also note that the agent is stateless, we can use a new instance to continue the conversation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b872681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current time in Singapore is **11:00:20 AM on July 31, 2025**. It's a lovely morning time to enjoy that nice weather you mentioned!\n",
      "\n",
      "completed state: IS_TERMINATE\n"
     ]
    }
   ],
   "source": [
    "agent = ToolUseAgent(\n",
    "    agent_name=\"ToolUseAgent\",\n",
    "    llm_config=llm_config,\n",
    "    aggregated_client=aggregated_client,\n",
    "    monologue=monologue,\n",
    ")\n",
    "\n",
    "resp = agent.resume()\n",
    "async for chunk in resp:\n",
    "    print_chunk(chunk)\n",
    "print(f\"\\ncompleted state: {agent.fsm.state}\")\n",
    "assert agent.fsm.state == \"IS_TERMINATE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2aedcf",
   "metadata": {},
   "source": [
    "### c) End Conversation\n",
    "\n",
    "Once the agent has finished its task, calling resume() will fail. To continue, you can use resume(user_message) to update the conversation or start a new one with start(user_message)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "189d2ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed: conversation is over. ToolUseAgent.resume: Cannot resume() as agent has completed its task. Either resume(user_message) to update the task or start a new task with start_async(user_message).\n"
     ]
    }
   ],
   "source": [
    "from gai.asm.agents.tool_use_agent import AutoResumeError\n",
    "try:\n",
    "    resp = agent.resume()\n",
    "    async for chunk in resp:\n",
    "        print_chunk(chunk)\n",
    "except AutoResumeError as e:\n",
    "    print(f\"Test passed: conversation is over. {str(e)}\")\n",
    "\n",
    "    # Save the user message and assistant message to the dialogue at end of the conversation\n",
    "    assistant_message = agent.fsm.state_bag[\"get_assistant_message\"]()\n",
    "    dialogue.add_user_message(recipient=\"Sara\", content=user_message)\n",
    "    dialogue.add_assistant_message(sender=\"Sara\", chunk=\"<eom>\", content=assistant_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec30bab",
   "metadata": {},
   "source": [
    "### d) Update conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec418ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a one sentence story for you:\n",
      "\n",
      "As the tropical rain began to fall in Singapore at 11 AM, Maya discovered that the old umbrella she found in her grandmother's attic could transport her to any place she had ever dreamed of visiting.\n"
     ]
    }
   ],
   "source": [
    "resp = agent.resume(\"Tell me a one sentence story.\")\n",
    "async for chunk in resp:\n",
    "    print_chunk(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1f18c0",
   "metadata": {},
   "source": [
    "### e) Show monologue\n",
    "\n",
    "See the monologue for details at `tmp/monologue.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa3af56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "───────────────────────── MONOLOGUE START ─────────────────────────\n",
      "{\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"\\n            Your name is ToolUseAgent within the context of this conversation and you will always respond as such.\\n            Do not refer to yourself as an AI or a bot or confuse your name with other agents.\\n           \\n            You may respond to my following message using the context you have learnt.\\n            \\n            What is the current time here?\\n\\n            Here is a recap of the conversation:\\n            User: It is a very nice weather in Singapore right now.\\nSara: Yes, it is! The weather in Singapore is typically warm and humid, with occasional rain showers. It's a great time to enjoy outdoor activities or relax indoors with a cool drink. How can I assist you today?\\n            \\n            \\n            You may ask me for more information if you need to clarify my request but ask just enough to get the information you need to get started.\\n            If you need to ask for more information, please use the \\\"user_input\\\" tool to get the information from me.\\n            Please be very specific about what you need from me. Don't end with \\\"I need some additional information\\\" or similar phrases as you need to be specific about what you need.\\n            \"\n",
      "}\n",
      "{\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": [\n",
      "        {\n",
      "            \"citations\": null,\n",
      "            \"text\": \"I'll help you get the current time in Singapore. Let me check that for you.\",\n",
      "            \"type\": \"text\"\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"toolu_0163qp9qxvuzS8XKFxSmFYYP\",\n",
      "            \"input\": {\n",
      "                \"format\": \"YYYY-MM-DD HH:mm:ss\",\n",
      "                \"timezone\": \"Asia/Singapore\"\n",
      "            },\n",
      "            \"name\": \"current_time\",\n",
      "            \"type\": \"tool_use\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"role\": \"user\",\n",
      "    \"content\": [\n",
      "        {\n",
      "            \"type\": \"tool_result\",\n",
      "            \"tool_use_id\": \"toolu_0163qp9qxvuzS8XKFxSmFYYP\",\n",
      "            \"content\": \"Current UTC time is 2025-07-30 01:17:52, and the time in Asia/Singapore is 2025-07-30 09:17:52.\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": [\n",
      "        {\n",
      "            \"citations\": null,\n",
      "            \"text\": \"The current time in Singapore is **9:17:52 AM on July 30, 2025**. Perfect timing to enjoy that nice weather you mentioned!\",\n",
      "            \"type\": \"text\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "───────────────────────── MONOLOGUE END ─────────────────────────\n",
      "\n",
      "Total char size= 1981\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from gai.messages import message_helper\n",
    "\n",
    "# Show the monologue\n",
    "print(\"\\n───────────────────────── MONOLOGUE START ─────────────────────────\")\n",
    "messages = agent.monologue.list_chat_messages()\n",
    "for message in messages:\n",
    "    print(json.dumps(message, indent=4))\n",
    "print(\"───────────────────────── MONOLOGUE END ─────────────────────────\\n\")\n",
    "\n",
    "# Print memory size\n",
    "mem_size=message_helper.get_messages_length(messages)\n",
    "print(\"Total char size=\", mem_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf7708e",
   "metadata": {},
   "source": [
    "### f) Show dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "475d8705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: It is a very nice weather in Singapore right now.\n",
      "Sara: Yes, it is! The weather in Singapore is typically warm and humid, with occasional rain showers. It's a great time to enjoy outdoor activities or relax indoors with a cool drink. How can I assist you today?\n",
      "User: Sara, What is the current time here?\n",
      "Sara: The current time in Singapore is **10:33:13 AM on July 31st, 2025**. It's a lovely morning time to be enjoying that nice weather you mentioned!\n"
     ]
    }
   ],
   "source": [
    "for msg in dialogue.list_messages():\n",
    "    print(f\"{msg.header.sender}: {msg.body.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd9f6b1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Scenario 2: Agent interrupt user for input\n",
    "\n",
    "We will invite the agent to ask questions in this scenario.\n",
    "\n",
    "### a) Start Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5019886c",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ToolUseAgent(\n",
    "    agent_name=\"ToolUseAgent\",\n",
    "    llm_config=llm_config,\n",
    "    aggregated_client=aggregated_client,\n",
    "    monologue=monologue,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef01e50",
   "metadata": {},
   "source": [
    "We know the agent is expecting response from the user when it calls \"user_input\" tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67e99e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd be happy to help you get the current time! To provide you with the most accurate time, I need to know a couple of details:\n",
      "Tool: \"user_input\"\n"
     ]
    }
   ],
   "source": [
    "user_message = \"What is the current time? Please ask if you need more information.\"\n",
    "\n",
    "resp = agent.start(user_message=user_message)\n",
    "async for chunk in resp:\n",
    "    print_chunk(chunk)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c7daef",
   "metadata": {},
   "source": [
    "### b) This will throw error unless user input is provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c86c0ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #800000\">ERROR   </span> <span style=\"color: #ff0000; text-decoration-color: #ff0000\">ToolUserAgent.resume: ToolUseAgent._resume_async: pending user input</span>                                      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;255;255;255;41mERROR   \u001b[0m \u001b[91mToolUserAgent.resume: ToolUseAgent._resume_async: pending user input\u001b[0m                                      \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred: ToolUseAgent._resume_async: pending user input\n",
      "This is expected as the agent is waiting for user input.\n"
     ]
    }
   ],
   "source": [
    "from gai.asm.agents.tool_use_agent import PendingUserInputError\n",
    "try:\n",
    "    resp = agent.resume()\n",
    "    async for chunk in resp:\n",
    "        print_chunk(chunk)\n",
    "except PendingUserInputError as e:\n",
    "    assert \"pending user input\" in str(e)\n",
    "    print(f\"Error occurred: {str(e)}\")\n",
    "    print(\"This is expected as the agent is waiting for user input.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c087dcf3",
   "metadata": {},
   "source": [
    "### c) Can resume normally after user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfec460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tool: \"current_time\"\n",
      "\tInput: format = YYYY-MM-DD HH:mm:ss\n",
      "\tInput: timezone = Asia/Singapore\n"
     ]
    }
   ],
   "source": [
    "# IS_TOOL_CALL -> TOOL_USE\n",
    "resp = agent.resume(\"Use SGT\")\n",
    "async for chunk in resp:\n",
    "    print_chunk(chunk)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8220932",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Scenario 3: User interrupt agent with adhoc input\n",
    "\n",
    "In this scenario, the user tries to distract the agent by interrupting it with an adhoc input.\n",
    "\n",
    "### a) Start Agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d45d37bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd be happy to get the current time for you! To provide the most accurate information, I need to know a couple of details:\n",
      "Tool: \"user_input\"\n"
     ]
    }
   ],
   "source": [
    "agent = ToolUseAgent(\n",
    "    agent_name=\"ToolUseAgent\",\n",
    "    llm_config=llm_config,\n",
    "    aggregated_client=aggregated_client,\n",
    "    monologue=monologue,\n",
    ")\n",
    "\n",
    "# Start the agent\n",
    "\n",
    "user_message = \"What is the current time? Please ask if you need more information.\"\n",
    "\n",
    "resp = agent.start(user_message=user_message)\n",
    "async for chunk in resp:\n",
    "    print_chunk(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23845068",
   "metadata": {},
   "source": [
    "### b) User interrupt agent\n",
    "\n",
    "Should be able to interrupt the agent and continue with original task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dda039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I understand you'd like a joke, but let me first get the current time information you requested. I need to know:\n",
      "\n",
      "1. What time format would you prefer? (For example: \"h:mm A\" for 12-hour format, \"YYYY-MM-DD HH:mm:ss\" for full date and time, etc.)\n",
      "2. What timezone should I use? (For example: \"America/New_York\", \"Europe/London\", \"Asia/Tokyo\", etc.)\n",
      "Tool: \"user_input\"\n"
     ]
    }
   ],
   "source": [
    "resp = agent.resume(\"Tell me a one paragraph joke\")\n",
    "async for chunk in resp:\n",
    "    print_chunk(chunk)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d046937",
   "metadata": {},
   "source": [
    "### c) Resume with input\n",
    "\n",
    "Provide required response and continue with original task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca09dc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you! I'll get the current time in Singapore Time (SGT). Let me use a standard format that shows both date and time:\n",
      "Tool: \"current_time\"\n",
      "\tInput: format = YYYY-MM-DD HH:mm:ss\n",
      "\tInput: timezone = Asia/Singapore\n"
     ]
    }
   ],
   "source": [
    "resp = agent.resume(\"Use SGT\")\n",
    "async for chunk in resp:\n",
    "    print_chunk(chunk)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa9db88",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Scenario 4: Undo last state\n",
    "\n",
    "In this scenario, the user undo the first message and provide a new one.\n",
    "\n",
    "### a) Start Agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83124701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'll help you get the current time. To provide you with the most accurate information, I need to know what format and timezone you'd like the time displayed in.\n",
      "Tool: \"user_input\"\n"
     ]
    }
   ],
   "source": [
    "agent = ToolUseAgent(\n",
    "    agent_name=\"ToolUseAgent\",\n",
    "    llm_config=llm_config,\n",
    "    aggregated_client=aggregated_client,\n",
    "    monologue=monologue,\n",
    ")\n",
    "\n",
    "# Start the agent\n",
    "\n",
    "user_message = \"What is the current time? Please ask if you need more information.\"\n",
    "\n",
    "resp = agent.start(user_message=user_message)\n",
    "async for chunk in resp:\n",
    "    print_chunk(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c1417f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000000; text-decoration-color: #000000; background-color: #808000\">WARNING </span> <span style=\"color: #808000; text-decoration-color: #808000\">MessageStore: No messages to insert. </span><span style=\"color: #808000; text-decoration-color: #808000\">path</span><span style=\"color: #808000; text-decoration-color: #808000\">=/workspaces/gai-sdk/test/integrationtest/tmp/monologue.json</span>     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[30;43mWARNING \u001b[0m \u001b[33mMessageStore: No messages to insert. \u001b[0m\u001b[33mpath\u001b[0m\u001b[33m=\u001b[0m\u001b[33m/workspaces/gai-sdk/test/integrationtest/tmp/\u001b[0m\u001b[33mmonologue.json\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current state is IS_TOOL_CALL\n"
     ]
    }
   ],
   "source": [
    "state =  agent.undo()\n",
    "print(f\"current state is {state}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e2f8519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi there! I'm ToolUseAgent, and I'd be happy to tell you a joke! Here's one for you:\n",
      "\n",
      "A programmer's wife asks him to go to the store and buy a gallon of milk, and if they have eggs, buy a dozen. So the programmer goes to the store, sees they have eggs, and comes home with twelve gallons of milk. His wife asks, \"Why did you buy so much milk?\" The programmer replies, \"They had eggs!\" She facepalms and says, \"I should have been more specific with my boolean logic.\" The programmer nods and says, \"Well, technically I executed your instructions perfectly - you said 'if they have eggs, buy a dozen,' so I bought a dozen gallons of milk!\" His wife sighs and mutters, \"Next time I'm writing the grocery list in pseudocode.\"\n",
      "\n",
      "Hope that gave you a chuckle!\n"
     ]
    }
   ],
   "source": [
    "resp = agent.resume(\"Tell me a one paragraph joke\")\n",
    "async for chunk in resp:\n",
    "    print_chunk(chunk)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddbaab8",
   "metadata": {},
   "source": [
    "Confirm by checking the monologue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f5e38ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': '\\n            Your name is ToolUseAgent within the context of this conversation and you will always respond as such.\\n            Do not refer to yourself as an AI or a bot or confuse your name with other agents.\\n           \\n            You may respond to my following message using the context you have learnt.\\n            Tell me a one paragraph joke\\n            \\n            You may ask me for more information if you need to clarify my request but ask just enough to get the information you need to get started.\\n            If you need to ask for more information, please use the \"user_input\" tool to get the information from me.\\n            Please be very specific about what you need from me. Don\\'t end with \"I need some additional information\" or similar phrases as you need to be specific about what you need.\\n            '},\n",
       " {'role': 'assistant',\n",
       "  'content': [{'citations': None,\n",
       "    'text': 'Hi there! I\\'m ToolUseAgent, and I\\'d be happy to tell you a joke! Here\\'s one for you:\\n\\nA programmer\\'s wife asks him to go to the store and buy a gallon of milk, and if they have eggs, buy a dozen. So the programmer goes to the store, sees they have eggs, and comes home with twelve gallons of milk. His wife asks, \"Why did you buy so much milk?\" The programmer replies, \"They had eggs!\" She facepalms and says, \"I should have been more specific with my boolean logic.\" The programmer nods and says, \"Well, technically I executed your instructions perfectly - you said \\'if they have eggs, buy a dozen,\\' so I bought a dozen gallons of milk!\" His wife sighs and mutters, \"Next time I\\'m writing the grocery list in pseudocode.\"\\n\\nHope that gave you a chuckle!',\n",
       "    'type': 'text'}]}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.monologue.list_chat_messages()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gai-sdk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
