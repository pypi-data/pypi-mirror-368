{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fa8def3",
   "metadata": {},
   "source": [
    "# AnthropicToolCallState\n",
    "\n",
    "## Example: Create TOOL_USE state using AnthropicToolUseState\n",
    "\n",
    "This is actually 2 actions within the same state. The first action is to call the tool and the second action is to pass the result to the LLM and return a response.\n",
    "\n",
    "```lua\n",
    "stateDiagram-v2\n",
    "    INIT --> TOOL_CALL\n",
    "    TOOL_CALL --> FINAL\n",
    "```\n",
    "\n",
    "```mermaid\n",
    "stateDiagram-v2\n",
    "    Direction LR\n",
    "    INIT --> TOOL_CALL\n",
    "    TOOL_CALL --> FINAL\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "837d6eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"LOG_LEVEL\"]=\"WARNING\"\n",
    "\n",
    "from gai.lib.config import config_helper\n",
    "\n",
    "llm_config = config_helper.get_client_config(\"sonnet-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "851e007b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current time is **2025-08-04 01:25:32** (UTC).\n",
      "\n",
      "If you'd like to know the time in a specific timezone, please let me know which timezone you're interested in!\n",
      "\n",
      "\n",
      "\n",
      "1754270730.0613885 User > What time is it now?\n",
      "1754270730.0615668 Assistant > [{'citations': None, 'text': \"I'll get the current time for you.\", 'type': 'text'}, {'id': 'toolu_012CyVmXRfMRzxoYBtmoeF1s', 'input': {'format': 'YYYY-MM-DD HH:mm:ss'}, 'name': 'current_time', 'type': 'tool_use'}]\n",
      "1754270732.3484035 User > [{'type': 'tool_result', 'tool_use_id': 'toolu_012CyVmXRfMRzxoYBtmoeF1s', 'content': 'Current UTC time is 2025-08-04 01:25:32, and the time in UTC is 2025-08-04 01:25:32.'}]\n",
      "1754270734.6111593 Assistant > [{'citations': None, 'text': \"The current time is **2025-08-04 01:25:32** (UTC).\\n\\nIf you'd like to know the time in a specific timezone, please let me know which timezone you're interested in!\", 'type': 'text'}]\n"
     ]
    }
   ],
   "source": [
    "from gai.asm import AgenticStateMachine\n",
    "from gai.messages import Monologue\n",
    "from gai.mcp.client import McpAggregatedClient\n",
    "\n",
    "monologue = Monologue()\n",
    "monologue.add_user_message(\"What time is it now?\")\n",
    "monologue.add_assistant_message(\n",
    "    [\n",
    "        {\n",
    "            \"citations\": None,\n",
    "            \"text\": \"I'll get the current time for you.\",\n",
    "            \"type\": \"text\",\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"toolu_012CyVmXRfMRzxoYBtmoeF1s\",\n",
    "            \"input\": {\"format\": \"YYYY-MM-DD HH:mm:ss\"},\n",
    "            \"name\": \"current_time\",\n",
    "            \"type\": \"tool_use\",\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "with AgenticStateMachine.StateMachineBuilder(\n",
    "    \"\"\"\n",
    "    INIT --> TOOL_USE\n",
    "    TOOL_USE--> FINAL\n",
    "    \"\"\"\n",
    ") as builder:\n",
    "    fsm = builder.build(\n",
    "        {\n",
    "            \"INIT\": {\n",
    "                \"input_data\": {\n",
    "                    \"llm_config\": {\"type\": \"getter\", \"dependency\": \"get_llm_config\"},\n",
    "                    \"mcp_client\": {\"type\": \"getter\", \"dependency\": \"get_mcp_client\"},\n",
    "                }\n",
    "            },\n",
    "            \"TOOL_USE\": {\n",
    "                \"module_path\": \"gai.asm.agents.tool_use_agent\",\n",
    "                \"class_name\": \"AnthropicToolUseState\",\n",
    "                \"title\": \"TOOL_USE\",\n",
    "                \"input_data\": {\n",
    "                    \"llm_config\": {\"type\": \"state_bag\", \"dependency\": \"llm_config\"},\n",
    "                    \"mcp_client\": {\"type\": \"state_bag\", \"dependency\": \"mcp_client\"},\n",
    "                },\n",
    "                \"output_data\": [\"streamer\", \"get_assistant_message\"],\n",
    "            },\n",
    "            \"FINAL\": {\n",
    "                \"output_data\": [\"monologue\"],\n",
    "            },\n",
    "        },\n",
    "        get_llm_config=lambda state: llm_config,\n",
    "        get_mcp_client=lambda state: McpAggregatedClient([\"mcp-time\"]),\n",
    "        monologue=monologue,\n",
    "    )\n",
    "    fsm.restart()\n",
    "\n",
    "## Step 2: INIT --> TOOL_CALL\n",
    "\n",
    "await fsm.run_async()\n",
    "async for chunk in fsm.state_bag[\"streamer\"]:\n",
    "    if (isinstance(chunk,str)):\n",
    "        print(chunk, end='', flush=True)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "## Step 4: Print the state history\n",
    "for message in fsm.state_history[1][\"output\"][\"monologue\"].list_messages():\n",
    "    print(\n",
    "        f\"{message.header.timestamp} {message.header.sender} > {message.body.content}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cd336f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## When LLM has completed its task (\"task_completed\")\n",
    "\n",
    "We can continue to resume as long as the agent can continue its task.\n",
    "\n",
    "In the following case, the previous message does not contain a \"tool_use\" content, that means the agent has either completed its task or is pending user input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab4ae0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing to resume.\n",
      "1754271542.3418617 User > What time is it now?\n",
      "1754271542.3420205 Assistant > [{'citations': None, 'text': '## Summary\\n\\nI have successfully completed ...', 'type': 'text'}]\n"
     ]
    }
   ],
   "source": [
    "from gai.asm import AgenticStateMachine\n",
    "from gai.messages import Monologue\n",
    "from gai.mcp.client import McpAggregatedClient\n",
    "\n",
    "monologue = Monologue()\n",
    "monologue.add_user_message(\"What time is it now?\")\n",
    "monologue.add_assistant_message(\n",
    "    [\n",
    "        {\n",
    "            \"citations\": None,\n",
    "            \"text\": \"## Summary\\n\\nI have successfully completed ...\",\n",
    "            \"type\": \"text\",\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "with AgenticStateMachine.StateMachineBuilder(\n",
    "    \"\"\"\n",
    "    INIT --> TOOL_USE\n",
    "    TOOL_USE--> FINAL\n",
    "    \"\"\"\n",
    ") as builder:\n",
    "    fsm = builder.build(\n",
    "        {\n",
    "            \"INIT\": {\n",
    "                \"input_data\": {\n",
    "                    \"llm_config\": {\"type\": \"getter\", \"dependency\": \"get_llm_config\"},\n",
    "                    \"mcp_client\": {\"type\": \"getter\", \"dependency\": \"get_mcp_client\"},\n",
    "                }\n",
    "            },\n",
    "            \"TOOL_USE\": {\n",
    "                \"module_path\": \"gai.asm.agents.tool_use_agent\",\n",
    "                \"class_name\": \"AnthropicToolUseState\",\n",
    "                \"title\": \"TOOL_USE\",\n",
    "                \"input_data\": {\n",
    "                    \"llm_config\": {\"type\": \"state_bag\", \"dependency\": \"llm_config\"},\n",
    "                    \"mcp_client\": {\"type\": \"state_bag\", \"dependency\": \"mcp_client\"},\n",
    "                },\n",
    "                \"output_data\": [\"streamer\", \"get_assistant_message\"],\n",
    "            },\n",
    "            \"FINAL\": {\n",
    "                \"output_data\": [\"monologue\"],\n",
    "            },\n",
    "        },\n",
    "        get_llm_config=lambda state: llm_config,\n",
    "        get_mcp_client=lambda state: McpAggregatedClient([\"mcp-time\"]),\n",
    "        monologue=monologue,\n",
    "    )\n",
    "    fsm.restart()\n",
    "\n",
    "## Step 2: INIT --> TOOL_CALL\n",
    "\n",
    "await fsm.run_async()\n",
    "if not fsm.state_bag.get(\"streamer\"):\n",
    "    print(\"Nothing to resume.\")\n",
    "else:\n",
    "    for chunk in fsm.state_bag[\"streamer\"]:\n",
    "        if (isinstance(chunk,str)):\n",
    "            print(chunk, end='', flush=True)\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "## Step 4: Print the state history\n",
    "\n",
    "for message in fsm.monologue.list_messages():\n",
    "    print(\n",
    "        f\"{message.header.timestamp} {message.header.sender} > {message.body.content}\"\n",
    "    )\n",
    "    \n",
    "# The last message should only contain the task_completed tool call, not the current time tool call.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2439560b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## When LLM has interrupted itself (\"user_input\")\n",
    "\n",
    "When the LLM interrupts itself, it will call a tool and expect a response from the user.\n",
    "If the user \"continue_async\", then the agent will not stream any responses.\n",
    "Instead, the user will provide a \"user_message\" with continue_async.\n",
    "\n",
    "\n",
    "\n",
    "In this scenario, the LLM will interrupt the user with a question and expects a response from the user.\n",
    "\n",
    "The previous message is an agent message that contains the tool \"user_message' and the text \"Are you asking for the local time or the UTC time?\".\n",
    "\n",
    "#### i) Answer correctly\n",
    "\n",
    "- Add \"Use SGT\" to the user message\n",
    "- Run it.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc6ca4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "1754271632.4178703 User > What time is it now?\n",
      "1754271632.4180486 Assistant > [{'citations': None, 'text': 'Are you asking for the local time or the UTC time?', 'type': 'text'}, {'id': 'toolu_012CyVmXRfMRzxoYBtmoeF1s', 'name': 'user_input', 'input': {}, 'type': 'tool_use'}]\n",
      "1754271633.7673826 User > [{'type': 'tool_result', 'tool_use_id': 'toolu_012CyVmXRfMRzxoYBtmoeF1s', 'content': 'Use SGT'}]\n",
      "1754271635.9466374 Assistant > [{'id': 'toolu_01Ube3n76eKSLujmPTtjGay2', 'input': {'format': 'YYYY-MM-DD HH:mm:ss', 'timezone': 'Asia/Singapore'}, 'name': 'current_time', 'type': 'tool_use'}]\n"
     ]
    }
   ],
   "source": [
    "from gai.asm import AgenticStateMachine\n",
    "from gai.messages import Monologue\n",
    "from gai.mcp.client import McpAggregatedClient\n",
    "\n",
    "monologue = Monologue()\n",
    "monologue.add_user_message(\"What time is it now?\")\n",
    "monologue.add_assistant_message(\n",
    "    [\n",
    "        {\n",
    "            \"citations\": None,\n",
    "            \"text\": \"Are you asking for the local time or the UTC time?\",\n",
    "            \"type\": \"text\",\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"toolu_012CyVmXRfMRzxoYBtmoeF1s\",\n",
    "            \"name\": \"user_input\",\n",
    "            \"input\": {},\n",
    "            \"type\": \"tool_use\",\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "with AgenticStateMachine.StateMachineBuilder(\n",
    "    \"\"\"\n",
    "    INIT --> TOOL_USE\n",
    "    TOOL_USE--> FINAL\n",
    "    \"\"\"\n",
    ") as builder:\n",
    "    fsm = builder.build(\n",
    "        {\n",
    "            \"INIT\": {\n",
    "                \"input_data\": {\n",
    "                    \"llm_config\": {\"type\": \"getter\", \"dependency\": \"get_llm_config\"},\n",
    "                    \"mcp_client\": {\"type\": \"getter\", \"dependency\": \"get_mcp_client\"},\n",
    "                }\n",
    "            },\n",
    "            \"TOOL_USE\": {\n",
    "                \"module_path\": \"gai.asm.agents.tool_use_agent\",\n",
    "                \"class_name\": \"AnthropicToolUseState\",\n",
    "                \"title\": \"TOOL_USE\",\n",
    "                \"input_data\": {\n",
    "                    \"llm_config\": {\"type\": \"state_bag\", \"dependency\": \"llm_config\"},\n",
    "                    \"mcp_client\": {\"type\": \"state_bag\", \"dependency\": \"mcp_client\"},\n",
    "                },\n",
    "                \"output_data\": [\"streamer\", \"get_assistant_message\"],\n",
    "            },\n",
    "            \"FINAL\": {\n",
    "                \"output_data\": [\"monologue\"],\n",
    "            },\n",
    "        },\n",
    "        get_llm_config=lambda state: llm_config,\n",
    "        get_mcp_client=lambda state: McpAggregatedClient([\"mcp-time\"]),\n",
    "        monologue=monologue,\n",
    "    )\n",
    "    fsm.restart()\n",
    "\n",
    "## Step 2: INIT --> TOOL_CALL\n",
    "\n",
    "fsm.user_message = \"Use SGT\"\n",
    "await fsm.run_async()\n",
    "async for chunk in fsm.state_bag[\"streamer\"]:\n",
    "    if isinstance(chunk, str):\n",
    "        print(chunk, end=\"\", flush=True)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "## Step 4: Print the state history\n",
    "\n",
    "for message in fsm.monologue.list_messages():\n",
    "    print(\n",
    "        f\"{message.header.timestamp} {message.header.sender} > {message.body.content}\"\n",
    "    )\n",
    "\n",
    "# The last message should only contain the task_completed tool call, not the current time tool call.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c3af36",
   "metadata": {},
   "source": [
    "#### ii) No answer given\n",
    "\n",
    "- Do not provide user_message.\n",
    "- Run it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c96e0896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Error: AnthropicToolUseState.run_async: pending user input\n",
      "1754271741.6188421 User > What time is it now?\n",
      "1754271741.6190364 Assistant > [{'citations': None, 'text': 'Are you asking for the local time or the UTC time?', 'type': 'text'}, {'id': 'toolu_012CyVmXRfMRzxoYBtmoeF1s', 'name': 'user_input', 'input': {}, 'type': 'tool_use'}]\n"
     ]
    }
   ],
   "source": [
    "from gai.asm import AgenticStateMachine\n",
    "from gai.asm.agents.tool_use_agent import PendingUserInputError\n",
    "from gai.messages import Monologue\n",
    "from gai.mcp.client import McpAggregatedClient\n",
    "\n",
    "monologue = Monologue()\n",
    "monologue.add_user_message(\"What time is it now?\")\n",
    "monologue.add_assistant_message(\n",
    "    [\n",
    "        {\n",
    "            \"citations\": None,\n",
    "            \"text\": \"Are you asking for the local time or the UTC time?\",\n",
    "            \"type\": \"text\",\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"toolu_012CyVmXRfMRzxoYBtmoeF1s\",\n",
    "            \"name\": \"user_input\",\n",
    "            \"input\": {},\n",
    "            \"type\": \"tool_use\",\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "with AgenticStateMachine.StateMachineBuilder(\n",
    "    \"\"\"\n",
    "    INIT --> TOOL_USE\n",
    "    TOOL_USE--> FINAL\n",
    "    \"\"\"\n",
    ") as builder:\n",
    "    fsm = builder.build(\n",
    "        {\n",
    "            \"INIT\": {\n",
    "                \"input_data\": {\n",
    "                    \"llm_config\": {\"type\": \"getter\", \"dependency\": \"get_llm_config\"},\n",
    "                    \"mcp_client\": {\"type\": \"getter\", \"dependency\": \"get_mcp_client\"},\n",
    "                }\n",
    "            },\n",
    "            \"TOOL_USE\": {\n",
    "                \"module_path\": \"gai.asm.agents.tool_use_agent\",\n",
    "                \"class_name\": \"AnthropicToolUseState\",\n",
    "                \"title\": \"TOOL_USE\",\n",
    "                \"input_data\": {\n",
    "                    \"llm_config\": {\"type\": \"state_bag\", \"dependency\": \"llm_config\"},\n",
    "                    \"mcp_client\": {\"type\": \"state_bag\", \"dependency\": \"mcp_client\"},\n",
    "                },\n",
    "                \"output_data\": [\"streamer\", \"get_assistant_message\"],\n",
    "            },\n",
    "            \"FINAL\": {\n",
    "                \"output_data\": [\"monologue\"],\n",
    "            },\n",
    "        },\n",
    "        get_llm_config=lambda state: llm_config,\n",
    "        get_mcp_client=lambda state: McpAggregatedClient([\"mcp-time\"]),\n",
    "        monologue=monologue,\n",
    "    )\n",
    "    fsm.restart()\n",
    "\n",
    "## Step 2: INIT --> TOOL_CALL\n",
    "try:\n",
    "    await fsm.run_async()\n",
    "    async for chunk in fsm.state_bag[\"streamer\"]:\n",
    "        if isinstance(chunk, str):\n",
    "            print(chunk, end=\"\", flush=True)\n",
    "    print(\"\\n\\n\")\n",
    "    assert False, \"Expected PendingUserInputError\"\n",
    "except PendingUserInputError as e:\n",
    "    print(\"Expected Error:\", e)\n",
    "\n",
    "## Step 4: Print the state history\n",
    "for message in fsm.monologue.list_messages():\n",
    "    print(\n",
    "        f\"{message.header.timestamp} {message.header.sender} > {message.body.content}\"\n",
    "    )\n",
    "\n",
    "# Notice that the monologue remains unchanged.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gai-mace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
