{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fa8def3",
   "metadata": {},
   "source": [
    "# AnthropicToolCallState\n",
    "\n",
    "```lua\n",
    "stateDiagram-v2\n",
    "    INIT --> CHAT\n",
    "    CHAT --> FINAL\n",
    "```\n",
    "\n",
    "```mermaid\n",
    "stateDiagram-v2\n",
    "    Direction LR\n",
    "    INIT --> CHAT\n",
    "    CHAT --> FINAL\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124ec26b",
   "metadata": {},
   "source": [
    "### a) Normal Chat Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c41a6bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"LOG_LEVEL\"]=\"WARNING\"\n",
    "\n",
    "from gai.lib.config import config_helper\n",
    "llm_config = config_helper.get_client_config(\"sonnet-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "851e007b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The old lighthouse keeper discovered that the mysterious light old lighthouse keeper discovered that the mysterious light he'd been seeing each night wasn he'd been seeing each night wasn't from a ship, but from his't from a ship, but from his own lantern reflecting own lantern reflecting off the tears he she off the tears he shed for his long-lost loved for his long-lost love.\n",
      "\n",
      "\n",
      "\n",
      "1754270273.545431 User > \n",
      "            Your name is Assistant within the context of this conversation and you will always respond as such.\n",
      "            Do not refer to yourself as an AI or a bot or confuse your name with other agents.\n",
      "           \n",
      "            You may respond to my following message using the context you have learnt.\n",
      "            Tell me a one sentence story.\n",
      "            \n",
      "            You may ask me for more information if you need to clarify my request but ask just enough to get the information you need to get started.\n",
      "            If you need to ask for more information, please use the \"user_input\" tool to get the information from me.\n",
      "            Never call \"user_input\" without providing a description of what you need from me.\n",
      "            Do not be vague and expect an input from me, be specific about what you want.\n",
      "            \n",
      "1754270276.6777515 Assistant > [{'citations': None, 'text': \"The old lighthouse keeper discovered that the mysterious light he'd been seeing each night wasn't from a ship, but from his own lantern reflecting off the tears he shed for his long-lost love.\", 'type': 'text'}]\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "1754270273.545431 User > \n",
      "            Your name is Assistant within the context of this conversation and you will always respond as such.\n",
      "            Do not refer to yourself as an AI or a bot or confuse your name with other agents.\n",
      "           \n",
      "            You may respond to my following message using the context you have learnt.\n",
      "            Tell me a one sentence story.\n",
      "            \n",
      "            You may ask me for more information if you need to clarify my request but ask just enough to get the information you need to get started.\n",
      "            If you need to ask for more information, please use the \"user_input\" tool to get the information from me.\n",
      "            Never call \"user_input\" without providing a description of what you need from me.\n",
      "            Do not be vague and expect an input from me, be specific about what you want.\n",
      "            \n",
      "1754270276.6777515 Assistant > [{'citations': None, 'text': \"The old lighthouse keeper discovered that the mysterious light he'd been seeing each night wasn't from a ship, but from his own lantern reflecting off the tears he shed for his long-lost love.\", 'type': 'text'}]\n"
     ]
    }
   ],
   "source": [
    "from gai.asm import AgenticStateMachine\n",
    "\n",
    "with AgenticStateMachine.StateMachineBuilder(\n",
    "    \"\"\"\n",
    "    INIT --> CHAT\n",
    "    CHAT--> FINAL\n",
    "    \"\"\"\n",
    ") as builder:\n",
    "    fsm = builder.build(\n",
    "        {\n",
    "            \"INIT\": {\n",
    "                \"input_data\": {\n",
    "                    \"llm_config\": {\"type\": \"getter\", \"dependency\": \"get_llm_config\"},\n",
    "                }\n",
    "            },\n",
    "            \"CHAT\": {\n",
    "                \"module_path\": \"gai.asm.agents.tool_use_agent\",\n",
    "                \"class_name\": \"AnthropicChatState\",\n",
    "                \"title\": \"CHAT\",\n",
    "                \"input_data\": {\n",
    "                    \"llm_config\": {\"type\": \"state_bag\", \"dependency\": \"llm_config\"},\n",
    "                },\n",
    "                \"output_data\": [\"streamer\", \"get_assistant_message\"],\n",
    "            },\n",
    "            \"FINAL\": {\n",
    "                \"output_data\": [\"monologue\"],\n",
    "            },\n",
    "        },\n",
    "        get_llm_config=lambda state: llm_config\n",
    "    )\n",
    "    fsm.restart()\n",
    "\n",
    "## Step 2: INIT --> TOOL_CALL\n",
    "fsm.user_message = \"Tell me a one sentence story.\"\n",
    "await fsm.run_async()\n",
    "async for chunk in fsm.state_bag[\"streamer\"]:\n",
    "    if (isinstance(chunk,str)):\n",
    "        print(chunk, end='', flush=True)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "## Step 4: Print the state history\n",
    "for message in fsm.state_history[1][\"output\"][\"monologue\"].list_messages():\n",
    "    print(\n",
    "        f\"{message.header.timestamp} {message.header.sender} > {message.body.content}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fce1053",
   "metadata": {},
   "source": [
    "### b) With Dialogue Recap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d839976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The old lighthouse keeper discovered that old lighthouse keeper discovered that the light he'd been t the light he'd been tending for forty yearsending for forty years wasn't guiding ships to safety, wasn't guiding ships to safety, but rather calling ancient sea creatures home from but rather calling ancient sea creatures home from the deepest trenches of the ocean. the deepest trenches of the ocean.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from gai.messages import Dialogue, MessagePydantic\n",
    "\n",
    "messages = [\n",
    "    MessagePydantic(\n",
    "        **{\n",
    "            \"id\": \"b1e5f98c-f6eb-47de-a6e2-387510d970f9\",\n",
    "            \"header\": {\n",
    "                \"sender\": \"User\",\n",
    "                \"recipient\": \"Sara\",\n",
    "                \"timestamp\": 1751308157.270983,\n",
    "                \"order\": 0,\n",
    "            },\n",
    "            \"body\": {\n",
    "                \"type\": \"chat.send\",\n",
    "                \"dialogue_id\": \"00000000-0000-0000-0000-000000000000\",\n",
    "                \"round_no\": 0,\n",
    "                \"step_no\": 0,\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"I love horror stories, are you familiar with them?\",\n",
    "            },\n",
    "        }\n",
    "    ),\n",
    "    MessagePydantic(\n",
    "        **{\n",
    "            \"id\": \"abbc7961-45dc-4973-aaf4-a6224ed35d37\",\n",
    "            \"header\": {\n",
    "                \"sender\": \"Sara\",\n",
    "                \"recipient\": \"User\",\n",
    "                \"timestamp\": 1751308167.3488164,\n",
    "                \"order\": 1,\n",
    "            },\n",
    "            \"body\": {\n",
    "                \"type\": \"chat.reply\",\n",
    "                \"dialogue_id\": \"00000000-0000-0000-0000-000000000000\",\n",
    "                \"round_no\": 0,\n",
    "                \"step_no\": 1,\n",
    "                \"chunk_no\": 10,\n",
    "                \"chunk\": \"<eom>\",\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"Yes, I am familiar with horror stories. They are a fascinating genre that can evoke strong emotions and create a sense of suspense and fear. Do you have any specific horror stories in mind that you would like to discuss?\",\n",
    "            },\n",
    "        }\n",
    "    ),\n",
    "]\n",
    "from gai.lib.constants import DEFAULT_GUID\n",
    "from gai.messages import Dialogue\n",
    "dialogue = Dialogue(messages=messages)\n",
    "recap = dialogue.extract_recap()\n",
    "\n",
    "#---\n",
    "\n",
    "from gai.asm import AgenticStateMachine\n",
    "\n",
    "with AgenticStateMachine.StateMachineBuilder(\n",
    "    \"\"\"\n",
    "    INIT --> CHAT\n",
    "    CHAT--> FINAL\n",
    "    \"\"\"\n",
    ") as builder:\n",
    "    fsm = builder.build(\n",
    "        {\n",
    "            \"INIT\": {\n",
    "                \"input_data\": {\n",
    "                    \"llm_config\": {\"type\": \"getter\", \"dependency\": \"get_llm_config\"},\n",
    "                    \"recap\": {\"type\": \"getter\", \"dependency\": \"get_recap\"},\n",
    "                }\n",
    "            },\n",
    "            \"CHAT\": {\n",
    "                \"module_path\": \"gai.asm.agents.tool_use_agent\",\n",
    "                \"class_name\": \"AnthropicChatState\",\n",
    "                \"title\": \"CHAT\",\n",
    "                \"input_data\": {\n",
    "                    \"llm_config\": {\"type\": \"state_bag\", \"dependency\": \"llm_config\"},\n",
    "                    \"recap\": {\n",
    "                        \"type\": \"state_bag\",\n",
    "                        \"dependency\": \"recap\",\n",
    "                    },\n",
    "                },\n",
    "                \"output_data\": [\"streamer\", \"get_assistant_message\"],\n",
    "            },\n",
    "            \"FINAL\": {\n",
    "                \"output_data\": [\"monologue\"],\n",
    "            },\n",
    "        },\n",
    "        get_llm_config=lambda state: llm_config,\n",
    "        get_recap=lambda state: recap,\n",
    "    )\n",
    "    fsm.restart()\n",
    "\n",
    "## Step 2: INIT --> CHAT\n",
    "\n",
    "fsm.user_message = \"Tell me a one sentence story.\"\n",
    "await fsm.run_async()\n",
    "async for chunk in fsm.state_bag[\"streamer\"]:\n",
    "    if isinstance(chunk, str):\n",
    "        print(chunk, end=\"\", flush=True)\n",
    "print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64c81b5",
   "metadata": {},
   "source": [
    "### b) Tool Call Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42acc31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'll check the current time in Singapore for you. the current time in Singapore for you.\n",
      "\n",
      "\n",
      "\n",
      "1754270316.4746602 User > \n",
      "            Your name is Assistant within the context of this conversation and you will always respond as such.\n",
      "            Do not refer to yourself as an AI or a bot or confuse your name with other agents.\n",
      "           \n",
      "            You may respond to my following message using the context you have learnt.\n",
      "            What time is it in Singapore?\n",
      "            \n",
      "            You may ask me for more information if you need to clarify my request but ask just enough to get the information you need to get started.\n",
      "            If you need to ask for more information, please use the \"user_input\" tool to get the information from me.\n",
      "            Never call \"user_input\" without providing a description of what you need from me.\n",
      "            Do not be vague and expect an input from me, be specific about what you want.\n",
      "            \n",
      "1754270326.7707736 Assistant > [{'citations': None, 'text': \"I'll check the current time in Singapore for you.\", 'type': 'text'}, {'id': 'toolu_011yGFQNjonUHWnpoHVztn6g', 'input': {'format': 'h:mm:ss A', 'timezone': 'Asia/Singapore'}, 'name': 'current_time', 'type': 'tool_use'}]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1754270316.4746602 User > \n",
      "            Your name is Assistant within the context of this conversation and you will always respond as such.\n",
      "            Do not refer to yourself as an AI or a bot or confuse your name with other agents.\n",
      "           \n",
      "            You may respond to my following message using the context you have learnt.\n",
      "            What time is it in Singapore?\n",
      "            \n",
      "            You may ask me for more information if you need to clarify my request but ask just enough to get the information you need to get started.\n",
      "            If you need to ask for more information, please use the \"user_input\" tool to get the information from me.\n",
      "            Never call \"user_input\" without providing a description of what you need from me.\n",
      "            Do not be vague and expect an input from me, be specific about what you want.\n",
      "            \n",
      "1754270326.7707736 Assistant > [{'citations': None, 'text': \"I'll check the current time in Singapore for you.\", 'type': 'text'}, {'id': 'toolu_011yGFQNjonUHWnpoHVztn6g', 'input': {'format': 'h:mm:ss A', 'timezone': 'Asia/Singapore'}, 'name': 'current_time', 'type': 'tool_use'}]\n"
     ]
    }
   ],
   "source": [
    "from gai.asm import AgenticStateMachine\n",
    "from gai.mcp.client import McpAggregatedClient\n",
    "\n",
    "with AgenticStateMachine.StateMachineBuilder(\n",
    "    \"\"\"\n",
    "    INIT --> CHAT\n",
    "    CHAT--> FINAL\n",
    "    \"\"\"\n",
    ") as builder:\n",
    "    fsm = builder.build(\n",
    "        {\n",
    "            \"INIT\": {\n",
    "                \"input_data\": {\n",
    "                    \"llm_config\": {\"type\": \"getter\", \"dependency\": \"get_llm_config\"},\n",
    "                    \"mcp_client\": {\"type\": \"getter\", \"dependency\": \"get_mcp_client\"},\n",
    "                }\n",
    "            },\n",
    "            \"CHAT\": {\n",
    "                \"module_path\": \"gai.asm.agents.tool_use_agent\",\n",
    "                \"class_name\": \"AnthropicChatState\",\n",
    "                \"title\": \"CHAT\",\n",
    "                \"input_data\": {\n",
    "                    \"llm_config\": {\"type\": \"state_bag\", \"dependency\": \"llm_config\"},\n",
    "                    \"mcp_client\": {\"type\": \"state_bag\", \"dependency\": \"mcp_client\"},\n",
    "                },\n",
    "                \"output_data\": [\"streamer\", \"get_assistant_message\"],\n",
    "            },\n",
    "            \"FINAL\": {\n",
    "                \"output_data\": [\"monologue\"],\n",
    "            },\n",
    "        },\n",
    "        get_llm_config=lambda state: llm_config,\n",
    "        get_mcp_client=lambda state: McpAggregatedClient([\"mcp-time\"]),\n",
    "    )\n",
    "    fsm.restart()\n",
    "\n",
    "## Step 2: INIT --> CHAT\n",
    "\n",
    "fsm.user_message = \"What time is it in Singapore?\"\n",
    "await fsm.run_async()\n",
    "async for chunk in fsm.state_bag[\"streamer\"]:\n",
    "    if (isinstance(chunk,str)):\n",
    "        print(chunk, end='', flush=True)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "## Step 4: Print the state history\n",
    "for message in fsm.state_history[1][\"output\"][\"monologue\"].list_messages():\n",
    "    print(\n",
    "        f\"{message.header.timestamp} {message.header.sender} > {message.body.content}\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gai-mace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
