{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Setup\n",
                "\n",
                "Make sure the model is downloaded\n",
                "\n",
                "```bash\n",
                "ollama pull llama3.2:3b\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Initialize"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from dotenv import load_dotenv\n",
                "load_dotenv()\n",
                "\n",
                "from openai import OpenAI\n",
                "\n",
                "model = \"llama3.2:3b\"\n",
                "\n",
                "client_config = {\n",
                "    \"type\": \"ttt\",\n",
                "    \"client_type\": \"ollama\",\n",
                "    \"engine\": \"ollama\",\n",
                "    \"model\": model,\n",
                "    \"name\": model,\n",
                "    }\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Generate"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "\n",
                        "Normal:\n",
                        "\n",
                        "Raw:\n",
                        "{'model': 'llama3.2:3b', 'created_at': '2025-07-30T12:42:00.697442757Z', 'done': True, 'done_reason': 'stop', 'total_duration': 25966287282, 'load_duration': 7911834327, 'prompt_eval_count': 31, 'prompt_eval_duration': 2814999273, 'eval_count': 40, 'eval_duration': 15229258281, 'message': {'role': 'assistant', 'content': \"As she lay in bed, Emily finally worked up the courage to answer the mysterious letter that had been sitting on her nightstand for months, its words written in a language she couldn't understand.\", 'images': None, 'tool_calls': None}}\n",
                        "Extracted:\n",
                        "As she lay in bed, Emily finally worked up the courage to answer the mysterious letter that had been sitting on her nightstand for months, its words written in a language she couldn't understand.\n",
                        "\n",
                        "\n",
                        "Patched:\n",
                        "\n",
                        "Raw:\n",
                        "{'id': 'chatcmpl-e6785241-3bdc-4777-9004-2f3f8bfde260', 'choices': [{'finish_reason': 'stop', 'index': 0, 'logprobs': None, 'message': {'content': \"As she rummaged through her grandmother's attic, Emily stumbled upon an old trunk with a mysterious key that unlocked not only the chest but also a century-old secret about their family's most treasured legacy.\", 'refusal': None, 'role': 'assistant', 'annotations': None, 'audio': None, 'function_call': None, 'tool_calls': None}}], 'created': 1753879337, 'model': 'ollama', 'object': 'chat.completion', 'service_tier': None, 'system_fingerprint': None, 'usage': {'completion_tokens': 43, 'prompt_tokens': 31, 'total_tokens': 74, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'extract': <function attach_extractor.<locals>.<lambda> at 0x7516a4611a20>}\n",
                        "Extracted:\n",
                        "As she rummaged through her grandmother's attic, Emily stumbled upon an old trunk with a mysterious key that unlocked not only the chest but also a century-old secret about their family's most treasured legacy.\n",
                        "\n",
                        "\n",
                        "Async:\n",
                        "\n",
                        "Raw:\n",
                        "{'id': 'chatcmpl-45c81dda-4b26-470f-86dd-735f88879c75', 'choices': [{'finish_reason': 'stop', 'index': 0, 'logprobs': None, 'message': {'content': \"As she opened the old trunk in her attic, Emily's fingers stumbled upon a faded photograph with a name she had never heard before - hers own.\", 'refusal': None, 'role': 'assistant', 'annotations': None, 'audio': None, 'function_call': None, 'tool_calls': None}}], 'created': 1753879360, 'model': 'ollama', 'object': 'chat.completion', 'service_tier': None, 'system_fingerprint': None, 'usage': {'completion_tokens': 31, 'prompt_tokens': 31, 'total_tokens': 62, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'extract': <function attach_extractor_async.<locals>.<lambda> at 0x75168e988160>}\n",
                        "Extracted:\n",
                        "As she opened the old trunk in her attic, Emily's fingers stumbled upon a faded photograph with a name she had never heard before - hers own.\n"
                    ]
                }
            ],
            "source": [
                "from ollama import chat\n",
                "\n",
                "model = \"llama3.2:3b\"\n",
                "\n",
                "# Using ollama client ────────────────────────────────────────────────────────────────────────\n",
                "\n",
                "print(\"\\n\\nNormal:\\n\")\n",
                "\n",
                "response = chat(\n",
                "    model=model,\n",
                "    messages=[{\"role\":\"user\",\"content\":\"tell me a one sentence story\"}]\n",
                ")\n",
                "\n",
                "print(f\"Raw:\\n{response.model_dump()}\\nExtracted:\\n{response.message.content}\")\n",
                "\n",
                "## Using OpenAI-Compatible client ───────────────────────────────────────────────────────────────────\n",
                "\n",
                "print(\"\\n\\nPatched:\\n\")\n",
                "\n",
                "from gai.llm.openai import OpenAI\n",
                "client = OpenAI(client_config=client_config)\n",
                "response = client.chat.completions.create(\n",
                "    model=model, \n",
                "    messages=[{\"role\":\"user\",\"content\":\"tell me a one sentence story\"}]\n",
                ")\n",
                "\n",
                "print(f\"Raw:\\n{response.model_dump()}\\nExtracted:\\n{response.extract()}\")\n",
                "\n",
                "## Using OpenAI-Compatible async client ───────────────────────────────────────────────────────────────────\n",
                "\n",
                "print(\"\\n\\nAsync:\\n\")\n",
                "\n",
                "from gai.llm.openai import AsyncOpenAI\n",
                "client = AsyncOpenAI(client_config=client_config)\n",
                "response = await client.chat.completions.create(\n",
                "    model=model, \n",
                "    messages=[{\"role\":\"user\",\"content\":\"tell me a one sentence story\"}]\n",
                ")\n",
                "\n",
                "print(f\"Raw:\\n{response.model_dump()}\\nExtracted:\\n{response.extract()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "### Stream"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "\n",
                        "Normal:\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/tmp/ipykernel_57712/893074345.py:18: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
                        "  dict = [ chunk.dict() for chunk in chunks ]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[\n",
                        "    {\n",
                        "        \"model\": \"llama3.2:3b\",\n",
                        "        \"created_at\": \"2025-06-10T08:22:56.082429691Z\",\n",
                        "        \"done\": false,\n",
                        "        \"done_reason\": null,\n",
                        "        \"total_duration\": null,\n",
                        "        \"load_duration\": null,\n",
                        "        \"prompt_eval_count\": null,\n",
                        "        \"prompt_eval_duration\": null,\n",
                        "        \"eval_count\": null,\n",
                        "        \"eval_duration\": null,\n",
                        "        \"message\": {\n",
                        "            \"role\": \"assistant\",\n",
                        "            \"content\": \"As\",\n",
                        "            \"images\": null,\n",
                        "            \"tool_calls\": null\n",
                        "        }\n",
                        "    },\n",
                        "    {\n",
                        "        \"model\": \"llama3.2:3b\",\n",
                        "        \"created_at\": \"2025-06-10T08:22:56.574112855Z\",\n",
                        "        \"done\": false,\n",
                        "        \"done_reason\": null,\n",
                        "        \"total_duration\": null,\n",
                        "        \"load_duration\": null,\n",
                        "        \"prompt_eval_count\": null,\n",
                        "        \"prompt_eval_duration\": null,\n",
                        "        \"eval_count\": null,\n",
                        "        \"eval_duration\": null,\n",
                        "        \"message\": {\n",
                        "            \"role\": \"assistant\",\n",
                        "            \"content\": \" she\",\n",
                        "            \"images\": null,\n",
                        "            \"tool_calls\": null\n",
                        "        }\n",
                        "    },\n",
                        "    {\n",
                        "        \"model\": \"llama3.2:3b\",\n",
                        "        \"created_at\": \"2025-06-10T08:22:56.947729988Z\",\n",
                        "        \"done\": false,\n",
                        "        \"done_reason\": null,\n",
                        "        \"total_duration\": null,\n",
                        "        \"load_duration\": null,\n",
                        "        \"prompt_eval_count\": null,\n",
                        "        \"prompt_eval_duration\": null,\n",
                        "        \"eval_count\": null,\n",
                        "        \"eval_duration\": null,\n",
                        "        \"message\": {\n",
                        "            \"role\": \"assistant\",\n",
                        "            \"content\": \" opened\",\n",
                        "            \"images\": null,\n",
                        "            \"tool_calls\": null\n",
                        "        }\n",
                        "    },\n",
                        "    {\n",
                        "        \"model\": \"llama3.2:3b\",\n",
                        "        \"created_at\": \"2025-06-10T08:22:57.395865584Z\",\n",
                        "        \"done\": false,\n",
                        "        \"done_reason\": null,\n",
                        "        \"total_duration\": null,\n",
                        "        \"load_duration\": null,\n",
                        "        \"prompt_eval_count\": null,\n",
                        "        \"prompt_eval_duration\": null,\n",
                        "        \"eval_count\": null,\n",
                        "        \"eval_duration\": null,\n",
                        "        \"message\": {\n",
                        "            \"role\": \"assistant\",\n",
                        "            \"content\": \" the\",\n",
                        "            \"images\": null,\n",
                        "            \"tool_calls\": null\n",
                        "        }\n",
                        "    },\n",
                        "    {\n",
                        "        \"model\": \"llama3.2:3b\",\n",
                        "        \"created_at\": \"2025-06-10T08:22:57.736452476Z\",\n",
                        "        \"done\": false,\n",
                        "        \"done_reason\": null,\n",
                        "        \"total_duration\": null,\n",
                        "        \"load_duration\": null,\n",
                        "        \"prompt_eval_count\": null,\n",
                        "        \"prompt_eval_duration\": null,\n",
                        "        \"eval_count\": null,\n",
                        "        \"eval_duration\": null,\n",
                        "        \"message\": {\n",
                        "            \"role\": \"assistant\",\n",
                        "            \"content\": \" old\",\n",
                        "            \"images\": null,\n",
                        "            \"tool_calls\": null\n",
                        "        }\n",
                        "    },\n",
                        "    {\n",
                        "        \"model\": \"llama3.2:3b\",\n",
                        "        \"created_at\": \"2025-06-10T08:22:58.045736179Z\",\n",
                        "        \"done\": false,\n",
                        "        \"done_reason\": null,\n",
                        "        \"total_duration\": null,\n",
                        "        \"load_duration\": null,\n",
                        "        \"prompt_eval_count\": null,\n",
                        "        \"prompt_eval_duration\": null,\n",
                        "        \"eval_count\": null,\n",
                        "        \"eval_duration\": null,\n",
                        "        \"message\": {\n",
                        "            \"role\": \"assistant\",\n",
                        "            \"content\": \",\",\n",
                        "            \"images\": null,\n",
                        "            \"tool_calls\": null\n",
                        "        }\n",
                        "    },\n",
                        "    {\n",
                        "        \"model\": \"llama3.2:3b\",\n",
                        "        \"created_at\": \"2025-06-10T08:22:58.313310797Z\",\n",
                        "        \"done\": false,\n",
                        "        \"done_reason\": null,\n",
                        "        \"total_duration\": null,\n",
                        "        \"load_duration\": null,\n",
                        "        \"prompt_eval_count\": null,\n",
                        "        \"prompt_eval_duration\": null,\n",
                        "        \"eval_count\": null,\n",
                        "        \"eval_duration\": null,\n",
                        "        \"message\": {\n",
                        "            \"role\": \"assistant\",\n",
                        "            \"content\": \" mysterious\",\n",
                        "            \"images\": null,\n",
                        "            \"tool_calls\": null\n",
                        "        }\n",
                        "    },\n",
                        "    {\n",
                        "        \"model\": \"llama3.2:3b\",\n",
                        "        \"created_at\": \"2025-06-10T08:22:58.597987381Z\",\n",
                        "        \"done\": false,\n",
                        "        \"done_reason\": null,\n",
                        "        \"total_duration\": null,\n",
                        "        \"load_duration\": null,\n",
                        "        \"prompt_eval_count\": null,\n",
                        "        \"prompt_eval_duration\": null,\n",
                        "        \"eval_count\": null,\n",
                        "        \"eval_duration\": null,\n",
                        "        \"message\": {\n",
                        "            \"role\": \"assistant\",\n",
                        "            \"content\": \" letter\",\n",
                        "            \"images\": null,\n",
                        "            \"tool_calls\": null\n",
                        "        }\n",
                        "    },\n",
                        "    {\n",
                        "        \"model\": \"llama3.2:3b\",\n",
                        "        \"created_at\": \"2025-06-10T08:22:58.806115335Z\",\n",
                        "        \"done\": false,\n",
                        "        \"done_reason\": null,\n",
                        "        \"total_duration\": null,\n",
                        "        \"load_duration\": null,\n",
                        "        \"prompt_eval_count\": null,\n",
                        "        \"prompt_eval_duration\": null,\n",
                        "        \"eval_count\": null,\n",
                        "        \"eval_duration\": null,\n",
                        "        \"message\": {\n",
                        "            \"role\": \"assistant\",\n",
                        "            \"content\": \" that\",\n",
                        "            \"images\": null,\n",
                        "            \"tool_calls\": null\n",
                        "        }\n",
                        "    },\n",
                        "    {\n",
                        "        \"model\": \"llama3.2:3b\",\n",
                        "        \"created_at\": \"2025-06-10T08:22:59.055386334Z\",\n",
                        "        \"done\": false,\n",
                        "        \"done_reason\": null,\n",
                        "        \"total_duration\": null,\n",
                        "        \"load_duration\": null,\n",
                        "        \"prompt_eval_count\": null,\n",
                        "        \"prompt_eval_duration\": null,\n",
                        "        \"eval_count\": null,\n",
                        "        \"eval_duration\": null,\n",
                        "        \"message\": {\n",
                        "            \"role\": \"assistant\",\n",
                        "            \"content\": \" had\",\n",
                        "            \"images\": null,\n",
                        "            \"tool_calls\": null\n",
                        "        }\n",
                        "    },\n",
                        "    {\n",
                        "        \"model\": \"llama3.2:3b\",\n",
                        "        \"created_at\": \"2025-06-10T08:22:59.287114316Z\",\n",
                        "        \"done\": false,\n",
                        "        \"done_reason\": null,\n",
                        "        \"total_duration\": null,\n",
                        "        \"load_duration\": null,\n",
                        "        \"prompt_eval_count\": null,\n",
                        "        \"prompt_eval_duration\": null,\n",
                        "        \"eval_count\": null,\n",
                        "        \"eval_duration\": null,\n",
                        "        \"message\": {\n",
                        "            \"role\": \"assistant\",\n",
                        "            \"content\": \" been\",\n",
                        "            \"images\": null,\n",
                        "            \"tool_calls\": null\n",
                        "        }\n",
                        "    },\n",
                        "    {\n",
                        "        \"model\": \"llama3.2:3b\",\n",
                        "        \"created_at\": \"2025-06-10T08:22:59.702758612Z\",\n",
                        "        \"done\": false,\n",
                        "        \"done_reason\": null,\n",
                        "        \"total_duration\": null,\n",
                        "        \"load_duration\": null,\n",
                        "        \"prompt_eval_count\": null,\n",
                        "        \"prompt_eval_duration\": null,\n",
                        "        \"eval_count\": null,\n",
                        "        \"eval_duration\": null,\n",
                        "        \"message\": {\n",
                        "            \"role\": \"assistant\",\n",
                        "            \"content\": \" waiting\",\n",
                        "            \"images\": null,\n",
                        "            \"tool_calls\": null\n",
                        "        }\n",
                        "    },\n",
                        "    {\n",
                        "        \"model\": \"llama3.2:3b\",\n",
                        "        \"created_at\": \"2025-06-10T08:23:00.001030364Z\",\n",
                        "        \"done\": false,\n",
                        "        \"done_reason\": null,\n",
                        "        \"total_duration\": null,\n",
                        "        \"load_duration\": null,\n",
                        "        \"prompt_eval_count\": null,\n",
                        "        \"prompt_eval_duration\": null,\n",
                        "        \"eval_count\": null,\n",
                        "        \"eval_duration\": null,\n",
                        "        \"message\": {\n",
                        "            \"role\": \"assistant\",\n",
                        "            \"content\": \" for\",\n",
                        "            \"images\": null,\n",
                        "            \"tool_calls\": null\n",
                        "        }\n",
                        "    },\n",
                        "    {\n",
                        "        \"model\": \"llama3.2:3b\",\n",
                        "        \"created_at\": \"2025-06-10T08:23:00.206936321Z\",\n",
                        "        \"done\": false,\n",
                        "        \"done_reason\": null,\n",
                        "        \"total_duration\": null,\n",
                        "        \"load_duration\": null,\n",
                        "        \"prompt_eval_count\": null,\n",
                        "        \"prompt_eval_duration\": null,\n",
                        "        \"eval_count\": null,\n",
                        "        \"eval_duration\": null,\n",
                        "        \"message\": {\n",
                        "            \"role\": \"assistant\",\n",
                        "            \"content\": \" her\",\n",
                        "            \"images\": null,\n",
                        "            \"tool_calls\": null\n",
                        "        }\n",
                        "    },\n",
                        "    {\n",
                        "        \"model\": \"llama3.2:3b\",\n",
                        "        \"created_at\": \"2025-06-10T08:23:00.449074464Z\",\n",
                        "        \"done\": false,\n",
                        "        \"done_reason\": null,\n",
                        "        \"total_duration\": null,\n",
                        "        \"load_duration\": null,\n",
                        "        \"prompt_eval_count\": null,\n",
                        "        \"prompt_eval_duration\": null,\n",
                        "        \"eval_count\": null,\n",
                        "        \"eval_duration\": null,\n",
                        "        \"message\": {\n",
                        "            \"role\": \"assistant\",\n",
                        "            \"content\": \" in\",\n",
                        "            \"images\": null,\n",
                        "            \"tool_calls\": null\n",
                        "        }\n",
                        "    },\n",
                        "    {\n",
                        "        \"model\": \"llama3.2:3b\",\n",
                        "        \"created_at\": \"2025-06-10T08:23:00.6496184Z\",\n",
                        "        \"done\": false,\n",
                        "        \"done_reason\": null,\n",
                        "        \"total_duration\": null,\n",
                        "        \"load_duration\": null,\n",
                        "        \"prompt_eval_count\": null,\n",
                        "        \"prompt_eval_duration\": null,\n",
                        "        \"eval_count\": null,\n",
                        "        \"eval_duration\": null,\n",
                        "        \"message\": {\n",
                        "            \"role\": \"assistant\",\n",
                        "            \"content\": \" the\",\n",
                        "            \"images\": null,\n",
                        "            \"tool_calls\": null\n",
                        "        }\n",
                        "    },\n",
                        "    {\n",
                        "        \"model\": \"llama3.2:3b\",\n",
                        "        \"created_at\": \"2025-06-10T08:23:00.828627279Z\",\n",
                        "        \"done\": false,\n",
                        "        \"done_reason\": null,\n",
                        "        \"total_duration\": null,\n",
                        "        \"load_duration\": null,\n",
                        "        \"prompt_eval_count\": null,\n",
                        "        \"prompt_eval_duration\": null,\n",
                        "        \"eval_count\": null,\n",
                        "        \"eval_duration\": null,\n",
                        "        \"message\": {\n",
                        "            \"role\": \"assistant\",\n",
                        "            \"content\": \" attic\",\n",
                        "            \"images\": null,\n",
                        "            \"tool_calls\": null\n",
                        "        }\n",
                        "    },\n",
                        "    {\n",
                        "        \"model\": \"llama3.2:3b\",\n",
                        "        \"created_at\": \"2025-06-10T08:23:01.103256968Z\",\n",
                        "        \"done\": false,\n",
                        "        \"done_reason\": null,\n",
                        "        \"total_duration\": null,\n",
                        "        \"load_duration\": null,\n",
                        "        \"prompt_eval_count\": null,\n",
                        "        \"prompt_eval_duration\": null,\n",
                        "        \"eval_count\": null,\n",
                        "        \"eval_duration\": null,\n",
                        "        \"message\": {\n",
                        "            \"role\": \"assistant\",\n",
                        "            \"content\": \" for\",\n",
                        "            \"images\": null,\n",
                        "            \"tool_calls\": null\n",
                        "        }\n",
                        "    },\n",
                        "    {\n",
                        "        \"model\": \"llama3.2:3b\",\n",
                        "        \"created_at\": \"2025-06-10T08:23:01.31800694Z\",\n",
                        "        \"done\": false,\n",
                        "        \"done_reason\": null,\n",
                        "        \"total_duration\": null,\n",
                        "        \"load_duration\": null,\n",
                        "        \"prompt_eval_count\": null,\n",
                        "        \"prompt_eval_duration\": null,\n",
                        "        \"eval_count\": null,\n",
                        "        \"eval_duration\": null,\n",
                        "        \"message\": {\n",
                        "            \"role\": \"assistant\",\n",
                        "            \"content\": \" decades\",\n",
                        "            \"images\": null,\n",
                        "            \"tool_calls\": null\n",
                        "        }\n",
                        "    },\n",
                        "    {\n",
                        "        \"model\": \"llama3.2:3b\",\n",
                        "        \"created_at\": \"2025-06-10T08:23:01.506313951Z\",\n",
                        "        \"done\": false,\n",
                        "        \"done_reason\": null,\n",
                        "        \"total_duration\": null,\n",
                        "        \"load_duration\": null,\n",
                        "        \"prompt_eval_count\": null,\n",
                        "        \"prompt_eval_duration\": null,\n",
                        "        \"eval_count\": null,\n",
                        "        \"eval_duration\": null,\n",
                        "        \"message\": {\n",
                        "            \"role\": \"assistant\",\n",
                        "            \"content\": \",\",\n",
                        "            \"images\": null,\n",
                        "            \"tool_calls\": null\n",
                        "        }\n",
                        "    },\n",
                        "    {\n",
                        "        \"model\": \"llama3.2:3b\",\n",
                        "        \"created_at\": \"2025-06-10T08:23:02.023280566Z\",\n",
                        "        \"done\": false,\n",
                        "        \"done_reason\": null,\n",
                        "        \"total_duration\": null,\n",
                        "        \"load_duration\": null,\n",
                        "        \"prompt_eval_count\": null,\n",
                        "        \"prompt_eval_duration\": null,\n",
                        "        \"eval_count\": null,\n",
                        "        \"eval_duration\": null,\n",
                        "        \"message\": {\n",
                        "            \"role\": \"assistant\",\n",
                        "            \"content\": \" Emily\",\n",
                        "            \"images\": null,\n",
                        "            \"tool_calls\": null\n",
                        "        }\n",
                        "    },\n",
                        "    {\n",
                        "        \"model\": \"llama3.2:3b\",\n",
                        "        \"created_at\": \"2025-06-10T08:23:02.195092849Z\",\n",
                        "        \"done\": false,\n",
                        "        \"done_reason\": null,\n",
                        "        \"total_duration\": null,\n",
                        "        \"load_duration\": null,\n",
                        "        \"prompt_eval_count\": null,\n",
                        "        \"prompt_eval_duration\": null,\n",
                        "        \"eval_count\": null,\n",
                        "        \"eval_duration\": null,\n",
                        "        \"message\": {\n",
                        "            \"role\": \"assistant\",\n",
                        "            \"content\": \"'s\",\n",
                        "            \"images\": null,\n",
                        "            \"tool_calls\": null\n",
                        "        }\n",
                        "    },\n",
                        "    {\n",
                        "        \"model\": \"llama3.2:3b\",\n",
                        "        \"created_at\": \"2025-06-10T08:23:02.422892098Z\",\n",
                        "        \"done\": false,\n",
                        "        \"done_reason\": null,\n",
                        "        \"total_duration\": null,\n",
                        "        \"load_duration\": null,\n",
                        "        \"prompt_eval_count\": null,\n",
                        "        \"prompt_eval_duration\": null,\n",
                        "        \"eval_count\": null,\n",
                        "        \"eval_duration\": null,\n",
                        "        \"message\": {\n",
                        "            \"role\": \"assistant\",\n",
                        "            \"content\": \" life\",\n",
                        "            \"images\": null,\n",
                        "            \"tool_calls\": null\n",
                        "        }\n",
                        "    },\n",
                        "    {\n",
                        "        \"model\": \"llama3.2:3b\",\n",
                        "        \"created_at\": \"2025-06-10T08:23:02.681422721Z\",\n",
                        "        \"done\": false,\n",
                        "        \"done_reason\": null,\n",
                        "        \"total_duration\": null,\n",
                        "        \"load_duration\": null,\n",
                        "        \"prompt_eval_count\": null,\n",
                        "        \"prompt_eval_duration\": null,\n",
                        "        \"eval_count\": null,\n",
                        "        \"eval_duration\": null,\n",
                        "        \"message\": {\n",
                        "            \"role\": \"assistant\",\n",
                        "            \"content\": \" was\",\n",
                        "            \"images\": null,\n",
                        "            \"tool_calls\": null\n",
                        "        }\n",
                        "    },\n",
                        "    {\n",
                        "        \"model\": \"llama3.2:3b\",\n",
                        "        \"created_at\": \"2025-06-10T08:23:03.023506573Z\",\n",
                        "        \"done\": false,\n",
                        "        \"done_reason\": null,\n",
                        "        \"total_duration\": null,\n",
                        "        \"load_duration\": null,\n",
                        "        \"prompt_eval_count\": null,\n",
                        "        \"prompt_eval_duration\": null,\n",
                        "        \"eval_count\": null,\n",
                        "        \"eval_duration\": null,\n",
                        "        \"message\": {\n",
                        "            \"role\": \"assistant\",\n",
                        "            \"content\": \" forever\",\n",
                        "            \"images\": null,\n",
                        "            \"tool_calls\": null\n",
                        "        }\n",
                        "    },\n",
                        "    {\n",
                        "        \"model\": \"llama3.2:3b\",\n",
                        "        \"created_at\": \"2025-06-10T08:23:03.203456892Z\",\n",
                        "        \"done\": false,\n",
                        "        \"done_reason\": null,\n",
                        "        \"total_duration\": null,\n",
                        "        \"load_duration\": null,\n",
                        "        \"prompt_eval_count\": null,\n",
                        "        \"prompt_eval_duration\": null,\n",
                        "        \"eval_count\": null,\n",
                        "        \"eval_duration\": null,\n",
                        "        \"message\": {\n",
                        "            \"role\": \"assistant\",\n",
                        "            \"content\": \" changed\",\n",
                        "            \"images\": null,\n",
                        "            \"tool_calls\": null\n",
                        "        }\n",
                        "    },\n",
                        "    {\n",
                        "        \"model\": \"llama3.2:3b\",\n",
                        "        \"created_at\": \"2025-06-10T08:23:03.443629708Z\",\n",
                        "        \"done\": false,\n",
                        "        \"done_reason\": null,\n",
                        "        \"total_duration\": null,\n",
                        "        \"load_duration\": null,\n",
                        "        \"prompt_eval_count\": null,\n",
                        "        \"prompt_eval_duration\": null,\n",
                        "        \"eval_count\": null,\n",
                        "        \"eval_duration\": null,\n",
                        "        \"message\": {\n",
                        "            \"role\": \"assistant\",\n",
                        "            \"content\": \" by\",\n",
                        "            \"images\": null,\n",
                        "            \"tool_calls\": null\n",
                        "        }\n",
                        "    },\n",
                        "    {\n",
                        "        \"model\": \"llama3.2:3b\",\n",
                        "        \"created_at\": \"2025-06-10T08:23:03.752946373Z\",\n",
                        "        \"done\": false,\n",
                        "        \"done_reason\": null,\n",
                        "        \"total_duration\": null,\n",
                        "        \"load_duration\": null,\n",
                        "        \"prompt_eval_count\": null,\n",
                        "        \"prompt_eval_duration\": null,\n",
                        "        \"eval_count\": null,\n",
                        "        \"eval_duration\": null,\n",
                        "        \"message\": {\n",
                        "            \"role\": \"assistant\",\n",
                        "            \"content\": \" the\",\n",
                        "            \"images\": null,\n",
                        "            \"tool_calls\": null\n",
                        "        }\n",
                        "    },\n",
                        "    {\n",
                        "        \"model\": \"llama3.2:3b\",\n",
                        "        \"created_at\": \"2025-06-10T08:23:04.009783826Z\",\n",
                        "        \"done\": false,\n",
                        "        \"done_reason\": null,\n",
                        "        \"total_duration\": null,\n",
                        "        \"load_duration\": null,\n",
                        "        \"prompt_eval_count\": null,\n",
                        "        \"prompt_eval_duration\": null,\n",
                        "        \"eval_count\": null,\n",
                        "        \"eval_duration\": null,\n",
                        "        \"message\": {\n",
                        "            \"role\": \"assistant\",\n",
                        "            \"content\": \" words\",\n",
                        "            \"images\": null,\n",
                        "            \"tool_calls\": null\n",
                        "        }\n",
                        "    },\n",
                        "    {\n",
                        "        \"model\": \"llama3.2:3b\",\n",
                        "        \"created_at\": \"2025-06-10T08:23:04.294441182Z\",\n",
                        "        \"done\": false,\n",
                        "        \"done_reason\": null,\n",
                        "        \"total_duration\": null,\n",
                        "        \"load_duration\": null,\n",
                        "        \"prompt_eval_count\": null,\n",
                        "        \"prompt_eval_duration\": null,\n",
                        "        \"eval_count\": null,\n",
                        "        \"eval_duration\": null,\n",
                        "        \"message\": {\n",
                        "            \"role\": \"assistant\",\n",
                        "            \"content\": \" written\",\n",
                        "            \"images\": null,\n",
                        "            \"tool_calls\": null\n",
                        "        }\n",
                        "    },\n",
                        "    {\n",
                        "        \"model\": \"llama3.2:3b\",\n",
                        "        \"created_at\": \"2025-06-10T08:23:04.493603221Z\",\n",
                        "        \"done\": false,\n",
                        "        \"done_reason\": null,\n",
                        "        \"total_duration\": null,\n",
                        "        \"load_duration\": null,\n",
                        "        \"prompt_eval_count\": null,\n",
                        "        \"prompt_eval_duration\": null,\n",
                        "        \"eval_count\": null,\n",
                        "        \"eval_duration\": null,\n",
                        "        \"message\": {\n",
                        "            \"role\": \"assistant\",\n",
                        "            \"content\": \" on\",\n",
                        "            \"images\": null,\n",
                        "            \"tool_calls\": null\n",
                        "        }\n",
                        "    },\n",
                        "    {\n",
                        "        \"model\": \"llama3.2:3b\",\n",
                        "        \"created_at\": \"2025-06-10T08:23:04.68242978Z\",\n",
                        "        \"done\": false,\n",
                        "        \"done_reason\": null,\n",
                        "        \"total_duration\": null,\n",
                        "        \"load_duration\": null,\n",
                        "        \"prompt_eval_count\": null,\n",
                        "        \"prompt_eval_duration\": null,\n",
                        "        \"eval_count\": null,\n",
                        "        \"eval_duration\": null,\n",
                        "        \"message\": {\n",
                        "            \"role\": \"assistant\",\n",
                        "            \"content\": \" its\",\n",
                        "            \"images\": null,\n",
                        "            \"tool_calls\": null\n",
                        "        }\n",
                        "    },\n",
                        "    {\n",
                        "        \"model\": \"llama3.2:3b\",\n",
                        "        \"created_at\": \"2025-06-10T08:23:04.891389811Z\",\n",
                        "        \"done\": false,\n",
                        "        \"done_reason\": null,\n",
                        "        \"total_duration\": null,\n",
                        "        \"load_duration\": null,\n",
                        "        \"prompt_eval_count\": null,\n",
                        "        \"prompt_eval_duration\": null,\n",
                        "        \"eval_count\": null,\n",
                        "        \"eval_duration\": null,\n",
                        "        \"message\": {\n",
                        "            \"role\": \"assistant\",\n",
                        "            \"content\": \" yellow\",\n",
                        "            \"images\": null,\n",
                        "            \"tool_calls\": null\n",
                        "        }\n",
                        "    },\n",
                        "    {\n",
                        "        \"model\": \"llama3.2:3b\",\n",
                        "        \"created_at\": \"2025-06-10T08:23:05.192776865Z\",\n",
                        "        \"done\": false,\n",
                        "        \"done_reason\": null,\n",
                        "        \"total_duration\": null,\n",
                        "        \"load_duration\": null,\n",
                        "        \"prompt_eval_count\": null,\n",
                        "        \"prompt_eval_duration\": null,\n",
                        "        \"eval_count\": null,\n",
                        "        \"eval_duration\": null,\n",
                        "        \"message\": {\n",
                        "            \"role\": \"assistant\",\n",
                        "            \"content\": \"ed\",\n",
                        "            \"images\": null,\n",
                        "            \"tool_calls\": null\n",
                        "        }\n",
                        "    },\n",
                        "    {\n",
                        "        \"model\": \"llama3.2:3b\",\n",
                        "        \"created_at\": \"2025-06-10T08:23:05.403355058Z\",\n",
                        "        \"done\": false,\n",
                        "        \"done_reason\": null,\n",
                        "        \"total_duration\": null,\n",
                        "        \"load_duration\": null,\n",
                        "        \"prompt_eval_count\": null,\n",
                        "        \"prompt_eval_duration\": null,\n",
                        "        \"eval_count\": null,\n",
                        "        \"eval_duration\": null,\n",
                        "        \"message\": {\n",
                        "            \"role\": \"assistant\",\n",
                        "            \"content\": \" pages\",\n",
                        "            \"images\": null,\n",
                        "            \"tool_calls\": null\n",
                        "        }\n",
                        "    },\n",
                        "    {\n",
                        "        \"model\": \"llama3.2:3b\",\n",
                        "        \"created_at\": \"2025-06-10T08:23:05.64588417Z\",\n",
                        "        \"done\": false,\n",
                        "        \"done_reason\": null,\n",
                        "        \"total_duration\": null,\n",
                        "        \"load_duration\": null,\n",
                        "        \"prompt_eval_count\": null,\n",
                        "        \"prompt_eval_duration\": null,\n",
                        "        \"eval_count\": null,\n",
                        "        \"eval_duration\": null,\n",
                        "        \"message\": {\n",
                        "            \"role\": \"assistant\",\n",
                        "            \"content\": \".\",\n",
                        "            \"images\": null,\n",
                        "            \"tool_calls\": null\n",
                        "        }\n",
                        "    },\n",
                        "    {\n",
                        "        \"model\": \"llama3.2:3b\",\n",
                        "        \"created_at\": \"2025-06-10T08:23:05.891878015Z\",\n",
                        "        \"done\": true,\n",
                        "        \"done_reason\": \"stop\",\n",
                        "        \"total_duration\": 10261937525,\n",
                        "        \"load_duration\": 20421675,\n",
                        "        \"prompt_eval_count\": 31,\n",
                        "        \"prompt_eval_duration\": 426948168,\n",
                        "        \"eval_count\": 37,\n",
                        "        \"eval_duration\": 9813796745,\n",
                        "        \"message\": {\n",
                        "            \"role\": \"assistant\",\n",
                        "            \"content\": \"\",\n",
                        "            \"images\": null,\n",
                        "            \"tool_calls\": null\n",
                        "        }\n",
                        "    }\n",
                        "]\n",
                        "\n",
                        "\n",
                        "Patched:\n",
                        "\n",
                        "As she blew out the candles on her 30th birthday cake, Emily's eyes landed on an old photograph tucked between the layers that revealed a shocking secret about her own identity.\n",
                        "\n",
                        "Async:\n",
                        "\n",
                        "As she opened the old, mysterious door hidden behind the bookshelf in her grandfather's attic, Emily discovered a letter that revealed her whole life had been a carefully constructed illusion."
                    ]
                }
            ],
            "source": [
                "import json\n",
                "from ollama import chat\n",
                "\n",
                "model=\"llama3.2:3b\"\n",
                "\n",
                "## Using ollama client ────────────────────────────────────────────────────────────────────────\n",
                "\n",
                "print(\"\\n\\nNormal:\\n\")\n",
                "\n",
                "response = chat(\n",
                "    model=model, \n",
                "    messages=[{\"role\":\"user\",\"content\":\"tell me a one sentence story\"}],\n",
                "    stream=True\n",
                ")\n",
                "chunks = []\n",
                "for chunk in response:\n",
                "    chunks.append(chunk)\n",
                "dict = [ chunk.dict() for chunk in chunks ]\n",
                "print(json.dumps(dict, indent=4))\n",
                "\n",
                "## Using OpenAI-Compatible client ───────────────────────────────────────────────────────────────────\n",
                "\n",
                "print(\"\\n\\nPatched:\\n\")\n",
                "\n",
                "from gai.llm.openai import OpenAI\n",
                "client = OpenAI(client_config={\n",
                "    \"client_type\":\"ollama\",\n",
                "    \"model\": model\n",
                "})\n",
                "\n",
                "response = client.chat.completions.create(\n",
                "    model=model, \n",
                "    messages=[{\"role\":\"user\",\"content\":\"tell me a one sentence story\"}],\n",
                "    stream=True\n",
                ")\n",
                "chunks = []\n",
                "for chunk in response:\n",
                "    chunk = chunk.extract()\n",
                "    if (isinstance(chunk, str)):\n",
                "        print(chunk, end=\"\", flush=True)\n",
                "\n",
                "# Using OpenAI-Compatible async client ───────────────────────────────────────────────────────────────────\n",
                "\n",
                "print(\"\\n\\nAsync:\\n\")\n",
                "\n",
                "from gai.llm.openai import AsyncOpenAI\n",
                "client = AsyncOpenAI(client_config={\n",
                "    \"client_type\":\"ollama\",\n",
                "    \"model\": model\n",
                "})\n",
                "\n",
                "response = await client.chat.completions.create(\n",
                "    model=model, \n",
                "    messages=[{\"role\":\"user\",\"content\":\"tell me a one sentence story\"}],\n",
                "    stream=True\n",
                ")\n",
                "chunks = []\n",
                "async for chunk in response:\n",
                "    chunk = chunk.extract()\n",
                "    if (isinstance(chunk, str)):\n",
                "        print(chunk, end=\"\", flush=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "### Tool Call"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "\n",
                        "Patched:\n",
                        "\n"
                    ]
                },
                {
                    "ename": "NameError",
                    "evalue": "name 'json' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[1], line 68\u001b[0m\n\u001b[1;32m     40\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI(client_config\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mollama\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[1;32m     43\u001b[0m })\n\u001b[1;32m     44\u001b[0m response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     45\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     46\u001b[0m     messages\u001b[38;5;241m=\u001b[39m[{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is the current time in Singapore?\u001b[39m\u001b[38;5;124m\"\u001b[39m}],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m     tool_choice\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     67\u001b[0m )\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mjson\u001b[49m\u001b[38;5;241m.\u001b[39mdumps(response\u001b[38;5;241m.\u001b[39mextract()\u001b[38;5;241m.\u001b[39mmodel_dump(), indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# ## Using OpenAI-Compatible async client ───────────────────────────────────────────────────────────────────\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# print(\"\\n\\nAsync:\\n\")\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# print(json.dumps(response.extract(), indent=4))\u001b[39;00m\n",
                        "\u001b[0;31mNameError\u001b[0m: name 'json' is not defined"
                    ]
                }
            ],
            "source": [
                "from ollama import chat\n",
                "\n",
                "model = \"llama3.2:3b\"\n",
                "\n",
                "# ## Using ollama client ────────────────────────────────────────────────────────────────────────\n",
                "\n",
                "# print(\"\\n\\nNormal:\\n\")\n",
                "\n",
                "# response = chat(\n",
                "#     model=model, \n",
                "#     messages=[{\"role\": \"user\", \"content\": \"What is the current time in Singapore?\"}],\n",
                "#     tools=[\n",
                "#         {\n",
                "#             \"type\": \"function\",\n",
                "#             \"function\": {\n",
                "#                 \"name\": \"google\",\n",
                "#                 \"description\": \"The 'google' function is a powerful tool that allows the AI to gather external information from the internet using Google search. It can be invoked when the AI needs to answer a question or provide information that requires up-to-date, comprehensive, and diverse sources which are not inherently known by the AI. For instance, it can be used to find current date, current news, weather updates, latest sports scores, trending topics, specific facts, or even the current date and time. The usage of this tool should be considered when the user's query implies or explicitly requests recent or wide-ranging data, or when the AI's inherent knowledge base may not have the required or most current information. The 'search_query' parameter should be a concise and accurate representation of the information needed.\",\n",
                "#                 \"parameters\": {\n",
                "#                     \"type\": \"object\",\n",
                "#                     \"properties\": {\n",
                "#                         \"search_query\": {\n",
                "#                             \"type\": \"string\",\n",
                "#                             \"description\": \"The search query to search google with. For example, to find the current date or time, use 'current date' or 'current time' respectively.\"\n",
                "#                         }\n",
                "#                     },\n",
                "#                     \"required\": [\"search_query\"]\n",
                "#                 }\n",
                "#             }\n",
                "#         }\n",
                "#     ],\n",
                "# )\n",
                "# import json\n",
                "# print(json.dumps(response.model_dump(), indent=4))\n",
                "\n",
                "## Using OpenAI-Compatible client ───────────────────────────────────────────────────────────────────\n",
                "\n",
                "print(\"\\n\\nPatched:\\n\")\n",
                "\n",
                "from gai.llm.openai import OpenAI\n",
                "client = OpenAI(client_config={\n",
                "    \"client_type\": \"ollama\",\n",
                "    \"model\": model,\n",
                "})\n",
                "response = client.chat.completions.create(\n",
                "    model=model,\n",
                "    messages=[{\"role\": \"user\", \"content\": \"What is the current time in Singapore?\"}],\n",
                "    tools=[\n",
                "        {\n",
                "            \"type\": \"function\",\n",
                "            \"function\": {\n",
                "                \"name\": \"google\",\n",
                "                \"description\": \"The 'google' function is a powerful tool that allows the AI to gather external information from the internet using Google search. It can be invoked when the AI needs to answer a question or provide information that requires up-to-date, comprehensive, and diverse sources which are not inherently known by the AI. For instance, it can be used to find current date, current news, weather updates, latest sports scores, trending topics, specific facts, or even the current date and time. The usage of this tool should be considered when the user's query implies or explicitly requests recent or wide-ranging data, or when the AI's inherent knowledge base may not have the required or most current information. The 'search_query' parameter should be a concise and accurate representation of the information needed.\",\n",
                "                \"parameters\": {\n",
                "                    \"type\": \"object\",\n",
                "                    \"properties\": {\n",
                "                        \"search_query\": {\n",
                "                            \"type\": \"string\",\n",
                "                            \"description\": \"The search query to search google with. For example, to find the current date or time, use 'current date' or 'current time' respectively.\"\n",
                "                        }\n",
                "                    },\n",
                "                    \"required\": [\"search_query\"]\n",
                "                }\n",
                "            }\n",
                "        }\n",
                "    ],\n",
                "    tool_choice=\"required\"\n",
                ")\n",
                "print(response.extract())\n",
                "\n",
                "# ## Using OpenAI-Compatible async client ───────────────────────────────────────────────────────────────────\n",
                "\n",
                "# print(\"\\n\\nAsync:\\n\")\n",
                "\n",
                "# from gai.llm.openai import AsyncOpenAI\n",
                "# client = AsyncOpenAI(client_config={\n",
                "#     \"client_type\": \"ollama\",\n",
                "#     \"model\": model,\n",
                "# })\n",
                "# response = await client.chat.completions.create(\n",
                "#     model=model,\n",
                "#     messages=[{\"role\": \"user\", \"content\": \"What is the current time in Singapore?\"}],\n",
                "#     tools=[\n",
                "#         {\n",
                "#             \"type\": \"function\",\n",
                "#             \"function\": {\n",
                "#                 \"name\": \"google\",\n",
                "#                 \"description\": \"The 'google' function is a powerful tool that allows the AI to gather external information from the internet using Google search. It can be invoked when the AI needs to answer a question or provide information that requires up-to-date, comprehensive, and diverse sources which are not inherently known by the AI. For instance, it can be used to find current date, current news, weather updates, latest sports scores, trending topics, specific facts, or even the current date and time. The usage of this tool should be considered when the user's query implies or explicitly requests recent or wide-ranging data, or when the AI's inherent knowledge base may not have the required or most current information. The 'search_query' parameter should be a concise and accurate representation of the information needed.\",\n",
                "#                 \"parameters\": {\n",
                "#                     \"type\": \"object\",\n",
                "#                     \"properties\": {\n",
                "#                         \"search_query\": {\n",
                "#                             \"type\": \"string\",\n",
                "#                             \"description\": \"The search query to search google with. For example, to find the current date or time, use 'current date' or 'current time' respectively.\"\n",
                "#                         }\n",
                "#                     },\n",
                "#                     \"required\": [\"search_query\"]\n",
                "#                 }\n",
                "#             }\n",
                "#         }\n",
                "#     ],\n",
                "#     tool_choice=\"required\"\n",
                "# )\n",
                "# print(json.dumps(response.extract(), indent=4))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Structured Output"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "\n",
                        "Normal:\n",
                        "\n",
                        "{\n",
                        "    \"model\": \"llama3.2:3b\",\n",
                        "    \"created_at\": \"2025-06-10T06:42:20.912940557Z\",\n",
                        "    \"done\": true,\n",
                        "    \"done_reason\": \"stop\",\n",
                        "    \"total_duration\": 34328004535,\n",
                        "    \"load_duration\": 22242986,\n",
                        "    \"prompt_eval_count\": 130,\n",
                        "    \"prompt_eval_duration\": 410288216,\n",
                        "    \"eval_count\": 85,\n",
                        "    \"eval_duration\": 33892671902,\n",
                        "    \"message\": {\n",
                        "        \"role\": \"assistant\",\n",
                        "        \"content\": \"{\\\"title\\\": \\\"Foundation\\\", \\\"summary\\\": \\\"A science fiction novel by Isaac Asimov, published in 1951 as a single book by Gnome Press, which tells the early story of the Foundation, an institute founded by psychohistorian Hari Seldon to preserve galactic civilization after the collapse of the Galactic Empire.\\\", \\\"author\\\": \\\"Isaac Asimov\\\", \\\"published_year\\\": 1951}\",\n",
                        "        \"images\": null,\n",
                        "        \"tool_calls\": null\n",
                        "    }\n",
                        "}\n",
                        "\n",
                        "\n",
                        "Patched:\n",
                        "\n",
                        "{\n",
                        "    \"id\": \"chatcmpl-659db893-3ca5-4552-b531-05d51851eb36\",\n",
                        "    \"choices\": [\n",
                        "        {\n",
                        "            \"finish_reason\": \"stop\",\n",
                        "            \"index\": 0,\n",
                        "            \"logprobs\": null,\n",
                        "            \"message\": {\n",
                        "                \"content\": \"{\\\"title\\\": \\\"Foundation\\\", \\\"summary\\\": \\\"A science fiction novel by Isaac Asimov, published in 1951 as a single book by Gnome Press, which tells the early story of the Foundation, an institute founded by psychohistorian Hari Seldon to preserve galactic civilization after the collapse of the Galactic Empire.\\\", \\\"author\\\": \\\"Isaac Asimov\\\", \\\"published_year\\\": 1951}\",\n",
                        "                \"refusal\": null,\n",
                        "                \"role\": \"assistant\",\n",
                        "                \"annotations\": null,\n",
                        "                \"audio\": null,\n",
                        "                \"function_call\": null,\n",
                        "                \"tool_calls\": null\n",
                        "            }\n",
                        "        }\n",
                        "    ],\n",
                        "    \"created\": 1749537771,\n",
                        "    \"model\": \"ollama\",\n",
                        "    \"object\": \"chat.completion\",\n",
                        "    \"service_tier\": null,\n",
                        "    \"system_fingerprint\": null,\n",
                        "    \"usage\": {\n",
                        "        \"completion_tokens\": 85,\n",
                        "        \"prompt_tokens\": 130,\n",
                        "        \"total_tokens\": 215,\n",
                        "        \"completion_tokens_details\": null,\n",
                        "        \"prompt_tokens_details\": null\n",
                        "    }\n",
                        "}\n",
                        "\n",
                        "\n",
                        "Extracted:\n",
                        "\n",
                        "{\"title\": \"Foundation\", \"summary\": \"A science fiction novel by Isaac Asimov, published in 1951 as a single book by Gnome Press, which tells the early story of the Foundation, an institute founded by psychohistorian Hari Seldon to preserve galactic civilization after the collapse of the Galactic Empire.\", \"author\": \"Isaac Asimov\", \"published_year\": 1951}\n",
                        "\n",
                        "\n",
                        "Async:\n",
                        "\n",
                        "{\n",
                        "    \"id\": \"chatcmpl-5e6a20bd-d8eb-4cd8-a670-a5e87012b32f\",\n",
                        "    \"choices\": [\n",
                        "        {\n",
                        "            \"finish_reason\": \"stop\",\n",
                        "            \"index\": 0,\n",
                        "            \"logprobs\": null,\n",
                        "            \"message\": {\n",
                        "                \"content\": \"{\\\"title\\\": \\\"Foundation\\\", \\\"summary\\\": \\\"A science fiction novel by Isaac Asimov, published in 1951 as a single book by Gnome Press, which tells the early story of the Foundation, an institute founded by psychohistorian Hari Seldon to preserve galactic civilization after the collapse of the Galactic Empire.\\\", \\\"author\\\": \\\"Isaac Asimov\\\", \\\"published_year\\\": 1951}\",\n",
                        "                \"refusal\": null,\n",
                        "                \"role\": \"assistant\",\n",
                        "                \"annotations\": null,\n",
                        "                \"audio\": null,\n",
                        "                \"function_call\": null,\n",
                        "                \"tool_calls\": null\n",
                        "            }\n",
                        "        }\n",
                        "    ],\n",
                        "    \"created\": 1749537808,\n",
                        "    \"model\": \"ollama\",\n",
                        "    \"object\": \"chat.completion\",\n",
                        "    \"service_tier\": null,\n",
                        "    \"system_fingerprint\": null,\n",
                        "    \"usage\": {\n",
                        "        \"completion_tokens\": 85,\n",
                        "        \"prompt_tokens\": 130,\n",
                        "        \"total_tokens\": 215,\n",
                        "        \"completion_tokens_details\": null,\n",
                        "        \"prompt_tokens_details\": null\n",
                        "    }\n",
                        "}\n",
                        "\n",
                        "\n",
                        "Extracted:\n",
                        "\n",
                        "{\"title\": \"Foundation\", \"summary\": \"A science fiction novel by Isaac Asimov, published in 1951 as a single book by Gnome Press, which tells the early story of the Foundation, an institute founded by psychohistorian Hari Seldon to preserve galactic civilization after the collapse of the Galactic Empire.\", \"author\": \"Isaac Asimov\", \"published_year\": 1951}\n"
                    ]
                }
            ],
            "source": [
                "from pydantic import BaseModel\n",
                "class Book(BaseModel):\n",
                "    title: str\n",
                "    summary: str\n",
                "    author: str\n",
                "    published_year: int\n",
                "data = \"\"\"Foundation is a science fiction novel by American writer\n",
                "        Isaac Asimov. It is the first published in his Foundation Trilogy (later\n",
                "        expanded into the Foundation series). Foundation is a cycle of five\n",
                "        interrelated short stories, first published as a single book by Gnome Press\n",
                "        in 1951. Collectively they tell the early story of the Foundation,\n",
                "        an institute founded by psychohistorian Hari Seldon to preserve the best\n",
                "        of galactic civilization after the collapse of the Galactic Empire.\"\"\"       \n",
                "\n",
                "from ollama import chat\n",
                "\n",
                "model = \"llama3.2:3b\"\n",
                "\n",
                "## Using ollama client ────────────────────────────────────────────────────────────────────────\n",
                "\n",
                "print(\"\\n\\nNormal:\\n\")\n",
                "\n",
                "response = chat(\n",
                "    model=model,\n",
                "    messages=[{\"role\":\"user\",\"content\":data}],\n",
                "    options={\n",
                "        \"temperature\":0,   \n",
                "    },\n",
                "    format=Book.model_json_schema()    \n",
                "    )\n",
                "dict = response.model_dump()\n",
                "import json\n",
                "print(json.dumps(dict, indent=4))\n",
                "\n",
                "## Using OpenAI-Compatible client ───────────────────────────────────────────────────────────────────\n",
                "\n",
                "print(\"\\n\\nPatched:\\n\")\n",
                "\n",
                "from gai.llm.openai import OpenAI\n",
                "client = OpenAI(client_config={\n",
                "    \"client_type\":\"ollama\",\n",
                "    \"model\": model\n",
                "})\n",
                "response = client.beta.chat.completions.parse(\n",
                "    model=model, \n",
                "    response_format=Book,\n",
                "    messages=[{\"role\":\"user\",\"content\":data}]\n",
                "    )\n",
                "dict = response.model_dump(exclude={\"extract\"})\n",
                "print(json.dumps(dict, indent=4))\n",
                "\n",
                "print(\"\\n\\nExtracted:\\n\")\n",
                "print(response.extract())\n",
                "\n",
                "## Using OpenAI-Compatible async client ───────────────────────────────────────────────────────────────────\n",
                "\n",
                "print(\"\\n\\nAsync:\\n\")\n",
                "\n",
                "from gai.llm.openai import AsyncOpenAI\n",
                "client = AsyncOpenAI(client_config={\n",
                "    \"client_type\":\"ollama\",\n",
                "    \"model\": model\n",
                "})\n",
                "response = await client.beta.chat.completions.parse(\n",
                "    model=model, \n",
                "    response_format=Book,\n",
                "    messages=[{\"role\":\"user\",\"content\":data}]\n",
                "    )\n",
                "dict = response.model_dump(exclude={\"extract\"})\n",
                "print(json.dumps(dict, indent=4))\n",
                "\n",
                "print(\"\\n\\nExtracted:\\n\")\n",
                "print(response.extract())\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "gai-sdk",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.18"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
