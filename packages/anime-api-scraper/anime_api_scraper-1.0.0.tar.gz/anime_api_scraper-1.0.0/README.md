# üéå Anime Scraper

Un scraper web robusto y escalable para extraer informaci√≥n de sitios de anime, comenzando con **AnimeFlv**. Este proyecto est√° dise√±ado con una arquitectura modular que permite agregar f√°cilmente nuevos sitios de anime en el futuro.

## üìã Caracter√≠sticas

- üîç **B√∫squeda de animes** por nombre con paginaci√≥n
- üìä **Informaci√≥n detallada** de animes (sinopsis, g√©neros, episodios, etc.)
- üÜï **Animes m√°s recientes** desde la p√°gina principal
- üì∫ **Episodios recientes** con informaci√≥n actualizada
- üîó **Enlaces de reproducci√≥n** para episodios espec√≠ficos
- üõ°Ô∏è **Protecci√≥n anti-bot** usando cloudscraper
- üèóÔ∏è **Arquitectura modular** para f√°cil extensi√≥n a nuevos sitios

## üöÄ Instalaci√≥n

### Requisitos previos

- Python 3.8+
- pip (gestor de paquetes de Python)

### Dependencias

```bash
pip install -r requirements.txt
```

**Dependencias principales:**
- `beautifulsoup4` - Parsing HTML
- `cloudscraper` - Evadir protecciones anti-bot
- `requests` - Peticiones HTTP
- `lxml` - Parser XML/HTML r√°pido

## üìÅ Estructura del Proyecto

```
anime-scraper/
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ data_models.py          # Modelos de datos (AnimeInfo, SearchResponse, etc.)
‚îÇ   ‚îú‚îÄ‚îÄ processors/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base_processors.py      # Clase base para procesadores
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ animeflv_processors.py  # Procesador espec√≠fico para AnimeFlv
‚îÇ   ‚îú‚îÄ‚îÄ scrapers/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base_scraper.py         # Clase base para scrapers
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ animeflv_scraper.py     # Scraper espec√≠fico para AnimeFlv
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îî‚îÄ‚îÄ exception.py            # Excepciones personalizadas
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

## üîß Uso

### Inicializaci√≥n del Scraper

```python
from api.scrapers.animeflv_scraper import AnimeFLVScraper

# Usando context manager (recomendado)
with AnimeFLVScraper() as scraper:
    # Tu c√≥digo aqu√≠
    pass
```

### B√∫squeda de Animes

```python
with AnimeFLVScraper() as scraper:
    # Buscar animes por nombre
    resultados = scraper.search("Naruto", pagina=1)
    
    print(f"P√°gina {resultados['pagination'].pagina_actual} de {resultados['pagination'].pagina_total}")
    
    for anime in resultados['results']:
        print(f"ID: {anime.anime_id}")
        print(f"Nombre: {anime.nombre}")
        print(f"Imagen: {anime.imagen}")
```

### Informaci√≥n Detallada de un Anime

```python
with AnimeFLVScraper() as scraper:
    # Obtener informaci√≥n completa
    anime_info = scraper.get_anime_info("naruto-tv")
    
    print(f"Nombre: {anime_info.nombre}")
    print(f"Tipo: {anime_info.tipo}")
    print(f"G√©neros: {anime_info.genero}")
    print(f"Descripci√≥n: {anime_info.descripcion}")
    print(f"Estado: {anime_info.estado}")
    print(f"Episodios disponibles: {len(anime_info.episodios)}")
    
    if anime_info.proximo_episodio:
        print(f"Pr√≥ximo episodio: {anime_info.proximo_episodio}")
    
    # Animes relacionados
    for relacionado in anime_info.animes_relacionados:
        print(f"- {relacionado.nombre} (ID: {relacionado.anime_id})")
```

### Animes y Episodios Recientes

```python
with AnimeFLVScraper() as scraper:
    # Obtener animes m√°s recientes
    animes_recientes = scraper.get_latest_animes()
    
    for anime in animes_recientes:
        print(f"{anime.nombre} - {anime.tipo} - ‚≠ê{anime.puntaje}")
    
    # Obtener episodios m√°s recientes
    episodios_recientes = scraper.get_latest_episodes()
    
    for episodio in episodios_recientes:
        print(f"{episodio.nombre} - Episodio {episodio.episodio}")
```

### Enlaces de Reproducci√≥n

```python
with AnimeFLVScraper() as scraper:
    # Obtener enlaces para un episodio espec√≠fico
    enlaces = scraper.get_links("naruto-tv", "1")
    
    for enlace in enlaces:
        print(f"Servidor: {enlace['server']}")
        print(f"T√≠tulo: {enlace['titulo']}")
        print(f"URL: {enlace['url']}")
```

## üìä Modelos de Datos

### AnimeSearchResult
Informaci√≥n b√°sica para resultados de b√∫squeda:
- `anime_id`: Identificador √∫nico
- `nombre`: T√≠tulo del anime
- `imagen`: URL de la imagen de portada

### AnimeInfo
Informaci√≥n completa del anime:
- `anime_id`: Identificador √∫nico
- `nombre`: T√≠tulo completo
- `tipo`: Tipo (TV, Movie, OVA, etc.)
- `genero`: G√©neros separados por comas
- `descripcion`: Sinopsis del anime
- `animes_relacionados`: Lista de animes relacionados
- `episodios`: Lista de n√∫meros de episodios disponibles
- `estado`: Estado de emisi√≥n (En emisi√≥n, Finalizado, etc.)
- `proximo_episodio`: Fecha del pr√≥ximo episodio (si aplica)

### LatestAnime
Informaci√≥n de animes recientes:
- `anime_id`: Identificador √∫nico
- `nombre`: T√≠tulo del anime
- `tipo`: Tipo de anime
- `puntaje`: Puntuaci√≥n (rating)
- `descripci√≥n`: Descripci√≥n breve
- `imagen`: URL de la imagen

### LatestEpisodes
Informaci√≥n de episodios recientes:
- `anime_id`: Identificador del anime
- `nombre`: Nombre del anime
- `episodio`: N√∫mero del episodio
- `imagen`: URL de la imagen del episodio

## üèóÔ∏è Arquitectura

### Patr√≥n de Dise√±o

El proyecto utiliza una **arquitectura modular** basada en el patr√≥n de responsabilidad √∫nica:

1. **Scrapers** (`BaseScraper` ‚Üí `AnimeFLVScraper`)
   - Manejan las peticiones HTTP
   - Coordinan el flujo de scraping
   - Gestionan la sesi√≥n y configuraci√≥n espec√≠fica del sitio

2. **Processors** (`BaseProcessors` ‚Üí `AnimeFLVProcessors`)
   - Procesan el HTML crudo
   - Extraen y estructuran los datos
   - Convierten HTML en objetos Python

3. **Models** (`data_models.py`)
   - Definen la estructura de datos
   - Validan tipos usando dataclasses
   - Proporcionan consistencia entre componentes

### Ventajas de esta Arquitectura

- ‚úÖ **Escalabilidad**: F√°cil agregar nuevos sitios
- ‚úÖ **Mantenibilidad**: Separaci√≥n clara de responsabilidades
- ‚úÖ **Reutilizaci√≥n**: Componentes base reutilizables
- ‚úÖ **Testeo**: Cada componente se puede testear independientemente

## üîÆ Extensibilidad

Para agregar un nuevo sitio de anime (ej: Crunchyroll):

1. **Crear el procesador espec√≠fico**:
```python
class CrunchyrollProcessors(BaseProcessors):
    def process_search(self, response):
        # L√≥gica espec√≠fica para Crunchyroll
        pass
```

2. **Crear el scraper espec√≠fico**:
```python
class CrunchyrollScraper(BaseScraper):
    def __init__(self):
        self._base_url = "https://crunchyroll.com"
        self._processor = CrunchyrollProcessors()
```

3. **Implementar los m√©todos requeridos** siguiendo la interfaz base.

## ‚ö° Manejo de Errores

El proyecto incluye manejo robusto de errores:

### AnimeException
Excepci√≥n personalizada que incluye:
- `message`: Descripci√≥n del error
- `metodo`: M√©todo donde ocurri√≥ el error
- `source`: Fuente del error (ej: "animeflv")

### Validaciones Comunes
- ‚úÖ Validaci√≥n de par√°metros de entrada
- ‚úÖ Verificaci√≥n de elementos HTML existentes
- ‚úÖ Manejo de contenido malformado
- ‚úÖ Timeout y errores de conectividad

## üõ°Ô∏è Caracter√≠sticas T√©cnicas

### Anti-Bot Protection
- Utiliza `cloudscraper` para evadir protecciones Cloudflare
- Headers realistas de navegador
- Manejo autom√°tico de challenges JavaScript

### Parsing Robusto
- M√∫ltiples selectores CSS como fallback
- Validaci√≥n de datos extra√≠dos
- Manejo graceful de contenido faltante

### Performance
- Sesi√≥n persistente para m√∫ltiples requests
- Parser `lxml` para velocidad optimizada
- Context managers para gesti√≥n eficiente de recursos

## üìù Ejemplos Avanzados

### B√∫squeda con Paginaci√≥n Completa

```python
def buscar_anime_completo(nombre):
    """Busca un anime en todas las p√°ginas disponibles."""
    with AnimeFLVScraper() as scraper:
        todos_resultados = []
        pagina = 1
        
        while True:
            resultado = scraper.search(nombre, pagina)
            todos_resultados.extend(resultado['results'])
            
            if pagina >= resultado['pagination'].pagina_total:
                break
            pagina += 1
        
        return todos_resultados
```

### Informaci√≥n Completa de un Anime

```python
def info_anime_completa(anime_id):
    """Obtiene toda la informaci√≥n disponible de un anime."""
    with AnimeFLVScraper() as scraper:
        info = scraper.get_anime_info(anime_id)
        
        # Obtener enlaces del primer episodio si est√° disponible
        enlaces = []
        if info.episodios:
            try:
                enlaces = scraper.get_links(anime_id, info.episodios[0])
            except Exception as e:
                print(f"No se pudieron obtener enlaces: {e}")
        
        return {
            'info': info,
            'enlaces_primer_episodio': enlaces
        }
```

## ü§ù Contribuir

1. Fork el repositorio
2. Crea una rama para tu feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit tus cambios (`git commit -am 'Agrega nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Crea un Pull Request

### Gu√≠as para Contribuir

- Sigue el estilo de c√≥digo existente
- Agrega docstrings a todas las funciones p√∫blicas
- Incluye manejo de errores apropiado
- Escribe tests para nuevas funcionalidades

## ‚ö†Ô∏è Consideraciones Legales

Este proyecto est√° dise√±ado para **uso educativo y personal**. Los usuarios son responsables de:

- Cumplir con los t√©rminos de servicio de los sitios web
- Respetar los derechos de autor del contenido
- Usar el scraper de manera responsable y √©tica
- No sobrecargar los servidores con requests excesivos

## üêõ Resoluci√≥n de Problemas

### Errores Comunes

**Error: "No se encontraron resultados"**
- Verifica que el nombre del anime est√© escrito correctamente
- Algunos animes pueden tener nombres espec√≠ficos en el sitio

**Error de conexi√≥n**
- Verifica tu conexi√≥n a internet
- El sitio podr√≠a estar temporalmente inaccesible
- Considera implementar reintentos autom√°ticos

**Error: "No se pudieron obtener enlaces"**
- Verifica que el anime_id y n√∫mero de episodio sean correctos
- Algunos episodios pueden no tener enlaces disponibles

## üîÑ Roadmap

### Versi√≥n Actual (v1.0)
- ‚úÖ Scraper completo para AnimeFlv
- ‚úÖ B√∫squeda, informaci√≥n detallada y enlaces
- ‚úÖ Manejo robusto de errores

### Futuras Versiones
- üìã Soporte para m√∫ltiples sitios de anime
- üîÑ Sistema de cache para mejorar performance
- üìä API REST para acceso program√°tico
- ü§ñ Rate limiting inteligente
- üì± Interfaz web para uso f√°cil
- üîç B√∫squeda avanzada con filtros
- üìà Estad√≠sticas y analytics

## üè∑Ô∏è Versionado

Utilizamos [SemVer](http://semver.org/) para el versionado. Para las versiones disponibles, revisa los [tags de este repositorio](https://github.com/tu-usuario/anime-scraper/tags).

## üìÑ Licencia

Este proyecto est√° bajo la Licencia MIT - revisa el archivo [LICENSE.md](LICENSE.md) para m√°s detalles.

## üë• Autores

- **Tu Nombre** - *Desarrollo inicial* - [TuUsuario](https://github.com/tu-usuario)

## üôè Agradecimientos

- Comunidad de desarrolladores de Python
- Mantenedores de BeautifulSoup y cloudscraper
- Sitios de anime que proporcionan contenido a los fans

## üìû Soporte

Si encuentras alg√∫n problema o tienes preguntas:

1. Revisa la secci√≥n de [Issues](https://github.com/tu-usuario/anime-scraper/issues)
2. Crea un nuevo issue con detalles del problema
3. Incluye informaci√≥n de tu entorno (Python version, OS, etc.)

---

**‚ö° ¬øTe gusta el proyecto?** ¬°Dale una estrella ‚≠ê en GitHub!
