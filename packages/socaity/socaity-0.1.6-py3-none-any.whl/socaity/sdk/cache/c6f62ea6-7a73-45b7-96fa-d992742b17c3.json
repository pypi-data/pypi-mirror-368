{"id": "c6f62ea6-7a73-45b7-96fa-d992742b17c3", "display_name": "stability-ai/sdxl", "description": null, "short_desc": null, "endpoints": [{"id": "predictions", "display_name": "predictions", "description": "", "short_desc": null, "path": "/predictions", "parameters": [{"name": "mask", "type": ["file", "string"], "required": false, "default": null, "location": "body", "param_schema": {"type": "string", "title": "Mask", "format": "uri", "x-order": 3, "description": "Input mask for inpaint mode. Black areas will be preserved, white areas will be inpainted."}, "description": "Input mask for inpaint mode. Black areas will be preserved, white areas will be inpainted."}, {"name": "seed", "type": "integer", "required": false, "default": null, "location": "body", "param_schema": {"type": "integer", "title": "Seed", "x-order": 11, "description": "Random seed. Leave blank to randomize the seed"}, "description": "Random seed. Leave blank to randomize the seed"}, {"name": "image", "type": ["file", "string"], "required": false, "default": null, "location": "body", "param_schema": {"type": "string", "title": "Image", "format": "uri", "x-order": 2, "description": "Input image for img2img or inpaint mode"}, "description": "Input image for img2img or inpaint mode"}, {"name": "width", "type": "integer", "required": false, "default": 1024, "location": "body", "param_schema": {"type": "integer", "title": "Width", "default": 1024, "x-order": 4, "description": "Width of output image"}, "description": "Width of output image"}, {"name": "height", "type": "integer", "required": false, "default": 1024, "location": "body", "param_schema": {"type": "integer", "title": "Height", "default": 1024, "x-order": 5, "description": "Height of output image"}, "description": "Height of output image"}, {"name": "prompt", "type": "string", "required": false, "default": "An astronaut riding a rainbow unicorn", "location": "body", "param_schema": {"type": "string", "title": "Prompt", "default": "An astronaut riding a rainbow unicorn", "x-order": 0, "description": "Input prompt"}, "description": "Input prompt"}, {"name": "refine", "type": "string", "required": false, "default": "no_refiner", "location": "body", "param_schema": {"allOf": [{"$ref": "#/components/schemas/refine"}], "default": "no_refiner", "x-order": 12, "description": "Which refine style to use"}, "description": "Which refine style to use"}, {"name": "scheduler", "type": "string", "required": false, "default": "K_EULER", "location": "body", "param_schema": {"allOf": [{"$ref": "#/components/schemas/scheduler"}], "default": "K_EULER", "x-order": 7, "description": "scheduler"}, "description": "scheduler"}, {"name": "lora_scale", "type": "number", "required": false, "default": 0.6, "location": "body", "param_schema": {"type": "number", "title": "Lora Scale", "default": 0.6, "maximum": 1, "minimum": 0, "x-order": 16, "description": "LoRA additive scale. Only applicable on trained models."}, "description": "LoRA additive scale. Only applicable on trained models."}, {"name": "num_outputs", "type": "integer", "required": false, "default": 1, "location": "body", "param_schema": {"type": "integer", "title": "Num Outputs", "default": 1, "maximum": 4, "minimum": 1, "x-order": 6, "description": "Number of images to output."}, "description": "Number of images to output."}, {"name": "refine_steps", "type": "integer", "required": false, "default": null, "location": "body", "param_schema": {"type": "integer", "title": "Refine Steps", "x-order": 14, "description": "For base_image_refiner, the number of steps to refine, defaults to num_inference_steps"}, "description": "For base_image_refiner, the number of steps to refine, defaults to num_inference_steps"}, {"name": "guidance_scale", "type": "number", "required": false, "default": 7.5, "location": "body", "param_schema": {"type": "number", "title": "Guidance Scale", "default": 7.5, "maximum": 50, "minimum": 1, "x-order": 9, "description": "Scale for classifier-free guidance"}, "description": "Scale for classifier-free guidance"}, {"name": "apply_watermark", "type": "boolean", "required": false, "default": true, "location": "body", "param_schema": {"type": "boolean", "title": "Apply Watermark", "default": true, "x-order": 15, "description": "Applies a watermark to enable determining if an image is generated in downstream applications. If you have other provisions for generating or deploying images safely, you can use this to disable watermarking."}, "description": "Applies a watermark to enable determining if an image is generated in downstream applications. If you have other provisions for generating or deploying images safely, you can use this to disable watermarking."}, {"name": "high_noise_frac", "type": "number", "required": false, "default": 0.8, "location": "body", "param_schema": {"type": "number", "title": "High Noise Frac", "default": 0.8, "maximum": 1, "minimum": 0, "x-order": 13, "description": "For expert_ensemble_refiner, the fraction of noise to use"}, "description": "For expert_ensemble_refiner, the fraction of noise to use"}, {"name": "negative_prompt", "type": "string", "required": false, "default": "", "location": "body", "param_schema": {"type": "string", "title": "Negative Prompt", "default": "", "x-order": 1, "description": "Input Negative Prompt"}, "description": "Input Negative Prompt"}, {"name": "prompt_strength", "type": "number", "required": false, "default": 0.8, "location": "body", "param_schema": {"type": "number", "title": "Prompt Strength", "default": 0.8, "maximum": 1, "minimum": 0, "x-order": 10, "description": "Prompt strength when using img2img / inpaint. 1.0 corresponds to full destruction of information in image"}, "description": "Prompt strength when using img2img / inpaint. 1.0 corresponds to full destruction of information in image"}, {"name": "replicate_weights", "type": "string", "required": false, "default": null, "location": "body", "param_schema": {"type": "string", "title": "Replicate Weights", "x-order": 17, "description": "Replicate LoRA weights to use. Leave blank to use the default weights."}, "description": "Replicate LoRA weights to use. Leave blank to use the default weights."}, {"name": "num_inference_steps", "type": "integer", "required": false, "default": 50, "location": "body", "param_schema": {"type": "integer", "title": "Num Inference Steps", "default": 50, "maximum": 500, "minimum": 1, "x-order": 8, "description": "Number of denoising steps"}, "description": "Number of denoising steps"}, {"name": "disable_safety_checker", "type": "boolean", "required": false, "default": false, "location": "body", "param_schema": {"type": "boolean", "title": "Disable Safety Checker", "default": false, "x-order": 18, "description": "Disable safety checker for generated images. This feature is only available through the API. See [https://replicate.com/docs/how-does-replicate-work#safety](https://replicate.com/docs/how-does-replicate-work#safety)"}, "description": "Disable safety checker for generated images. This feature is only available through the API. See [https://replicate.com/docs/how-does-replicate-work#safety](https://replicate.com/docs/how-does-replicate-work#safety)"}], "responses": {"200": {"description": "Successful prediction", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/Output"}}}}}, "timeout_s": null}], "specification": "socaity", "used_models": [], "category": ["2a455e76-d55f-44fb-895c-9b49d7f18e92"], "family_id": "e7a7a0ae-d558-4a01-aff8-3014d122c405", "service_address": {"url": "http://localhost:8001/v1/stability-ai/sdxl"}, "created_at": "2025-08-12T10:19:41.666858+00:00", "version": "cdd3817139edf0cceb4f3ac6596c5926f14ce4a5", "schemas": {"Input": {"type": "object", "title": "Input", "properties": {"mask": {"type": "string", "title": "Mask", "format": "uri", "x-order": 3, "description": "Input mask for inpaint mode. Black areas will be preserved, white areas will be inpainted."}, "seed": {"type": "integer", "title": "Seed", "x-order": 11, "description": "Random seed. Leave blank to randomize the seed"}, "image": {"type": "string", "title": "Image", "format": "uri", "x-order": 2, "description": "Input image for img2img or inpaint mode"}, "width": {"type": "integer", "title": "Width", "default": 1024, "x-order": 4, "description": "Width of output image"}, "height": {"type": "integer", "title": "Height", "default": 1024, "x-order": 5, "description": "Height of output image"}, "prompt": {"type": "string", "title": "Prompt", "default": "An astronaut riding a rainbow unicorn", "x-order": 0, "description": "Input prompt"}, "refine": {"allOf": [{"$ref": "#/components/schemas/refine"}], "default": "no_refiner", "x-order": 12, "description": "Which refine style to use"}, "scheduler": {"allOf": [{"$ref": "#/components/schemas/scheduler"}], "default": "K_EULER", "x-order": 7, "description": "scheduler"}, "lora_scale": {"type": "number", "title": "Lora Scale", "default": 0.6, "maximum": 1, "minimum": 0, "x-order": 16, "description": "LoRA additive scale. Only applicable on trained models."}, "num_outputs": {"type": "integer", "title": "Num Outputs", "default": 1, "maximum": 4, "minimum": 1, "x-order": 6, "description": "Number of images to output."}, "refine_steps": {"type": "integer", "title": "Refine Steps", "x-order": 14, "description": "For base_image_refiner, the number of steps to refine, defaults to num_inference_steps"}, "guidance_scale": {"type": "number", "title": "Guidance Scale", "default": 7.5, "maximum": 50, "minimum": 1, "x-order": 9, "description": "Scale for classifier-free guidance"}, "apply_watermark": {"type": "boolean", "title": "Apply Watermark", "default": true, "x-order": 15, "description": "Applies a watermark to enable determining if an image is generated in downstream applications. If you have other provisions for generating or deploying images safely, you can use this to disable watermarking."}, "high_noise_frac": {"type": "number", "title": "High Noise Frac", "default": 0.8, "maximum": 1, "minimum": 0, "x-order": 13, "description": "For expert_ensemble_refiner, the fraction of noise to use"}, "negative_prompt": {"type": "string", "title": "Negative Prompt", "default": "", "x-order": 1, "description": "Input Negative Prompt"}, "prompt_strength": {"type": "number", "title": "Prompt Strength", "default": 0.8, "maximum": 1, "minimum": 0, "x-order": 10, "description": "Prompt strength when using img2img / inpaint. 1.0 corresponds to full destruction of information in image"}, "replicate_weights": {"type": "string", "title": "Replicate Weights", "x-order": 17, "description": "Replicate LoRA weights to use. Leave blank to use the default weights."}, "num_inference_steps": {"type": "integer", "title": "Num Inference Steps", "default": 50, "maximum": 500, "minimum": 1, "x-order": 8, "description": "Number of denoising steps"}, "disable_safety_checker": {"type": "boolean", "title": "Disable Safety Checker", "default": false, "x-order": 18, "description": "Disable safety checker for generated images. This feature is only available through the API. See [https://replicate.com/docs/how-does-replicate-work#safety](https://replicate.com/docs/how-does-replicate-work#safety)"}}}, "Output": {"type": "array", "items": {"type": "string", "format": "uri"}, "title": "Output"}, "Status": {"enum": ["starting", "processing", "succeeded", "canceled", "failed"], "type": "string", "title": "Status", "description": "An enumeration."}, "refine": {"enum": ["no_refiner", "expert_ensemble_refiner", "base_image_refiner"], "type": "string", "title": "refine", "description": "An enumeration."}, "scheduler": {"enum": ["DDIM", "DPMSolverMultistep", "HeunDiscrete", "KarrasDPM", "K_EULER_ANCESTRAL", "K_EULER", "PNDM"], "type": "string", "title": "scheduler", "description": "An enumeration."}, "WebhookEvent": {"enum": ["start", "output", "logs", "completed"], "type": "string", "title": "WebhookEvent", "description": "An enumeration."}, "lr_scheduler": {"enum": ["constant", "linear"], "type": "string", "title": "lr_scheduler", "description": "An enumeration."}, "TrainingInput": {"type": "object", "title": "TrainingInput", "required": ["input_images"], "properties": {"seed": {"type": "integer", "title": "Seed", "x-order": 1, "description": "Random seed for reproducible training. Leave empty to use a random seed"}, "ti_lr": {"type": "number", "title": "Ti Lr", "default": 0.0003, "x-order": 8, "description": "Scaling of learning rate for training textual inversion embeddings. Don't alter unless you know what you're doing."}, "is_lora": {"type": "boolean", "title": "Is Lora", "default": true, "x-order": 6, "description": "Whether to use LoRA training. If set to False, will use Full fine tuning"}, "lora_lr": {"type": "number", "title": "Lora Lr", "default": 0.0001, "x-order": 9, "description": "Scaling of learning rate for training LoRA embeddings. Don't alter unless you know what you're doing."}, "verbose": {"type": "boolean", "title": "Verbose", "default": true, "x-order": 19, "description": "verbose output"}, "lora_rank": {"type": "integer", "title": "Lora Rank", "default": 32, "x-order": 10, "description": "Rank of LoRA embeddings. Don't alter unless you know what you're doing."}, "resolution": {"type": "integer", "title": "Resolution", "default": 768, "x-order": 2, "description": "Square pixel resolution which your images will be resized to for training"}, "input_images": {"type": "string", "title": "Input Images", "format": "uri", "x-order": 0, "description": "A .zip or .tar file containing the image files that will be used for fine-tuning"}, "lr_scheduler": {"allOf": [{"$ref": "#/components/schemas/lr_scheduler"}], "default": "constant", "x-order": 11, "description": "Learning rate scheduler to use for training"}, "token_string": {"type": "string", "title": "Token String", "default": "TOK", "x-order": 13, "description": "A unique string that will be trained to refer to the concept in the input images. Can be anything, but TOK works well"}, "caption_prefix": {"type": "string", "title": "Caption Prefix", "default": "a photo of TOK, ", "x-order": 14, "description": "Text which will be used as prefix during automatic captioning. Must contain the `token_string`. For example, if caption text is 'a photo of TOK', automatic captioning will expand to 'a photo of TOK under a bridge', 'a photo of TOK holding a cup', etc."}, "lr_warmup_steps": {"type": "integer", "title": "Lr Warmup Steps", "default": 100, "x-order": 12, "description": "Number of warmup steps for lr schedulers with warmups."}, "max_train_steps": {"type": "integer", "title": "Max Train Steps", "default": 1000, "x-order": 5, "description": "Number of individual training steps. Takes precedence over num_train_epochs"}, "num_train_epochs": {"type": "integer", "title": "Num Train Epochs", "default": 4000, "x-order": 4, "description": "Number of epochs to loop through your training dataset"}, "train_batch_size": {"type": "integer", "title": "Train Batch Size", "default": 4, "x-order": 3, "description": "Batch size (per device) for training"}, "unet_learning_rate": {"type": "number", "title": "Unet Learning Rate", "default": 1e-06, "x-order": 7, "description": "Learning rate for the U-Net. We recommend this value to be somewhere between `1e-6` to `1e-5`."}, "checkpointing_steps": {"type": "integer", "title": "Checkpointing Steps", "default": 999999, "x-order": 20, "description": "Number of steps between saving checkpoints. Set to very very high number to disable checkpointing, because you don't need one."}, "clipseg_temperature": {"type": "number", "title": "Clipseg Temperature", "default": 1, "x-order": 18, "description": "How blurry you want the CLIPSeg mask to be. We recommend this value be something between `0.5` to `1.0`. If you want to have more sharp mask (but thus more errorful), you can decrease this value."}, "mask_target_prompts": {"type": "string", "title": "Mask Target Prompts", "x-order": 15, "description": "Prompt that describes part of the image that you will find important. For example, if you are fine-tuning your pet, `photo of a dog` will be a good prompt. Prompt-based masking is used to focus the fine-tuning process on the important/salient parts of the image"}, "input_images_filetype": {"allOf": [{"$ref": "#/components/schemas/input_images_filetype"}], "default": "infer", "x-order": 21, "description": "Filetype of the input images. Can be either `zip` or `tar`. By default its `infer`, and it will be inferred from the ext of input file."}, "crop_based_on_salience": {"type": "boolean", "title": "Crop Based On Salience", "default": true, "x-order": 16, "description": "If you want to crop the image to `target_size` based on the important parts of the image, set this to True. If you want to crop the image based on face detection, set this to False"}, "use_face_detection_instead": {"type": "boolean", "title": "Use Face Detection Instead", "default": false, "x-order": 17, "description": "If you want to use face detection instead of CLIPSeg for masking. For face applications, we recommend using this option."}}}, "TrainingOutput": {"type": "object", "title": "TrainingOutput", "required": ["weights"], "properties": {"weights": {"type": "string", "title": "Weights", "format": "uri"}}}, "TrainingRequest": {"type": "object", "title": "TrainingRequest", "properties": {"id": {"type": "string", "title": "Id"}, "input": {"$ref": "#/components/schemas/TrainingInput"}, "webhook": {"type": "string", "title": "Webhook", "format": "uri", "maxLength": 65536, "minLength": 1}, "created_at": {"type": "string", "title": "Created At", "format": "date-time"}, "output_file_prefix": {"type": "string", "title": "Output File Prefix"}, "webhook_events_filter": {"type": "array", "items": {"$ref": "#/components/schemas/WebhookEvent"}, "default": ["start", "output", "logs", "completed"]}}}, "ValidationError": {"type": "object", "title": "ValidationError", "required": ["loc", "msg", "type"], "properties": {"loc": {"type": "array", "items": {"anyOf": [{"type": "string"}, {"type": "integer"}]}, "title": "Location"}, "msg": {"type": "string", "title": "Message"}, "type": {"type": "string", "title": "Error Type"}}}, "TrainingResponse": {"type": "object", "title": "TrainingResponse", "properties": {"id": {"type": "string", "title": "Id"}, "logs": {"type": "string", "title": "Logs", "default": ""}, "error": {"type": "string", "title": "Error"}, "input": {"$ref": "#/components/schemas/TrainingInput"}, "output": {"$ref": "#/components/schemas/TrainingOutput"}, "status": {"$ref": "#/components/schemas/Status"}, "metrics": {"type": "object", "title": "Metrics"}, "version": {"type": "string", "title": "Version"}, "created_at": {"type": "string", "title": "Created At", "format": "date-time"}, "started_at": {"type": "string", "title": "Started At", "format": "date-time"}, "completed_at": {"type": "string", "title": "Completed At", "format": "date-time"}}}, "PredictionRequest": {"type": "object", "title": "PredictionRequest", "properties": {"id": {"type": "string", "title": "Id"}, "input": {"$ref": "#/components/schemas/Input"}, "webhook": {"type": "string", "title": "Webhook", "format": "uri", "maxLength": 65536, "minLength": 1}, "created_at": {"type": "string", "title": "Created At", "format": "date-time"}, "output_file_prefix": {"type": "string", "title": "Output File Prefix"}, "webhook_events_filter": {"type": "array", "items": {"$ref": "#/components/schemas/WebhookEvent"}, "default": ["start", "output", "logs", "completed"]}}}, "PredictionResponse": {"type": "object", "title": "PredictionResponse", "properties": {"id": {"type": "string", "title": "Id"}, "logs": {"type": "string", "title": "Logs", "default": ""}, "error": {"type": "string", "title": "Error"}, "input": {"$ref": "#/components/schemas/Input"}, "output": {"$ref": "#/components/schemas/Output"}, "status": {"$ref": "#/components/schemas/Status"}, "metrics": {"type": "object", "title": "Metrics"}, "version": {"type": "string", "title": "Version"}, "created_at": {"type": "string", "title": "Created At", "format": "date-time"}, "started_at": {"type": "string", "title": "Started At", "format": "date-time"}, "completed_at": {"type": "string", "title": "Completed At", "format": "date-time"}}}, "HTTPValidationError": {"type": "object", "title": "HTTPValidationError", "properties": {"detail": {"type": "array", "items": {"$ref": "#/components/schemas/ValidationError"}, "title": "Detail"}}}, "input_images_filetype": {"enum": ["zip", "tar", "infer"], "type": "string", "title": "input_images_filetype", "description": "An enumeration."}}}