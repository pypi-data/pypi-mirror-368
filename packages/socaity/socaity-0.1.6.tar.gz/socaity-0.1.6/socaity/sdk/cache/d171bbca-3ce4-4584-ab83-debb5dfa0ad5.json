{"id": "d171bbca-3ce4-4584-ab83-debb5dfa0ad5", "display_name": "meta/meta-llama-3-8b-instruct", "description": null, "short_desc": null, "endpoints": [{"id": "predictions", "display_name": "predictions", "description": "", "short_desc": null, "path": "/predictions", "parameters": [{"name": "top_k", "type": "integer", "required": false, "default": 50, "location": "body", "param_schema": {"type": "integer", "title": "Top K", "default": 50, "x-order": 5, "description": "The number of highest probability tokens to consider for generating the output. If > 0, only keep the top k tokens with highest probability (top-k filtering)."}, "description": "The number of highest probability tokens to consider for generating the output. If > 0, only keep the top k tokens with highest probability (top-k filtering)."}, {"name": "top_p", "type": "number", "required": false, "default": 0.9, "location": "body", "param_schema": {"type": "number", "title": "Top P", "default": 0.9, "x-order": 4, "description": "A probability threshold for generating the output. If < 1.0, only keep the top tokens with cumulative probability >= top_p (nucleus filtering). Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751)."}, "description": "A probability threshold for generating the output. If < 1.0, only keep the top tokens with cumulative probability >= top_p (nucleus filtering). Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751)."}, {"name": "prompt", "type": "string", "required": false, "default": "", "location": "body", "param_schema": {"type": "string", "title": "Prompt", "default": "", "x-order": 0, "description": "Prompt"}, "description": "Prompt"}, {"name": "max_tokens", "type": "integer", "required": false, "default": 512, "location": "body", "param_schema": {"type": "integer", "title": "Max Tokens", "default": 512, "x-order": 2, "description": "The maximum number of tokens the model should generate as output."}, "description": "The maximum number of tokens the model should generate as output."}, {"name": "min_tokens", "type": "integer", "required": false, "default": 0, "location": "body", "param_schema": {"type": "integer", "title": "Min Tokens", "default": 0, "x-order": 1, "description": "The minimum number of tokens the model should generate as output."}, "description": "The minimum number of tokens the model should generate as output."}, {"name": "temperature", "type": "number", "required": false, "default": 0.6, "location": "body", "param_schema": {"type": "number", "title": "Temperature", "default": 0.6, "x-order": 3, "description": "The value used to modulate the next token probabilities."}, "description": "The value used to modulate the next token probabilities."}, {"name": "prompt_template", "type": "string", "required": false, "default": "{prompt}", "location": "body", "param_schema": {"type": "string", "title": "Prompt Template", "default": "{prompt}", "x-order": 8, "description": "Prompt template. The string `{prompt}` will be substituted for the input prompt. If you want to generate dialog output, use this template as a starting point and construct the prompt string manually, leaving `prompt_template={prompt}`."}, "description": "Prompt template. The string `{prompt}` will be substituted for the input prompt. If you want to generate dialog output, use this template as a starting point and construct the prompt string manually, leaving `prompt_template={prompt}`."}, {"name": "presence_penalty", "type": "number", "required": false, "default": 1.15, "location": "body", "param_schema": {"type": "number", "title": "Presence Penalty", "default": 1.15, "x-order": 6, "description": "Presence penalty"}, "description": "Presence penalty"}, {"name": "frequency_penalty", "type": "number", "required": false, "default": 0.2, "location": "body", "param_schema": {"type": "number", "title": "Frequency Penalty", "default": 0.2, "x-order": 7, "description": "Frequency penalty"}, "description": "Frequency penalty"}], "responses": {"200": {"description": "Successful prediction", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/Output"}}}}}, "timeout_s": null}], "specification": "socaity", "used_models": [], "category": ["01dd20d6-db6a-4c59-9cee-1a3860356a88"], "family_id": "6d19f203-74b9-405e-bb68-896cb96a2dc0", "service_address": {"url": "http://localhost:8001/v1/meta/meta-llama-3-8b-instruct"}, "created_at": "2025-08-12T10:19:40.187686+00:00", "version": "a512c55e78951e824baca54d4b52ac0d63a641e0", "schemas": {"Input": {"type": "object", "title": "Input", "properties": {"top_k": {"type": "integer", "title": "Top K", "default": 50, "x-order": 5, "description": "The number of highest probability tokens to consider for generating the output. If > 0, only keep the top k tokens with highest probability (top-k filtering)."}, "top_p": {"type": "number", "title": "Top P", "default": 0.9, "x-order": 4, "description": "A probability threshold for generating the output. If < 1.0, only keep the top tokens with cumulative probability >= top_p (nucleus filtering). Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751)."}, "prompt": {"type": "string", "title": "Prompt", "default": "", "x-order": 0, "description": "Prompt"}, "max_tokens": {"type": "integer", "title": "Max Tokens", "default": 512, "x-order": 2, "description": "The maximum number of tokens the model should generate as output."}, "min_tokens": {"type": "integer", "title": "Min Tokens", "default": 0, "x-order": 1, "description": "The minimum number of tokens the model should generate as output."}, "temperature": {"type": "number", "title": "Temperature", "default": 0.6, "x-order": 3, "description": "The value used to modulate the next token probabilities."}, "prompt_template": {"type": "string", "title": "Prompt Template", "default": "{prompt}", "x-order": 8, "description": "Prompt template. The string `{prompt}` will be substituted for the input prompt. If you want to generate dialog output, use this template as a starting point and construct the prompt string manually, leaving `prompt_template={prompt}`."}, "presence_penalty": {"type": "number", "title": "Presence Penalty", "default": 1.15, "x-order": 6, "description": "Presence penalty"}, "frequency_penalty": {"type": "number", "title": "Frequency Penalty", "default": 0.2, "x-order": 7, "description": "Frequency penalty"}}}, "Output": {"type": "array", "items": {"type": "string"}, "title": "Output", "x-cog-array-type": "iterator", "x-cog-array-display": "concatenate"}, "Status": {"enum": ["starting", "processing", "succeeded", "canceled", "failed"], "type": "string", "title": "Status", "description": "An enumeration."}, "WebhookEvent": {"enum": ["start", "output", "logs", "completed"], "type": "string", "title": "WebhookEvent", "description": "An enumeration."}, "ValidationError": {"type": "object", "title": "ValidationError", "required": ["loc", "msg", "type"], "properties": {"loc": {"type": "array", "items": {"anyOf": [{"type": "string"}, {"type": "integer"}]}, "title": "Location"}, "msg": {"type": "string", "title": "Message"}, "type": {"type": "string", "title": "Error Type"}}}, "PredictionRequest": {"type": "object", "title": "PredictionRequest", "properties": {"id": {"type": "string", "title": "Id"}, "input": {"$ref": "#/components/schemas/Input"}, "webhook": {"type": "string", "title": "Webhook", "format": "uri", "maxLength": 65536, "minLength": 1}, "created_at": {"type": "string", "title": "Created At", "format": "date-time"}, "output_file_prefix": {"type": "string", "title": "Output File Prefix"}, "webhook_events_filter": {"type": "array", "items": {"$ref": "#/components/schemas/WebhookEvent"}, "default": ["start", "output", "logs", "completed"]}}}, "PredictionResponse": {"type": "object", "title": "PredictionResponse", "properties": {"id": {"type": "string", "title": "Id"}, "logs": {"type": "string", "title": "Logs", "default": ""}, "error": {"type": "string", "title": "Error"}, "input": {"$ref": "#/components/schemas/Input"}, "output": {"$ref": "#/components/schemas/Output"}, "status": {"$ref": "#/components/schemas/Status"}, "metrics": {"type": "object", "title": "Metrics"}, "version": {"type": "string", "title": "Version"}, "created_at": {"type": "string", "title": "Created At", "format": "date-time"}, "started_at": {"type": "string", "title": "Started At", "format": "date-time"}, "completed_at": {"type": "string", "title": "Completed At", "format": "date-time"}}}, "HTTPValidationError": {"type": "object", "title": "HTTPValidationError", "properties": {"detail": {"type": "array", "items": {"$ref": "#/components/schemas/ValidationError"}, "title": "Detail"}}}}}