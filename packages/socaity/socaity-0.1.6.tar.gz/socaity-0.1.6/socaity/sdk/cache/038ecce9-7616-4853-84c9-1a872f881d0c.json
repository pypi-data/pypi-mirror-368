{"id": "038ecce9-7616-4853-84c9-1a872f881d0c", "display_name": "meta/meta-llama-3-1-405b-instruct", "description": null, "short_desc": null, "endpoints": [{"id": "predictions", "display_name": "predictions", "description": "", "short_desc": null, "path": "/predictions", "parameters": [{"name": "top_k", "type": "integer", "required": false, "default": 50, "location": "body", "param_schema": {"type": "integer", "title": "Top K", "default": 50, "x-order": 6, "description": "The number of highest probability tokens to consider for generating the output. If > 0, only keep the top k tokens with highest probability (top-k filtering)."}, "description": "The number of highest probability tokens to consider for generating the output. If > 0, only keep the top k tokens with highest probability (top-k filtering)."}, {"name": "top_p", "type": "number", "required": false, "default": 0.9, "location": "body", "param_schema": {"type": "number", "title": "Top P", "default": 0.9, "x-order": 5, "description": "A probability threshold for generating the output. If < 1.0, only keep the top tokens with cumulative probability >= top_p (nucleus filtering). Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751)."}, "description": "A probability threshold for generating the output. If < 1.0, only keep the top tokens with cumulative probability >= top_p (nucleus filtering). Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751)."}, {"name": "prompt", "type": "string", "required": false, "default": "", "location": "body", "param_schema": {"type": "string", "title": "Prompt", "default": "", "x-order": 0, "description": "Prompt"}, "description": "Prompt"}, {"name": "max_tokens", "type": "integer", "required": false, "default": 512, "location": "body", "param_schema": {"type": "integer", "title": "Max Tokens", "default": 512, "x-order": 3, "description": "The maximum number of tokens the model should generate as output."}, "description": "The maximum number of tokens the model should generate as output."}, {"name": "min_tokens", "type": "integer", "required": false, "default": 0, "location": "body", "param_schema": {"type": "integer", "title": "Min Tokens", "default": 0, "x-order": 2, "description": "The minimum number of tokens the model should generate as output."}, "description": "The minimum number of tokens the model should generate as output."}, {"name": "temperature", "type": "number", "required": false, "default": 0.6, "location": "body", "param_schema": {"type": "number", "title": "Temperature", "default": 0.6, "x-order": 4, "description": "The value used to modulate the next token probabilities."}, "description": "The value used to modulate the next token probabilities."}, {"name": "system_prompt", "type": "string", "required": false, "default": "You are a helpful assistant.", "location": "body", "param_schema": {"type": "string", "title": "System Prompt", "default": "You are a helpful assistant.", "x-order": 1, "description": "System prompt to send to the model. This is prepended to the prompt and helps guide system behavior. Ignored for non-chat models."}, "description": "System prompt to send to the model. This is prepended to the prompt and helps guide system behavior. Ignored for non-chat models."}, {"name": "stop_sequences", "type": "string", "required": false, "default": null, "location": "body", "param_schema": {"type": "string", "title": "Stop Sequences", "x-order": 9, "description": "A comma-separated list of sequences to stop generation at. For example, '<end>,<stop>' will stop generation at the first instance of 'end' or '<stop>'."}, "description": "A comma-separated list of sequences to stop generation at. For example, '<end>,<stop>' will stop generation at the first instance of 'end' or '<stop>'."}, {"name": "presence_penalty", "type": "number", "required": false, "default": 0, "location": "body", "param_schema": {"type": "number", "title": "Presence Penalty", "default": 0, "x-order": 7, "description": "Presence penalty"}, "description": "Presence penalty"}, {"name": "frequency_penalty", "type": "number", "required": false, "default": 0, "location": "body", "param_schema": {"type": "number", "title": "Frequency Penalty", "default": 0, "x-order": 8, "description": "Frequency penalty"}, "description": "Frequency penalty"}], "responses": {"200": {"description": "Successful prediction", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/Output"}}}}}, "timeout_s": null}], "specification": "socaity", "used_models": [], "category": ["01dd20d6-db6a-4c59-9cee-1a3860356a88"], "family_id": "ae24b631-7bf6-4c07-b12a-1e71790ae75c", "service_address": {"url": "http://localhost:8001/v1/meta/meta-llama-3-1-405b-instruct"}, "created_at": "2025-08-12T10:19:40.134910+00:00", "version": "582ad07198ee76b587926e5812cb8122ce2908e1", "schemas": {"Input": {"type": "object", "title": "Input", "properties": {"top_k": {"type": "integer", "title": "Top K", "default": 50, "x-order": 6, "description": "The number of highest probability tokens to consider for generating the output. If > 0, only keep the top k tokens with highest probability (top-k filtering)."}, "top_p": {"type": "number", "title": "Top P", "default": 0.9, "x-order": 5, "description": "A probability threshold for generating the output. If < 1.0, only keep the top tokens with cumulative probability >= top_p (nucleus filtering). Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751)."}, "prompt": {"type": "string", "title": "Prompt", "default": "", "x-order": 0, "description": "Prompt"}, "max_tokens": {"type": "integer", "title": "Max Tokens", "default": 512, "x-order": 3, "description": "The maximum number of tokens the model should generate as output."}, "min_tokens": {"type": "integer", "title": "Min Tokens", "default": 0, "x-order": 2, "description": "The minimum number of tokens the model should generate as output."}, "temperature": {"type": "number", "title": "Temperature", "default": 0.6, "x-order": 4, "description": "The value used to modulate the next token probabilities."}, "system_prompt": {"type": "string", "title": "System Prompt", "default": "You are a helpful assistant.", "x-order": 1, "description": "System prompt to send to the model. This is prepended to the prompt and helps guide system behavior. Ignored for non-chat models."}, "stop_sequences": {"type": "string", "title": "Stop Sequences", "x-order": 9, "description": "A comma-separated list of sequences to stop generation at. For example, '<end>,<stop>' will stop generation at the first instance of 'end' or '<stop>'."}, "presence_penalty": {"type": "number", "title": "Presence Penalty", "default": 0, "x-order": 7, "description": "Presence penalty"}, "frequency_penalty": {"type": "number", "title": "Frequency Penalty", "default": 0, "x-order": 8, "description": "Frequency penalty"}}}, "Output": {"type": "array", "items": {"type": "string"}, "title": "Output", "x-cog-array-type": "iterator", "x-cog-array-display": "concatenate"}, "Status": {"enum": ["starting", "processing", "succeeded", "canceled", "failed"], "type": "string", "title": "Status", "description": "An enumeration."}, "WebhookEvent": {"enum": ["start", "output", "logs", "completed"], "type": "string", "title": "WebhookEvent", "description": "An enumeration."}, "TrainingInput": {"type": "object", "title": "TrainingInput", "required": ["hf_model_id"], "properties": {"hf_token": {"type": "string", "title": "Hf Token", "format": "password", "x-order": 2, "description": "\n        Hugging Face API token. \n        Get your token at https://huggingface.co/settings/tokens\n        ", "x-cog-secret": true}, "hf_model_id": {"type": "string", "title": "Hf Model Id", "x-order": 0, "description": "\n        Hugging Face model identifier \n        (e.g. NousResearch/Hermes-2-Theta-Llama-3-8B).\n        "}, "hf_model_sha": {"type": "string", "title": "Hf Model Sha", "x-order": 1, "description": "\n        The version of the model.\n        If unspecified, the latest version is used.\n        "}, "allow_patterns": {"type": "string", "title": "Allow Patterns", "x-order": 3, "description": "\n        Patterns constituting the allowlist. \n        If provided, item paths must match at least one pattern from the allowlist. \n        (e.g. \"*.safetensors\").\n        "}, "ignore_patterns": {"type": "string", "title": "Ignore Patterns", "default": "*.gguf", "x-order": 4, "description": "\n        Patterns constituting the denylist. \n        If provided, item paths must not match any patterns from the denylist. \n        (e.g. \"*.gguf\").\n        "}, "prompt_template": {"type": "string", "title": "Prompt Template", "x-order": 5, "description": "Prompt template. This is a Jinja2 template that overrides the HuggingFace tokenizer configuration. If this is set to None and nothing is configured on HuggingFace, no formatting is applied. To override HuggingFace configuration, set it to the string `{{messages[0]['content']}}`."}}}, "TrainingOutput": {"type": "object", "title": "TrainingOutput", "required": ["weights"], "properties": {"weights": {"type": "string", "title": "Weights", "format": "uri"}}}, "TrainingRequest": {"type": "object", "title": "TrainingRequest", "properties": {"id": {"type": "string", "title": "Id"}, "input": {"$ref": "#/components/schemas/TrainingInput"}, "webhook": {"type": "string", "title": "Webhook", "format": "uri", "maxLength": 65536, "minLength": 1}, "created_at": {"type": "string", "title": "Created At", "format": "date-time"}, "output_file_prefix": {"type": "string", "title": "Output File Prefix"}, "webhook_events_filter": {"type": "array", "items": {"$ref": "#/components/schemas/WebhookEvent"}, "default": ["start", "output", "logs", "completed"]}}}, "ValidationError": {"type": "object", "title": "ValidationError", "required": ["loc", "msg", "type"], "properties": {"loc": {"type": "array", "items": {"anyOf": [{"type": "string"}, {"type": "integer"}]}, "title": "Location"}, "msg": {"type": "string", "title": "Message"}, "type": {"type": "string", "title": "Error Type"}}}, "TrainingResponse": {"type": "object", "title": "TrainingResponse", "properties": {"id": {"type": "string", "title": "Id"}, "logs": {"type": "string", "title": "Logs", "default": ""}, "error": {"type": "string", "title": "Error"}, "input": {"$ref": "#/components/schemas/TrainingInput"}, "output": {"$ref": "#/components/schemas/TrainingOutput"}, "status": {"$ref": "#/components/schemas/Status"}, "metrics": {"type": "object", "title": "Metrics"}, "version": {"type": "string", "title": "Version"}, "created_at": {"type": "string", "title": "Created At", "format": "date-time"}, "started_at": {"type": "string", "title": "Started At", "format": "date-time"}, "completed_at": {"type": "string", "title": "Completed At", "format": "date-time"}}}, "PredictionRequest": {"type": "object", "title": "PredictionRequest", "properties": {"id": {"type": "string", "title": "Id"}, "input": {"$ref": "#/components/schemas/Input"}, "webhook": {"type": "string", "title": "Webhook", "format": "uri", "maxLength": 65536, "minLength": 1}, "created_at": {"type": "string", "title": "Created At", "format": "date-time"}, "output_file_prefix": {"type": "string", "title": "Output File Prefix"}, "webhook_events_filter": {"type": "array", "items": {"$ref": "#/components/schemas/WebhookEvent"}, "default": ["start", "output", "logs", "completed"]}}}, "PredictionResponse": {"type": "object", "title": "PredictionResponse", "properties": {"id": {"type": "string", "title": "Id"}, "logs": {"type": "string", "title": "Logs", "default": ""}, "error": {"type": "string", "title": "Error"}, "input": {"$ref": "#/components/schemas/Input"}, "output": {"$ref": "#/components/schemas/Output"}, "status": {"$ref": "#/components/schemas/Status"}, "metrics": {"type": "object", "title": "Metrics"}, "version": {"type": "string", "title": "Version"}, "created_at": {"type": "string", "title": "Created At", "format": "date-time"}, "started_at": {"type": "string", "title": "Started At", "format": "date-time"}, "completed_at": {"type": "string", "title": "Completed At", "format": "date-time"}}}, "HTTPValidationError": {"type": "object", "title": "HTTPValidationError", "properties": {"detail": {"type": "array", "items": {"$ref": "#/components/schemas/ValidationError"}, "title": "Detail"}}}}}