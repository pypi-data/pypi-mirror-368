{"id": "0b47f390-cedf-429d-9157-dada4f0b747a", "display_name": "center-for-curriculum-redesign/bge-1-5-query-embeddings", "description": null, "short_desc": null, "endpoints": [{"id": "predictions", "display_name": "predictions", "description": "", "short_desc": null, "path": "/predictions", "parameters": [{"name": "normalize", "type": "boolean", "required": false, "default": true, "location": "body", "param_schema": {"type": "boolean", "title": "Normalize", "default": true, "x-order": 1, "description": "normalizes returned embedding vectors to a magnitude of 1. (default: true, as this model presumes cosine similarity comparisons downstream)"}, "description": "normalizes returned embedding vectors to a magnitude of 1. (default: true, as this model presumes cosine similarity comparisons downstream)"}, {"name": "precision", "type": "string", "required": false, "default": "full", "location": "body", "param_schema": {"allOf": [{"$ref": "#/components/schemas/precision"}], "default": "full", "x-order": 3, "description": "numerical precision for inference computations. Either full or half. Defaults to a paranoid value of full. You may want to test if 'half' is sufficient for your needs, though regardless you should probably prefer to use the same precision for querying as you do for archiving."}, "description": "numerical precision for inference computations. Either full or half. Defaults to a paranoid value of full. You may want to test if 'half' is sufficient for your needs, though regardless you should probably prefer to use the same precision for querying as you do for archiving."}, {"name": "query_texts", "type": "string", "required": false, "default": "[]", "location": "body", "param_schema": {"type": "string", "title": "Query Texts", "default": "[]", "x-order": 0, "description": "A serialized JSON array of strings you wish to generate *retreival* embeddings for. (note, that you should keep this list short to avoid Replicate response size limitations). Use this to embed short text queries intended for comparison against document text. A vector will be returned corresponding to each line of text in the input array (in order of input). This endpoint will automatically format your query strings for retrieval, you do not need to preprocess them."}, "description": "A serialized JSON array of strings you wish to generate *retreival* embeddings for. (note, that you should keep this list short to avoid Replicate response size limitations). Use this to embed short text queries intended for comparison against document text. A vector will be returned corresponding to each line of text in the input array (in order of input). This endpoint will automatically format your query strings for retrieval, you do not need to preprocess them."}, {"name": "batchtoken_max", "type": "number", "required": false, "default": 200, "location": "body", "param_schema": {"type": "number", "title": "Batchtoken Max", "default": 200, "minimum": 0.5, "x-order": 2, "description": "You probably don't need to worry about this parameter if you're just getting the embeddings for a handful of queries. This parameter sets the maximumum number of kibiTokens (1 kibiToken = 1024 tokens) to try to stuff into a batch (to avoid out of memory errors but maximize throughput). If the total number of tokens across the flattened list of requested embeddings exceed this value, the list will be split internally and run across multiple forward passes. This will not affect the shape of your output, just the time it takes to run."}, "description": "You probably don't need to worry about this parameter if you're just getting the embeddings for a handful of queries. This parameter sets the maximumum number of kibiTokens (1 kibiToken = 1024 tokens) to try to stuff into a batch (to avoid out of memory errors but maximize throughput). If the total number of tokens across the flattened list of requested embeddings exceed this value, the list will be split internally and run across multiple forward passes. This will not affect the shape of your output, just the time it takes to run."}], "responses": {"200": {"description": "Successful prediction", "content": {"application/json": {"schema": {"$ref": "#/components/schemas/Output"}}}}}, "timeout_s": null}], "specification": "socaity", "used_models": [], "category": ["b3a961b9-9466-47e6-90df-92ba01f0bd31"], "family_id": "2307739c-ca0a-46e7-a9ce-859e61e425e1", "service_address": {"url": "http://localhost:8001/v1/center-for-curriculum-redesign/bge-1-5-query-embeddings"}, "created_at": "2025-08-12T10:19:39.782330+00:00", "version": "71107252d95b71e0b58c139c5e0b35faa40b4e18", "schemas": {"Input": {"type": "object", "title": "Input", "properties": {"normalize": {"type": "boolean", "title": "Normalize", "default": true, "x-order": 1, "description": "normalizes returned embedding vectors to a magnitude of 1. (default: true, as this model presumes cosine similarity comparisons downstream)"}, "precision": {"allOf": [{"$ref": "#/components/schemas/precision"}], "default": "full", "x-order": 3, "description": "numerical precision for inference computations. Either full or half. Defaults to a paranoid value of full. You may want to test if 'half' is sufficient for your needs, though regardless you should probably prefer to use the same precision for querying as you do for archiving."}, "query_texts": {"type": "string", "title": "Query Texts", "default": "[]", "x-order": 0, "description": "A serialized JSON array of strings you wish to generate *retreival* embeddings for. (note, that you should keep this list short to avoid Replicate response size limitations). Use this to embed short text queries intended for comparison against document text. A vector will be returned corresponding to each line of text in the input array (in order of input). This endpoint will automatically format your query strings for retrieval, you do not need to preprocess them."}, "batchtoken_max": {"type": "number", "title": "Batchtoken Max", "default": 200, "minimum": 0.5, "x-order": 2, "description": "You probably don't need to worry about this parameter if you're just getting the embeddings for a handful of queries. This parameter sets the maximumum number of kibiTokens (1 kibiToken = 1024 tokens) to try to stuff into a batch (to avoid out of memory errors but maximize throughput). If the total number of tokens across the flattened list of requested embeddings exceed this value, the list will be split internally and run across multiple forward passes. This will not affect the shape of your output, just the time it takes to run."}}}, "Output": {"type": "object", "title": "Output", "required": ["query_embeddings", "extra_metrics"], "properties": {"extra_metrics": {"type": "string", "title": "Extra Metrics"}, "query_embeddings": {"type": "array", "items": {"type": "array", "items": {"type": "number"}}, "title": "Query Embeddings"}}}, "Status": {"enum": ["starting", "processing", "succeeded", "canceled", "failed"], "type": "string", "title": "Status", "description": "An enumeration."}, "precision": {"enum": ["full", "half"], "type": "string", "title": "precision", "description": "An enumeration."}, "WebhookEvent": {"enum": ["start", "output", "logs", "completed"], "type": "string", "title": "WebhookEvent", "description": "An enumeration."}, "ValidationError": {"type": "object", "title": "ValidationError", "required": ["loc", "msg", "type"], "properties": {"loc": {"type": "array", "items": {"anyOf": [{"type": "string"}, {"type": "integer"}]}, "title": "Location"}, "msg": {"type": "string", "title": "Message"}, "type": {"type": "string", "title": "Error Type"}}}, "PredictionRequest": {"type": "object", "title": "PredictionRequest", "properties": {"id": {"type": "string", "title": "Id"}, "input": {"$ref": "#/components/schemas/Input"}, "webhook": {"type": "string", "title": "Webhook", "format": "uri", "maxLength": 65536, "minLength": 1}, "created_at": {"type": "string", "title": "Created At", "format": "date-time"}, "output_file_prefix": {"type": "string", "title": "Output File Prefix"}, "webhook_events_filter": {"type": "array", "items": {"$ref": "#/components/schemas/WebhookEvent"}, "default": ["start", "output", "logs", "completed"]}}}, "PredictionResponse": {"type": "object", "title": "PredictionResponse", "properties": {"id": {"type": "string", "title": "Id"}, "logs": {"type": "string", "title": "Logs", "default": ""}, "error": {"type": "string", "title": "Error"}, "input": {"$ref": "#/components/schemas/Input"}, "output": {"$ref": "#/components/schemas/Output"}, "status": {"$ref": "#/components/schemas/Status"}, "metrics": {"type": "object", "title": "Metrics"}, "version": {"type": "string", "title": "Version"}, "created_at": {"type": "string", "title": "Created At", "format": "date-time"}, "started_at": {"type": "string", "title": "Started At", "format": "date-time"}, "completed_at": {"type": "string", "title": "Completed At", "format": "date-time"}}}, "HTTPValidationError": {"type": "object", "title": "HTTPValidationError", "properties": {"detail": {"type": "array", "items": {"$ref": "#/components/schemas/ValidationError"}, "title": "Detail"}}}}}