{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f935234",
   "metadata": {},
   "source": [
    "# Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92f4a7a",
   "metadata": {},
   "source": [
    "## Wrapping a PyTorch model\n",
    "Create a simple PyTorch model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adc61e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple MLP.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple model class.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim = 64):\n",
    "        super(SimpleModel, self).__init__()\n",
    "\n",
    "        self.mlp = MLP(input_dim, output_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mlp(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6941215c",
   "metadata": {},
   "source": [
    "Train the model on some data.\n",
    "\n",
    "$$\n",
    "y = x_0^2 +3 \\sin(x_4)-4\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f363579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the dataset \n",
    "x = np.array([np.random.uniform(0, 1, 10_000) for _ in range(5)]).T  \n",
    "y = x[:, 0]**2 + 3*np.sin(x[:, 4]) - 4\n",
    "noise = np.array([np.random.normal(0, 0.05*np.std(y)) for _ in range(len(y))])\n",
    "y = y + noise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fcf89e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up training\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_model(model, dataloader, opt, criterion, epochs = 100):\n",
    "    \"\"\"\n",
    "    Train a model for the specified number of epochs.\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model to train\n",
    "        dataloader: DataLoader for training data\n",
    "        opt: Optimizer\n",
    "        criterion: Loss function\n",
    "        epochs: Number of training epochs\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (trained_model, loss_tracker)\n",
    "    \"\"\"\n",
    "    loss_tracker = []\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        \n",
    "        for batch_x, batch_y in dataloader:\n",
    "            # Forward pass\n",
    "            pred = model(batch_x)\n",
    "            loss = criterion(pred, batch_y)\n",
    "            \n",
    "            # Backward pass\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        loss_tracker.append(epoch_loss)\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            avg_loss = epoch_loss / len(dataloader)\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Avg Loss: {avg_loss:.6f}')\n",
    "    return model, loss_tracker\n",
    "\n",
    "# Instantiate the model\n",
    "model = SimpleModel(input_dim=x.shape[1], output_dim=1)\n",
    "\n",
    "# Set up training\n",
    "criterion = nn.MSELoss()\n",
    "opt = optim.Adam(model.parameters(), lr=0.001)\n",
    "X_train, _, y_train, _ = train_test_split(x, y.reshape(-1,1), test_size=0.2, random_state=290402)\n",
    "\n",
    "# Set up dataset\n",
    "dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "add838bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Avg Loss: 0.103513\n",
      "Epoch [10/20], Avg Loss: 0.069692\n",
      "Epoch [15/20], Avg Loss: 0.054784\n",
      "Epoch [20/20], Avg Loss: 0.043314\n"
     ]
    }
   ],
   "source": [
    "# Train the model and save the weights\n",
    "\n",
    "model, losses = train_model(model, dataloader, opt, criterion, 20)\n",
    "torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb22ef1",
   "metadata": {},
   "source": [
    "Wrap the mlp layer in the trained model with MLP_SR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77bc4f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liz/PhD/SymTorch_project/symtorch_venv/lib/python3.11/site-packages/juliacall/__init__.py:61: UserWarning: torch was imported before juliacall. This may cause a segfault. To avoid this, import juliacall before importing torch. For updates, see https://github.com/pytorch/pytorch/issues/78829.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected IPython. Loading juliacall extension. See https://juliapy.github.io/PythonCall.jl/stable/compat/#IPython\n"
     ]
    }
   ],
   "source": [
    "from symtorch.mlp_sr import MLP_SR\n",
    "model.mlp = MLP_SR(model.mlp, mlp_name = 'Sequential')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1db5df8",
   "metadata": {},
   "source": [
    "## Interpret the MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca15a8d3",
   "metadata": {},
   "source": [
    "In this example, we pass extra parameters into the `.interpret` method (complexity of operators/constants and parsimony, which is a penalisation of complexity).\\\n",
    "To see all the possible parameters, please see the `PySRRegressor` class from [PySR](https://ai.damtp.cam.ac.uk/pysr/api/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b47775",
   "metadata": {},
   "source": [
    "In this example, we turn verbosity off because we are in a Jupyter notebook. For best performance, run in IPython, as you can terminate the SR any time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d637d376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🛠️ Running SR on output dimension 0 of 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liz/PhD/SymTorch_project/symtorch_venv/lib/python3.11/site-packages/pysr/sr.py:2811: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💡Best equation for output 0 found to be ((sin(x4) * 3.1075206) + -4.0526915) + (x0 * (sin(x4 + 20.25151) * x0)).\n",
      "❤️ SR on Sequential complete.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: PySRRegressor.equations_ = [\n",
       " \t    pick         score                                           equation  \\\n",
       " \t0         0.000000e+00                                                 x4   \n",
       " \t1         2.589440e+00                                         -2.3372025   \n",
       " \t2         3.962054e-01                                    x4 + -2.8320389   \n",
       " \t3         4.909863e-01                             (x4 + -3.3268287) + x4   \n",
       " \t4         2.943301e-01                      (x4 * 2.5722113) + -3.6099672   \n",
       " \t5         7.500944e-01                       ((x0 + x4) + x4) + -3.824443   \n",
       " \t6         1.178268e+00                  ((x4 * 2.5593166) + -4.1012) + x0   \n",
       " \t7         1.394943e-01         (x4 * 2.557785) + ((x0 * x0) + -3.9332936)   \n",
       " \t8         2.682228e-01            ((sin(x4) * 2.9906468) + -4.19712) + x0   \n",
       " \t9         2.632322e-01   ((x0 * x0) + -4.0290413) + (sin(x4) * 2.9886153)   \n",
       " \t10        7.668198e-08  inv(inv(((x0 * x0) + -4.0290413) + (sin(x4) * ...   \n",
       " \t11        2.554324e-01  (sin(x0 * x0) + -4.0077133) + (sin(x4) * 2.991...   \n",
       " \t12        9.983039e-03  ((x0 * (sin(x0) + 0.037946302)) + (sin(x4) * 2...   \n",
       " \t13        1.519488e-01  ((x4 + sin(x0 * x0)) + -3.5611627) + sin(x4 + ...   \n",
       " \t14  >>>>  3.531477e-01  ((sin(x4) * 3.1075206) + -4.0526915) + (x0 * (...   \n",
       " \t15        7.956269e-02  sin(((x0 * x0) + -0.6257372) + x4) + (sin(x4 +...   \n",
       " \t16        3.471651e-03  (sin((x0 * x0) + (x4 + -0.61608624)) + (sin((x...   \n",
       " \t\n",
       " \t        loss  complexity  \n",
       " \t0   8.302468           1  \n",
       " \t1   0.623200           2  \n",
       " \t2   0.282155           4  \n",
       " \t3   0.105687           6  \n",
       " \t4   0.078740           7  \n",
       " \t5   0.037191           8  \n",
       " \t6   0.011448           9  \n",
       " \t7   0.008661          11  \n",
       " \t8   0.006623          12  \n",
       " \t9   0.003912          14  \n",
       " \t10  0.003912          16  \n",
       " \t11  0.003030          17  \n",
       " \t12  0.002941          20  \n",
       " \t13  0.002526          21  \n",
       " \t14  0.001775          22  \n",
       " \t15  0.001514          24  \n",
       " \t16  0.001498          27  \n",
       " ]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure the SR\n",
    "\n",
    "sr_params = {'complexity_of_operators':  {\"sin\":3, \"exp\":3},\n",
    "             'complexity_of_constants': 2, \n",
    "             'parsimony': 0.1,\n",
    "             'verbosity': 0,\n",
    "             'niterations': 500}\n",
    "\n",
    "model.mlp.interpret(torch.FloatTensor(X_train),\n",
    "                       sr_params = sr_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8275ed6e",
   "metadata": {},
   "source": [
    "See the full Pareto front of equations. The best equation is chosen as a balance of accuracy and complexity.\\\n",
    "Outputs from *PySR* are saved in `SR_output/MLP_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31109683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: PySRRegressor.equations_ = [\n",
      "\t    pick         score                                           equation  \\\n",
      "\t0         0.000000e+00                                                 x4   \n",
      "\t1         2.589440e+00                                         -2.3372025   \n",
      "\t2         3.962054e-01                                    x4 + -2.8320389   \n",
      "\t3         4.909863e-01                             (x4 + -3.3268287) + x4   \n",
      "\t4         2.943301e-01                      (x4 * 2.5722113) + -3.6099672   \n",
      "\t5         7.500944e-01                       ((x0 + x4) + x4) + -3.824443   \n",
      "\t6         1.178268e+00                  ((x4 * 2.5593166) + -4.1012) + x0   \n",
      "\t7         1.394943e-01         (x4 * 2.557785) + ((x0 * x0) + -3.9332936)   \n",
      "\t8         2.682228e-01            ((sin(x4) * 2.9906468) + -4.19712) + x0   \n",
      "\t9         2.632322e-01   ((x0 * x0) + -4.0290413) + (sin(x4) * 2.9886153)   \n",
      "\t10        7.668198e-08  inv(inv(((x0 * x0) + -4.0290413) + (sin(x4) * ...   \n",
      "\t11        2.554324e-01  (sin(x0 * x0) + -4.0077133) + (sin(x4) * 2.991...   \n",
      "\t12        9.983039e-03  ((x0 * (sin(x0) + 0.037946302)) + (sin(x4) * 2...   \n",
      "\t13        1.519488e-01  ((x4 + sin(x0 * x0)) + -3.5611627) + sin(x4 + ...   \n",
      "\t14  >>>>  3.531477e-01  ((sin(x4) * 3.1075206) + -4.0526915) + (x0 * (...   \n",
      "\t15        7.956269e-02  sin(((x0 * x0) + -0.6257372) + x4) + (sin(x4 +...   \n",
      "\t16        3.471651e-03  (sin((x0 * x0) + (x4 + -0.61608624)) + (sin((x...   \n",
      "\t\n",
      "\t        loss  complexity  \n",
      "\t0   8.302468           1  \n",
      "\t1   0.623200           2  \n",
      "\t2   0.282155           4  \n",
      "\t3   0.105687           6  \n",
      "\t4   0.078740           7  \n",
      "\t5   0.037191           8  \n",
      "\t6   0.011448           9  \n",
      "\t7   0.008661          11  \n",
      "\t8   0.006623          12  \n",
      "\t9   0.003912          14  \n",
      "\t10  0.003912          16  \n",
      "\t11  0.003030          17  \n",
      "\t12  0.002941          20  \n",
      "\t13  0.002526          21  \n",
      "\t14  0.001775          22  \n",
      "\t15  0.001514          24  \n",
      "\t16  0.001498          27  \n",
      "]}\n"
     ]
    }
   ],
   "source": [
    "print(model.mlp.pysr_regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db788500",
   "metadata": {},
   "source": [
    "## Switch to Using the Equation Instead in the Forwards Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dbf360",
   "metadata": {},
   "source": [
    "You can choose the equation you want to switch to by choosing the desired complexity of equation. \\\n",
    "If left blank, then we choose the best equation chosen by *PySR*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abef72c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully switched Sequential to symbolic equations for all 1 dimensions:\n",
      "   Dimension 0: ((x0 * x0) + -4.0290413) + (sin(x4) * 2.9886153)\n",
      "   Variables: ['x0', 'x4']\n",
      "🎯 All 1 output dimensions now using symbolic equations.\n"
     ]
    }
   ],
   "source": [
    "model.mlp.switch_to_equation(complexity=[14]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e7cfd0",
   "metadata": {},
   "source": [
    "Now when running the forwards pass through the model, it uses the symbolic equation instead of the MLP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e526154f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.4945],\n",
       "        [-2.7125],\n",
       "        [-2.9032],\n",
       "        ...,\n",
       "        [-2.5894],\n",
       "        [-3.7545],\n",
       "        [-2.1077]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpretable_outputs = model(torch.tensor(X_train, dtype=torch.float32))\n",
    "interpretable_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5835dd8e",
   "metadata": {},
   "source": [
    "## Switch to Using the MLP in the Forwards Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34291a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Switched Sequential back to MLP\n"
     ]
    }
   ],
   "source": [
    "mlp_outputs = model.mlp.switch_to_mlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79e43dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.4598],\n",
       "        [-2.7900],\n",
       "        [-2.8136],\n",
       "        ...,\n",
       "        [-2.6042],\n",
       "        [-3.6704],\n",
       "        [-2.0613]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    model_outputs = model.mlp(torch.tensor(X_train, dtype=torch.float32))\n",
    "model_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0c6c463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8000, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e258b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up \n",
    "import os\n",
    "import shutil\n",
    "if os.path.exists('SR_output'):\n",
    "    shutil.rmtree('SR_output')\n",
    "os.remove('model_weights.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "symtorch_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
