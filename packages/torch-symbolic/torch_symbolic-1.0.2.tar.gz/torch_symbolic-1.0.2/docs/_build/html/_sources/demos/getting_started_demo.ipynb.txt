{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f935234",
   "metadata": {},
   "source": [
    "# Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92f4a7a",
   "metadata": {},
   "source": [
    "## Wrapping a PyTorch model\n",
    "Create a simple PyTorch model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adc61e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple MLP.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple model class.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim = 64):\n",
    "        super(SimpleModel, self).__init__()\n",
    "\n",
    "        self.mlp = MLP(input_dim, output_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mlp(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6941215c",
   "metadata": {},
   "source": [
    "Train the model on some data.\n",
    "\n",
    "$$\n",
    "y = x_0^2 +3 \\sin(x_4)-4\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f363579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the dataset \n",
    "x = np.array([np.random.uniform(0, 1, 10_000) for _ in range(5)]).T  \n",
    "y = x[:, 0]**2 + 3*np.sin(x[:, 4]) - 4\n",
    "noise = np.array([np.random.normal(0, 0.05*np.std(y)) for _ in range(len(y))])\n",
    "y = y + noise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fcf89e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up training\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_model(model, dataloader, opt, criterion, epochs = 100):\n",
    "    \"\"\"\n",
    "    Train a model for the specified number of epochs.\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model to train\n",
    "        dataloader: DataLoader for training data\n",
    "        opt: Optimizer\n",
    "        criterion: Loss function\n",
    "        epochs: Number of training epochs\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (trained_model, loss_tracker)\n",
    "    \"\"\"\n",
    "    loss_tracker = []\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        \n",
    "        for batch_x, batch_y in dataloader:\n",
    "            # Forward pass\n",
    "            pred = model(batch_x)\n",
    "            loss = criterion(pred, batch_y)\n",
    "            \n",
    "            # Backward pass\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        loss_tracker.append(epoch_loss)\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            avg_loss = epoch_loss / len(dataloader)\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Avg Loss: {avg_loss:.6f}')\n",
    "    return model, loss_tracker\n",
    "\n",
    "# Instantiate the model\n",
    "model = SimpleModel(input_dim=x.shape[1], output_dim=1)\n",
    "\n",
    "# Set up training\n",
    "criterion = nn.MSELoss()\n",
    "opt = optim.Adam(model.parameters(), lr=0.001)\n",
    "X_train, _, y_train, _ = train_test_split(x, y.reshape(-1,1), test_size=0.2, random_state=290402)\n",
    "\n",
    "# Set up dataset\n",
    "dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "add838bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Avg Loss: 0.094613\n",
      "Epoch [10/20], Avg Loss: 0.063776\n",
      "Epoch [15/20], Avg Loss: 0.048936\n",
      "Epoch [20/20], Avg Loss: 0.040046\n"
     ]
    }
   ],
   "source": [
    "# Train the model and save the weights\n",
    "\n",
    "model, losses = train_model(model, dataloader, opt, criterion, 20)\n",
    "torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb22ef1",
   "metadata": {},
   "source": [
    "Wrap the mlp layer in the trained model with MLP_SR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77bc4f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liz/PhD/InterpretSR_project/interpretsr_venv/lib/python3.11/site-packages/juliacall/__init__.py:61: UserWarning: torch was imported before juliacall. This may cause a segfault. To avoid this, import juliacall before importing torch. For updates, see https://github.com/pytorch/pytorch/issues/78829.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected IPython. Loading juliacall extension. See https://juliapy.github.io/PythonCall.jl/stable/compat/#IPython\n"
     ]
    }
   ],
   "source": [
    "from symtorch.mlp_sr import MLP_SR\n",
    "model.mlp = MLP_SR(model.mlp, mlp_name = 'Sequential')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1db5df8",
   "metadata": {},
   "source": [
    "## Interpret the MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca15a8d3",
   "metadata": {},
   "source": [
    "In this example, we pass extra parameters into the `.interpret` method (complexity of operators/constants and parsimony, which is a penalisation of complexity).\\\n",
    "To see all the possible parameters, please see the `PySRRegressor` class from [PySR](https://ai.damtp.cam.ac.uk/pysr/api/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b47775",
   "metadata": {},
   "source": [
    "In this example, we turn verbosity off because we are in a Jupyter notebook. For best performance, run in IPython, as you can terminate the SR any time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d637d376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🛠️ Running SR on output dimension 0 of 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liz/PhD/InterpretSR_project/interpretsr_venv/lib/python3.11/site-packages/pysr/sr.py:2811: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💡Best equation for output 0 found to be ((x0 * x0) + -3.918567) + (sin(x4) * 2.8742185).\n",
      "❤️ SR on Sequential complete.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: PySRRegressor.equations_ = [\n",
       " \t    pick         score                                           equation  \\\n",
       " \t0         0.000000e+00                                                 x4   \n",
       " \t1         2.596927e+00                                         -2.2726457   \n",
       " \t2         4.073414e-01                                    x4 + -2.7684813   \n",
       " \t3         4.770055e-01                             (x4 + x4) + -3.2644153   \n",
       " \t4         1.900821e-01                      (x4 + -1.4215928) * 2.4550738   \n",
       " \t5         1.122596e+00                       ((x0 + x4) + -3.766932) + x4   \n",
       " \t6         1.062448e+00                (x4 * 2.459092) + (x0 + -3.9945967)   \n",
       " \t7         2.566310e-01        ((x4 * 2.4604707) + (x0 * x0)) + -3.8280373   \n",
       " \t8         4.459062e-08  ((x0 * x0) + (x4 + -3.828038)) + (x4 * 1.4604728)   \n",
       " \t9   >>>>  1.072845e+00    ((x0 * x0) + -3.918567) + (sin(x4) * 2.8742185)   \n",
       " \t10        5.908252e-02  ((x0 * (x0 * 0.9405975)) + -3.8984792) + (sin(...   \n",
       " \t11        1.201339e-02  ((sin(x4) * 2.8734725) + -3.9172218) + (((x0 *...   \n",
       " \t12        2.686410e-03  ((((x2 * 0.051761005) + x0) * x0) * 0.9188136)...   \n",
       " \t13        2.204982e-02  ((sin(x4) * 2.9311705) + (x0 * (x0 + (x4 * ((x...   \n",
       " \t14        9.261696e-02  (sin(x4) * 2.848834) + ((x0 * (x0 * sin((x4 + ...   \n",
       " \t15        5.744458e-03  (x0 * ((x0 + -0.017147552) * sin((x0 + x4) + 0...   \n",
       " \t16        6.804990e-03  (sin(x4) * 2.9278073) + ((((((x4 * (x4 * x4)) ...   \n",
       " \t\n",
       " \t        loss  complexity  \n",
       " \t0   7.926341           1  \n",
       " \t1   0.590529           2  \n",
       " \t2   0.261474           4  \n",
       " \t3   0.100718           6  \n",
       " \t4   0.083283           7  \n",
       " \t5   0.027103           8  \n",
       " \t6   0.009367           9  \n",
       " \t7   0.005607          11  \n",
       " \t8   0.005607          13  \n",
       " \t9   0.001918          14  \n",
       " \t10  0.001606          17  \n",
       " \t11  0.001549          20  \n",
       " \t12  0.001541          22  \n",
       " \t13  0.001507          23  \n",
       " \t14  0.001374          24  \n",
       " \t15  0.001351          27  \n",
       " \t16  0.001332          29  \n",
       " ]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.mlp.interpret(torch.FloatTensor(X_train), \n",
    "                       niterations = 500, # Should set to higher\n",
    "                       verbosity=0, \n",
    "                       complexity_of_operators = {\"sin\":3, \"exp\":3}, \n",
    "                       complexity_of_constants = 2,\n",
    "                       parsimony = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8275ed6e",
   "metadata": {},
   "source": [
    "See the full Pareto front of equations. The best equation is chosen as a balance of accuracy and complexity.\\\n",
    "Outputs from *PySR* are saved in `SR_output/MLP_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31109683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: PySRRegressor.equations_ = [\n",
      "\t    pick         score                                           equation  \\\n",
      "\t0         0.000000e+00                                                 x4   \n",
      "\t1         2.596927e+00                                         -2.2726457   \n",
      "\t2         4.073414e-01                                    x4 + -2.7684813   \n",
      "\t3         4.770055e-01                             (x4 + x4) + -3.2644153   \n",
      "\t4         1.900821e-01                      (x4 + -1.4215928) * 2.4550738   \n",
      "\t5         1.122596e+00                       ((x0 + x4) + -3.766932) + x4   \n",
      "\t6         1.062448e+00                (x4 * 2.459092) + (x0 + -3.9945967)   \n",
      "\t7         2.566310e-01        ((x4 * 2.4604707) + (x0 * x0)) + -3.8280373   \n",
      "\t8         4.459062e-08  ((x0 * x0) + (x4 + -3.828038)) + (x4 * 1.4604728)   \n",
      "\t9   >>>>  1.072845e+00    ((x0 * x0) + -3.918567) + (sin(x4) * 2.8742185)   \n",
      "\t10        5.908252e-02  ((x0 * (x0 * 0.9405975)) + -3.8984792) + (sin(...   \n",
      "\t11        1.201339e-02  ((sin(x4) * 2.8734725) + -3.9172218) + (((x0 *...   \n",
      "\t12        2.686410e-03  ((((x2 * 0.051761005) + x0) * x0) * 0.9188136)...   \n",
      "\t13        2.204982e-02  ((sin(x4) * 2.9311705) + (x0 * (x0 + (x4 * ((x...   \n",
      "\t14        9.261696e-02  (sin(x4) * 2.848834) + ((x0 * (x0 * sin((x4 + ...   \n",
      "\t15        5.744458e-03  (x0 * ((x0 + -0.017147552) * sin((x0 + x4) + 0...   \n",
      "\t16        6.804990e-03  (sin(x4) * 2.9278073) + ((((((x4 * (x4 * x4)) ...   \n",
      "\t\n",
      "\t        loss  complexity  \n",
      "\t0   7.926341           1  \n",
      "\t1   0.590529           2  \n",
      "\t2   0.261474           4  \n",
      "\t3   0.100718           6  \n",
      "\t4   0.083283           7  \n",
      "\t5   0.027103           8  \n",
      "\t6   0.009367           9  \n",
      "\t7   0.005607          11  \n",
      "\t8   0.005607          13  \n",
      "\t9   0.001918          14  \n",
      "\t10  0.001606          17  \n",
      "\t11  0.001549          20  \n",
      "\t12  0.001541          22  \n",
      "\t13  0.001507          23  \n",
      "\t14  0.001374          24  \n",
      "\t15  0.001351          27  \n",
      "\t16  0.001332          29  \n",
      "]}\n"
     ]
    }
   ],
   "source": [
    "print(model.mlp.pysr_regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db788500",
   "metadata": {},
   "source": [
    "## Switch to Using the Equation Instead in the Forwards Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dbf360",
   "metadata": {},
   "source": [
    "You can choose the equation you want to switch to by choosing the desired complexity of equation. \\\n",
    "If left blank, then we choose the best equation chosen by *PySR*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abef72c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully switched Sequential to symbolic equations for all 1 dimensions:\n",
      "   Dimension 0: ((x0 * x0) + -3.918567) + (sin(x4) * 2.8742185)\n",
      "   Variables: ['x0', 'x4']\n",
      "🎯 All 1 output dimensions now using symbolic equations.\n"
     ]
    }
   ],
   "source": [
    "model.mlp.switch_to_equation(complexity=[14]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e7cfd0",
   "metadata": {},
   "source": [
    "Now when running the forwards pass through the model, it uses the symbolic equation instead of the MLP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e526154f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.7752],\n",
       "        [-2.6276],\n",
       "        [-3.6235],\n",
       "        ...,\n",
       "        [-1.2497],\n",
       "        [-1.9447],\n",
       "        [-3.7815]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpretable_outputs = model(torch.tensor(X_train, dtype=torch.float32))\n",
    "interpretable_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5835dd8e",
   "metadata": {},
   "source": [
    "## Switch to Using the MLP in the Forwards Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34291a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Switched Sequential back to MLP\n"
     ]
    }
   ],
   "source": [
    "mlp_outputs = model.mlp.switch_to_mlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79e43dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.8287],\n",
       "        [-2.6227],\n",
       "        [-3.5882],\n",
       "        ...,\n",
       "        [-1.2214],\n",
       "        [-1.9201],\n",
       "        [-3.7148]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    model_outputs = model.mlp(torch.tensor(X_train, dtype=torch.float32))\n",
    "model_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0c6c463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8000, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e258b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up \n",
    "import os\n",
    "import shutil\n",
    "if os.path.exists('SR_output'):\n",
    "    shutil.rmtree('SR_output')\n",
    "os.remove('model_weights.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interpretsr_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
