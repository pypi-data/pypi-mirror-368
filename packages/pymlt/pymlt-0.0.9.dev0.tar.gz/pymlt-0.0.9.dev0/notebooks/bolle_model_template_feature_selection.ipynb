{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection\n",
    "Although this approach to select features is really handy without much knowledge of the underlying data we should keep in mind that business knowledge should be incorporated in this phase as well. Furthermore this step takes a long time for small to medium sized datasets -> ergo: this is not scalabe. Possible solutions:\n",
    "- increase step_size of the RFECV functions\n",
    "- decrease the number of estimators in the RFECV functions\n",
    "- use a subset of the original dataset\n",
    "- ..\n",
    "\n",
    "The goal behind this approach is to keep the best features, since we are combining the different lists and possibly adding features besides these approaches we might be better off keeping a high over indicator of the most relevant features.\n",
    "\n",
    "To formally check the difference we make use of the timeit module: https://www.pythoncentral.io/time-a-python-function/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import src.features.feature_selection as feat_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path_cleaned = os.path.join(\"..\", \"data\", \"train_set_cleaned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    train_path_cleaned, sep=\";\", decimal=\".\", low_memory=False, compression=\"zip\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int64      308\n",
       "float64      3\n",
       "object       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fix objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>klant_min_begindatum_dat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-10-31 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001-10-31 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-04-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1992-12-31 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-06-14 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  klant_min_begindatum_dat\n",
       "0      2013-10-31 00:00:00\n",
       "1      2001-10-31 00:00:00\n",
       "2      2004-04-01 00:00:00\n",
       "3      1992-12-31 00:00:00\n",
       "4      2016-06-14 00:00:00"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select_dtypes(include=\"object\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"klant_min_begindatum_dat\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection\n",
    "\n",
    "n_features_rf, xgb, and logreg all use Recursive Feature Elimination and cross-validation:\n",
    "\n",
    "\"Given an external estimator that assigns weights to features (e.g., the coefficients of a linear model), recursive feature elimination (RFE) is to select features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features and the importance of each feature is obtained either through a coef_ attribute or through a feature_importances_ attribute. Then, the least important features are pruned from current set of features.That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached.\"\n",
    "- use the different feat select methods\n",
    "- combine the output\n",
    "- add business sense\n",
    "\n",
    "Notes:\n",
    "- The initial accuracy is quite high (88%), are there still near perfect predictors in the set?\n",
    "\n",
    "Notes on improved efficiency:\n",
    "- n_features_rf with cpus=4, max_depth=10, n_estimators=100,  and step_size=5: 17.44 min, feat=65, max_acc=88%\n",
    "- n_features_rf with cpus=4, max_depth=10, n_estimators=100, and step_size=10: 6.9 min., feat=70, max_acc=87%\n",
    "- n_features_rf with cpus=4, max_depth=10, n_estimators=50,  and step_size=10: 3.5 min., feat=70, max_acc=87.9%\n",
    "\n",
    "Code to measure improved efficiency:\n",
    "```python\n",
    "import timeit\n",
    "\n",
    "# Create a wrapper(decorator) to include arguments \n",
    "def wrapper(func, *args, **kwargs):\n",
    "    def wrapped():\n",
    "        return func(*args, **kwargs)\n",
    "    return wrapped\n",
    "\n",
    "wrapped = wrapper(feat_select.n_features_rf, x_train=X, y_train=y, cpus=4)\n",
    "\n",
    "timeit.timeit(wrapped, number=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"toon_churn\"]\n",
    "X = df.drop([\"toon_churn\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changed step_size to 10 for all RFECV feature selection functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest: The optimal number of features is 70 with a maximum accuracy\n",
      "of 87.9%. Please keep in mind that the stepsize is 10.\n"
     ]
    }
   ],
   "source": [
    "rf_list = feat_select.n_features_rf(X, y, cpus=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGboost: The optimal number of features is 30 with a maximum accuracy\n",
      "of 85.8%. Please keep in mind that the stepsize is 10.\n"
     ]
    }
   ],
   "source": [
    "xgb_list = feat_select.n_features_xgb(X, y, cpus=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log. regression: The optimal number of features is 280 with a maximum accuracy\n",
      "of 87.5%. Please keep in mind that the stepsize is 5.\n"
     ]
    }
   ],
   "source": [
    "logreg_list = feat_select.n_features_logreg(X, y, cpus=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boruta: The optimal number of features is 160\n"
     ]
    }
   ],
   "source": [
    "boruta_list = feat_select.n_features_boruta(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine lists and continue\n",
    "- Abstract the code, notify that files are being written to local folders, catch the error via Exception\n",
    "- Or add your destination folder given your current folder\n",
    "- add os.path.join, os.scandir, os.mkdir\n",
    "- Assume you are working with the modeling template + jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The list with 4 vote(s) contains 27 variables and can be found in ..\\feature_lists\\combined_list_4_votes\n",
      "The list with 3 vote(s) contains 71 variables and can be found in ..\\feature_lists\\combined_list_3_votes\n",
      "The list with 2 vote(s) contains 146 variables and can be found in ..\\feature_lists\\combined_list_2_votes\n",
      "The list with 1 vote(s) contains 296 variables and can be found in ..\\feature_lists\\combined_list_1_votes\n"
     ]
    }
   ],
   "source": [
    "extensive_list = feat_select.create_feature_lists(\n",
    "    \"toon_churn\", rf_list, xgb_list, logreg_list, boruta_list\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export dataset for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path_processed = os.path.join(\"..\", \"data\", \"train_set_processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[extensive_list].to_csv(\n",
    "    train_path_processed, sep=\";\", encoding=\"utf-8\", index=False, compression=\"zip\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
