{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple example where we use ginjax to learn scalar filters. We start by specifying what GPUs to use, and importing packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=3\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=3\n",
    "\n",
    "import time\n",
    "import optax\n",
    "from typing_extensions import Optional, Self\n",
    "\n",
    "import jax\n",
    "from jax import random\n",
    "from jaxtyping import ArrayLike\n",
    "import equinox as eqx\n",
    "\n",
    "import ginjax.geometric as geom\n",
    "import ginjax.ml as ml\n",
    "import ginjax.models as models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets define our images X and what filters we are going to use. Our image will be 2D, 64 x 64 scalar images. Our filters will be 3x3 and they will be the invariant scalar filters only. There are 3 of these, and the first one is the identity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = random.PRNGKey(time.time_ns())\n",
    "\n",
    "D = 2\n",
    "N = 64  # image size\n",
    "M = 3  # filter image size\n",
    "num_images = 10\n",
    "\n",
    "group_actions = geom.make_all_operators(D)\n",
    "conv_filters = geom.get_invariant_filters(\n",
    "    Ms=[M], ks=[0], parities=[0], D=D, operators=group_actions\n",
    ")\n",
    "\n",
    "key, subkey = random.split(key)\n",
    "multi_image_X = geom.MultiImage(\n",
    "    {(0, 0): random.normal(subkey, shape=(num_images, 1) + (N,) * D)}, D\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us define our target function, and then construct our target images Y. The target function will merely be convolving by the filter at index 1, then convolving by the filter at index 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_function(\n",
    "    multi_image: geom.MultiImage, conv_filter_a: jax.Array, conv_filter_b: jax.Array\n",
    ") -> geom.MultiImage:\n",
    "    convolved_data = geom.convolve(\n",
    "        multi_image.D,\n",
    "        geom.convolve(\n",
    "            multi_image.D, multi_image[((), 0)], conv_filter_a[None, None], multi_image.is_torus\n",
    "        ),\n",
    "        conv_filter_b[None, None],\n",
    "        multi_image.is_torus,\n",
    "    )\n",
    "    return geom.MultiImage({(0, 0): convolved_data}, multi_image.D, multi_image.is_torus)\n",
    "\n",
    "multi_image_y = target_function(multi_image_X, conv_filters[((), 0)][1], conv_filters[((), 0)][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to define our network and loss function. Machine learning on the GeometricImageNet is done on the MultiImage object, which is a way of collecting batches of multiple channels of images at possible different tensor orders in a single object.\n",
    "\n",
    "For this toy example, we will make our task straightforward by making our network a linear combination of all the pairs of convolving by one filter from our set of three, then another filter from our set of three with replacement. In this fashion, our target function will be the 5th of 6 images. Our loss is simply the root mean square error loss (RMSE). The ml.train function expects a map_and_loss function that operates on MultiImages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(models.MultiImageModule):\n",
    "    D: int\n",
    "    net: list[ml.ConvContract]\n",
    "\n",
    "    def __init__(\n",
    "        self: Self,\n",
    "        D: int,\n",
    "        input_keys: geom.Signature,\n",
    "        output_keys: geom.Signature,\n",
    "        conv_filters: geom.MultiImage,\n",
    "        key: ArrayLike,\n",
    "    ):\n",
    "        self.D = D\n",
    "        key, subkey1, subkey2 = random.split(key, num=3)\n",
    "        self.net = [\n",
    "            ml.ConvContract(input_keys, output_keys, conv_filters, False, key=subkey1),\n",
    "            ml.ConvContract(output_keys, output_keys, conv_filters, False, key=subkey2),\n",
    "        ]\n",
    "\n",
    "    def __call__(\n",
    "        self: Self, x: geom.MultiImage, aux_data: Optional[eqx.nn.State] = None\n",
    "    ) -> tuple[geom.MultiImage, Optional[eqx.nn.State]]:\n",
    "        for layer in self.net:\n",
    "            x = layer(x)\n",
    "\n",
    "        return x, aux_data\n",
    "\n",
    "\n",
    "def map_and_loss(\n",
    "    model: models.MultiImageModule,\n",
    "    multi_image_x: geom.MultiImage,\n",
    "    multi_image_y: geom.MultiImage,\n",
    "    aux_data: Optional[eqx.nn.State] = None,\n",
    ") -> tuple[jax.Array, Optional[eqx.nn.State]]:\n",
    "    pred_y, aux_data = jax.vmap(model, in_axes=(0,None), out_axes=(0,None))(multi_image_x, aux_data)\n",
    "    return ml.smse_loss(multi_image_y, pred_y), aux_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will train our model using the `train` function from `ml.py`. Train takes the input data as a MultiImage, the target data as a MultiImage, a map and loss function that takes arguments (model, x, y, aux_data), the model, a random key for doing the batches, the number of epochs to run, the batch size, and the desired optax optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 Train: 0.1476211 Epoch time: 0.01771\n",
      "Epoch 100 Train: 0.0060808 Epoch time: 0.02097\n",
      "Epoch 150 Train: 0.0001239 Epoch time: 0.01527\n",
      "Epoch 200 Train: 0.0000097 Epoch time: 0.01195\n",
      "Epoch 250 Train: 0.0000021 Epoch time: 0.01348\n",
      "Epoch 300 Train: 0.0000008 Epoch time: 0.01915\n",
      "Epoch 350 Train: 0.0000004 Epoch time: 0.01971\n",
      "Epoch 400 Train: 0.0000003 Epoch time: 0.01432\n",
      "Epoch 450 Train: 0.0000002 Epoch time: 0.01266\n",
      "Epoch 500 Train: 0.0000002 Epoch time: 0.01407\n",
      "{((), 0): {((), 0): Array([[[4.1636670e-04, 1.3408582e-05, 1.1102087e+00]]], dtype=float32)}}\n",
      "{((), 0): {((), 0): Array([[[-2.3628289e-05,  9.0061241e-01, -6.9961043e-06]]], dtype=float32)}}\n"
     ]
    }
   ],
   "source": [
    "key, subkey = random.split(key)\n",
    "model = SimpleModel(\n",
    "    D, multi_image_X.get_signature(), multi_image_y.get_signature(), conv_filters, subkey\n",
    ")\n",
    "\n",
    "key, subkey = random.split(key)\n",
    "trained_model, _, _, _ = ml.train(\n",
    "    multi_image_X,\n",
    "    multi_image_y,\n",
    "    map_and_loss,\n",
    "    model,\n",
    "    subkey,\n",
    "    ml.EpochStop(500, verbose=1),\n",
    "    num_images,\n",
    "    optimizer=optax.adam(optax.exponential_decay(0.1, transition_steps=1, decay_rate=0.99)),\n",
    ")\n",
    "assert isinstance(trained_model, SimpleModel)\n",
    "\n",
    "print(trained_model.net[0].weights)\n",
    "print(trained_model.net[1].weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that two are the filters have weight very close to 1, and the rest are close to 0. Hooray!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gi_net",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
