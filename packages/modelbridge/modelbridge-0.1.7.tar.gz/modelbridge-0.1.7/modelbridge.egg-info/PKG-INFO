Metadata-Version: 2.4
Name: modelbridge
Version: 0.1.7
Summary: Simple Multi-Provider LLM Gateway
Home-page: https://github.com/code-mohanprakash/modelbridge
Author: Mohan Prakash
Author-email: Mohan Prakash <mohanprkash462@gmail.com>
License: MIT
Project-URL: Homepage, https://github.com/code-mohanprakash/modelbridge
Project-URL: Repository, https://github.com/code-mohanprakash/modelbridge
Project-URL: Issues, https://github.com/code-mohanprakash/modelbridge/issues
Keywords: llm,ai,gateway,routing,openai,anthropic,google,groq,multi-provider,load-balancing
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: aiohttp>=3.8.0
Requires-Dist: pydantic>=2.0.0
Requires-Dist: openai>=1.0.0
Requires-Dist: anthropic>=0.5.0
Requires-Dist: google-generativeai>=0.3.0
Requires-Dist: groq>=0.4.0
Requires-Dist: PyYAML>=6.0
Requires-Dist: python-dotenv>=1.0.0
Requires-Dist: typing-extensions>=4.5.0
Requires-Dist: psutil>=5.9.0
Requires-Dist: redis>=4.5.0
Requires-Dist: tenacity>=8.0.0
Requires-Dist: langchain-google-genai>=0.1.0
Requires-Dist: langchain-core>=0.1.0
Provides-Extra: dev
Requires-Dist: pytest>=7.0.0; extra == "dev"
Requires-Dist: pytest-asyncio>=0.21.0; extra == "dev"
Requires-Dist: pytest-cov>=4.0.0; extra == "dev"
Requires-Dist: black>=23.0.0; extra == "dev"
Requires-Dist: isort>=5.12.0; extra == "dev"
Requires-Dist: flake8>=6.0.0; extra == "dev"
Requires-Dist: mypy>=1.0.0; extra == "dev"
Provides-Extra: ml
Requires-Dist: scikit-learn>=1.3.0; extra == "ml"
Requires-Dist: numpy>=1.24.0; extra == "ml"
Requires-Dist: pandas>=2.0.0; extra == "ml"
Dynamic: author
Dynamic: home-page
Dynamic: license-file
Dynamic: requires-python

# ModelBridge

[![PyPI version](https://badge.fury.io/py/modelbridge.svg)](https://badge.fury.io/py/modelbridge)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)

**Simple Multi-Provider LLM Gateway**

ModelBridge is a Python library that provides unified access to multiple AI providers. It simplifies working with OpenAI, Anthropic, Google, and Groq APIs through a single interface.

## âœ¨ What it Does

- **Multi-Provider Support**: Works with OpenAI, Groq, Google, and Anthropic
- **Smart Model Selection**: Automatically picks models based on your task
- **Cost Tracking**: Shows you how much each request costs
- **Simple API**: One function (`ask`) for most use cases
- **Environment Variables**: Secure API key management

## ðŸš€ Quick Start

### Installation

```bash
pip install modelbridge
```

### Basic Usage

```python
import asyncio
from modelbridge.simple import ask

# Set your API keys as environment variables:
# export OPENAI_API_KEY='your_openai_key'
# export GROQ_API_KEY='your_groq_key'

async def main():
    response = await ask("What is the capital of France?")
    print(f"Answer: {response.content}")
    print(f"Model: {response.model_id}")
    print(f"Provider: {response.provider_name}")
    print(f"Cost: ${response.cost:.4f}")

asyncio.run(main())
```

### Advanced Usage

```python
# Specify a particular model
response = await ask("Write Python code", model="gpt-4")

# Optimize for speed, cost, or quality
response = await ask("Simple math", optimize_for="cost")
response = await ask("Complex analysis", optimize_for="quality")

# Set maximum cost limit
response = await ask("Quick question", max_cost=0.001)

# Other useful functions
from modelbridge.simple import code, translate, summarize

# Generate code
response = await code("Create a sorting function", language="python")

# Translate text
response = await translate("Hello world", "Spanish")

# Summarize text
response = await summarize("Long article text here...", length="short")
```

## Configuration

### API Keys

Set your API keys as environment variables:

```bash
# Add the providers you want to use
export OPENAI_API_KEY='sk-your-openai-key'
export GROQ_API_KEY='gsk_your-groq-key'
export GOOGLE_API_KEY='your-google-key'
export ANTHROPIC_API_KEY='sk-ant-your-anthropic-key'
```

You need at least one API key for ModelBridge to work.

## Supported Providers

- **OpenAI**: GPT-4, GPT-3.5-turbo, GPT-5-mini
- **Groq**: Llama 3.3 (very fast)
- **Google**: Gemini models
- **Anthropic**: Claude models

## How It Works

1. You call `ask("your question")`
2. ModelBridge analyzes your prompt
3. It picks the best model for the task
4. Returns response with cost tracking
5. Automatically handles errors and retries

## License

MIT License

---

**Simple AI provider integration.**
