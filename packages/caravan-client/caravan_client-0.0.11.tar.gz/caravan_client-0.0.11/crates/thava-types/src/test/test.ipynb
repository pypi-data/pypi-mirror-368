{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying group access...\n",
      "Setting up a new caravan of GPU(s)...\n",
      "Received a caravan of GPU(s)!\n",
      "Connecting to each GPU in your caravan...\n",
      "Connected to each GPU in your caravan!\n",
      "Built Caravan!\n"
     ]
    }
   ],
   "source": [
    "from caravan import Caravan\n",
    "caravan = Caravan()\n",
    "caravan.group(\"speech\").email(\"prabhune@berkeley.edu\").key(\"BYxUTe7n\").gpu_count(1).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.transformer.Transformer"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prabhune/thava/client/.venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = torch.nn.Transformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 32, 512])\n",
      "torch.Size([10, 32, 512])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeCheckError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thava/client/src/rtorch/rtorch/biject.py:273\u001b[39m, in \u001b[36mtypecheck_arguments\u001b[39m\u001b[34m(signature, bound_arguments)\u001b[39m\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m273\u001b[39m     \u001b[43mcheck_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproposed_argument\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margument_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m TypeCheckError:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thava/client/.venv/lib/python3.11/site-packages/typeguard/_functions.py:106\u001b[39m, in \u001b[36mcheck_type\u001b[39m\u001b[34m(value, expected_type, forward_ref_policy, typecheck_fail_callback, collection_check_strategy)\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     \u001b[43mcheck_type_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpected_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m TypeCheckError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thava/client/.venv/lib/python3.11/site-packages/typeguard/_checkers.py:946\u001b[39m, in \u001b[36mcheck_type_internal\u001b[39m\u001b[34m(value, annotation, memo)\u001b[39m\n\u001b[32m    945\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, origin_type):\n\u001b[32m--> \u001b[39m\u001b[32m946\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m TypeCheckError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mis not an instance of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mqualified_name(origin_type)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    947\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(origin_type) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mstr\u001b[39m:  \u001b[38;5;66;03m# noqa: E721\u001b[39;00m\n",
      "\u001b[31mTypeCheckError\u001b[39m: torch.storage.UntypedStorage is not an instance of inspect._empty",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m y = torch.randn(\u001b[32m10\u001b[39m, \u001b[32m32\u001b[39m, \u001b[32m512\u001b[39m).to(\u001b[32m0\u001b[39m)  \u001b[38;5;66;03m# (sequence_length, batch_size, embedding_dim)\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(y.shape)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m output = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(output.shape)  \u001b[38;5;66;03m# (sequence_length, batch_size, embedding_dim)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thava/client/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thava/client/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thava/client/.venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py:278\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, src, tgt, src_mask, tgt_mask, memory_mask, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask, src_is_causal, tgt_is_causal, memory_is_causal)\u001b[39m\n\u001b[32m    268\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    269\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mthe feature number of src and tgt must be equal to d_model\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    270\u001b[39m     )\n\u001b[32m    272\u001b[39m memory = \u001b[38;5;28mself\u001b[39m.encoder(\n\u001b[32m    273\u001b[39m     src,\n\u001b[32m    274\u001b[39m     mask=src_mask,\n\u001b[32m    275\u001b[39m     src_key_padding_mask=src_key_padding_mask,\n\u001b[32m    276\u001b[39m     is_causal=src_is_causal,\n\u001b[32m    277\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m278\u001b[39m output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtgt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmemory_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtgt_is_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtgt_is_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_is_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmemory_is_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thava/client/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thava/client/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thava/client/.venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py:602\u001b[39m, in \u001b[36mTransformerDecoder.forward\u001b[39m\u001b[34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[39m\n\u001b[32m    599\u001b[39m tgt_is_causal = _detect_is_causal_mask(tgt_mask, tgt_is_causal, seq_len)\n\u001b[32m    601\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers:\n\u001b[32m--> \u001b[39m\u001b[32m602\u001b[39m     output = \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    603\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    604\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    606\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmemory_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmemory_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    608\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    609\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtgt_is_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtgt_is_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    610\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmemory_is_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmemory_is_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    611\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    613\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.norm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    614\u001b[39m     output = \u001b[38;5;28mself\u001b[39m.norm(output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thava/client/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thava/client/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thava/client/.venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py:1091\u001b[39m, in \u001b[36mTransformerDecoderLayer.forward\u001b[39m\u001b[34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[39m\n\u001b[32m   1085\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1086\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.norm1(\n\u001b[32m   1087\u001b[39m         x + \u001b[38;5;28mself\u001b[39m._sa_block(x, tgt_mask, tgt_key_padding_mask, tgt_is_causal)\n\u001b[32m   1088\u001b[39m     )\n\u001b[32m   1089\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.norm2(\n\u001b[32m   1090\u001b[39m         x\n\u001b[32m-> \u001b[39m\u001b[32m1091\u001b[39m         + \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mha_block\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1092\u001b[39m \u001b[43m            \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_is_causal\u001b[49m\n\u001b[32m   1093\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1094\u001b[39m     )\n\u001b[32m   1095\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.norm3(x + \u001b[38;5;28mself\u001b[39m._ff_block(x))\n\u001b[32m   1097\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thava/client/.venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py:1127\u001b[39m, in \u001b[36mTransformerDecoderLayer._mha_block\u001b[39m\u001b[34m(self, x, mem, attn_mask, key_padding_mask, is_causal)\u001b[39m\n\u001b[32m   1119\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_mha_block\u001b[39m(\n\u001b[32m   1120\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1121\u001b[39m     x: Tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1125\u001b[39m     is_causal: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1126\u001b[39m ) -> Tensor:\n\u001b[32m-> \u001b[39m\u001b[32m1127\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmultihead_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1128\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1129\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1130\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1131\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1132\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1133\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1134\u001b[39m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1135\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m   1136\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dropout2(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thava/client/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thava/client/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thava/client/.venv/lib/python3.11/site-packages/torch/nn/modules/activation.py:1368\u001b[39m, in \u001b[36mMultiheadAttention.forward\u001b[39m\u001b[34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[39m\n\u001b[32m   1342\u001b[39m     attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001b[32m   1343\u001b[39m         query,\n\u001b[32m   1344\u001b[39m         key,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1365\u001b[39m         is_causal=is_causal,\n\u001b[32m   1366\u001b[39m     )\n\u001b[32m   1367\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1368\u001b[39m     attn_output, attn_output_weights = \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1369\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1370\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1371\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1372\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1374\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1375\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1376\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1378\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1379\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1380\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mout_proj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1381\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mout_proj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1382\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1383\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1384\u001b[39m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1385\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1386\u001b[39m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1387\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1388\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1389\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.batch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[32m   1390\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output.transpose(\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m), attn_output_weights\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thava/client/.venv/lib/python3.11/site-packages/torch/nn/functional.py:5984\u001b[39m, in \u001b[36mmulti_head_attention_forward\u001b[39m\u001b[34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[39m\n\u001b[32m   5972\u001b[39m tens_ops = (\n\u001b[32m   5973\u001b[39m     query,\n\u001b[32m   5974\u001b[39m     key,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5981\u001b[39m     out_proj_bias,\n\u001b[32m   5982\u001b[39m )\n\u001b[32m   5983\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tens_ops):\n\u001b[32m-> \u001b[39m\u001b[32m5984\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandle_torch_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5985\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5986\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtens_ops\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5987\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5988\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5989\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5990\u001b[39m \u001b[43m        \u001b[49m\u001b[43membed_dim_to_check\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5991\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5992\u001b[39m \u001b[43m        \u001b[49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5993\u001b[39m \u001b[43m        \u001b[49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5994\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5995\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5996\u001b[39m \u001b[43m        \u001b[49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5997\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5998\u001b[39m \u001b[43m        \u001b[49m\u001b[43mout_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mout_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   6000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   6001\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   6002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   6003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   6004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   6005\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_separate_proj_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_separate_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   6006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mq_proj_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mq_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   6007\u001b[39m \u001b[43m        \u001b[49m\u001b[43mk_proj_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   6008\u001b[39m \u001b[43m        \u001b[49m\u001b[43mv_proj_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mv_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   6009\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstatic_k\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstatic_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   6010\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstatic_v\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstatic_v\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   6011\u001b[39m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   6012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6014\u001b[39m is_batched = _mha_shape_check(\n\u001b[32m   6015\u001b[39m     query, key, value, key_padding_mask, attn_mask, num_heads\n\u001b[32m   6016\u001b[39m )\n\u001b[32m   6018\u001b[39m \u001b[38;5;66;03m# For unbatched input, we unsqueeze at the expected batch-dim to pretend that the input\u001b[39;00m\n\u001b[32m   6019\u001b[39m \u001b[38;5;66;03m# is batched, run the computation and before returning squeeze the\u001b[39;00m\n\u001b[32m   6020\u001b[39m \u001b[38;5;66;03m# batch dimension so that the output doesn't carry this temporary batch dimension.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thava/client/.venv/lib/python3.11/site-packages/torch/overrides.py:1739\u001b[39m, in \u001b[36mhandle_torch_function\u001b[39m\u001b[34m(public_api, relevant_args, *args, **kwargs)\u001b[39m\n\u001b[32m   1731\u001b[39m     warnings.warn(\n\u001b[32m   1732\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mDefining your `__torch_function__ as a plain method is deprecated and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1733\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mwill be an error in future, please define it as a classmethod.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1734\u001b[39m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[32m   1735\u001b[39m     )\n\u001b[32m   1737\u001b[39m \u001b[38;5;66;03m# Use `public_api` instead of `implementation` so __torch_function__\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;66;03m# implementations can do equality/identity comparisons.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m result = \u001b[43mtorch_func_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpublic_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1741\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[32m   1742\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thava/client/.venv/lib/python3.11/site-packages/torch/_tensor.py:1512\u001b[39m, in \u001b[36mTensor.__torch_function__\u001b[39m\u001b[34m(cls, func, types, args, kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[32m   1511\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _C.DisableTorchFunctionSubclass():\n\u001b[32m-> \u001b[39m\u001b[32m1512\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1513\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[32m   1514\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thava/client/.venv/lib/python3.11/site-packages/torch/nn/functional.py:6097\u001b[39m, in \u001b[36mmulti_head_attention_forward\u001b[39m\u001b[34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[39m\n\u001b[32m   6093\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_separate_proj_weight:\n\u001b[32m   6094\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[32m   6095\u001b[39m         in_proj_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   6096\u001b[39m     ), \u001b[33m\"\u001b[39m\u001b[33muse_separate_proj_weight is False but in_proj_weight is None\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m6097\u001b[39m     q, k, v = \u001b[43m_in_projection_packed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_proj_bias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6098\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6099\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[32m   6100\u001b[39m         q_proj_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   6101\u001b[39m     ), \u001b[33m\"\u001b[39m\u001b[33muse_separate_proj_weight is True but q_proj_weight is None\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thava/client/.venv/lib/python3.11/site-packages/torch/nn/functional.py:5513\u001b[39m, in \u001b[36m_in_projection_packed\u001b[39m\u001b[34m(q, k, v, w, b)\u001b[39m\n\u001b[32m   5510\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m proj[\u001b[32m0\u001b[39m], proj[\u001b[32m1\u001b[39m], proj[\u001b[32m2\u001b[39m]\n\u001b[32m   5511\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   5512\u001b[39m     \u001b[38;5;66;03m# encoder-decoder attention\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5513\u001b[39m     w_q, w_kv = \u001b[43mw\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mE\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5514\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m b \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5515\u001b[39m         b_q = b_kv = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thava/client/src/rtorch/rtorch/biject.py:414\u001b[39m, in \u001b[36mbiject_fn.<locals>.bijected_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    410\u001b[39m payload = remote_call_payload.dumps()\n\u001b[32m    412\u001b[39m remote_call_result_payload = remote_call(payload, device=device)\n\u001b[32m--> \u001b[39m\u001b[32m414\u001b[39m result = pickle.loads(\u001b[38;5;28mbytes\u001b[39m(remote_call_result_payload))\n\u001b[32m    416\u001b[39m \u001b[38;5;66;03m# TODO: we are passing in a \"device\" and a \"to_device\", where\u001b[39;00m\n\u001b[32m    417\u001b[39m \u001b[38;5;66;03m# device means where we route the call, and to_device means where\u001b[39;00m\n\u001b[32m    418\u001b[39m \u001b[38;5;66;03m# the device will put any RObject. But does this just mean cpu?\u001b[39;00m\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, RObject):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thava/client/.venv/lib/python3.11/site-packages/torch/_utils.py:202\u001b[39m, in \u001b[36m_rebuild_tensor_v2\u001b[39m\u001b[34m(storage, storage_offset, size, stride, requires_grad, backward_hooks, metadata)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_rebuild_tensor_v2\u001b[39m(\n\u001b[32m    194\u001b[39m     storage,\n\u001b[32m    195\u001b[39m     storage_offset,\n\u001b[32m   (...)\u001b[39m\u001b[32m    200\u001b[39m     metadata=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    201\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m     tensor = \u001b[43m_rebuild_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    203\u001b[39m     tensor.requires_grad = requires_grad\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m metadata:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thava/client/.venv/lib/python3.11/site-packages/torch/_utils.py:175\u001b[39m, in \u001b[36m_rebuild_tensor\u001b[39m\u001b[34m(storage, storage_offset, size, stride)\u001b[39m\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_rebuild_tensor\u001b[39m(storage, storage_offset, size, stride):\n\u001b[32m    173\u001b[39m     \u001b[38;5;66;03m# first construct a tensor with the correct dtype/device\u001b[39;00m\n\u001b[32m    174\u001b[39m     t = torch.empty((\u001b[32m0\u001b[39m,), dtype=storage.dtype, device=storage._untyped_storage.device)\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_untyped_storage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thava/client/src/rtorch/rtorch/biject.py:388\u001b[39m, in \u001b[36mbiject_fn.<locals>.bijected_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbijected_fn\u001b[39m(*args, **kwargs) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m388\u001b[39m     bound_arguments: Optional[BoundArguments] = \u001b[43mget_typechecked_arguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfull_fn_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    392\u001b[39m     parameterized_call = get_parameterized_call(bound_arguments, *args, **kwargs)\n\u001b[32m    394\u001b[39m     \u001b[38;5;28;01mmatch\u001b[39;00m parameterized_call:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thava/client/src/rtorch/rtorch/biject.py:294\u001b[39m, in \u001b[36mget_typechecked_arguments\u001b[39m\u001b[34m(full_fn_name, namespace, fn_name, signatures, *args, **kwargs)\u001b[39m\n\u001b[32m    292\u001b[39m     bound_arguments: BoundArguments = signature.bind(*args, **kwargs)\n\u001b[32m    293\u001b[39m     bound_arguments.apply_defaults()\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m     \u001b[43mtypecheck_arguments\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbound_arguments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    295\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m bound_arguments\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m _e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thava/client/src/rtorch/rtorch/biject.py:276\u001b[39m, in \u001b[36mtypecheck_arguments\u001b[39m\u001b[34m(signature, bound_arguments)\u001b[39m\n\u001b[32m    273\u001b[39m     check_type(proposed_argument, argument_type)\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m TypeCheckError:\n\u001b[32m    275\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtype of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproposed_argument\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(proposed_argument)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    277\u001b[39m         + \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mwhich does not match type hint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margument_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    278\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thava/client/.venv/lib/python3.11/site-packages/torch/storage.py:218\u001b[39m, in \u001b[36m_StorageBase.__repr__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.device.type == \u001b[33m\"\u001b[39m\u001b[33mmeta\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + info_str\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m data_str = \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m + \u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data_str + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + info_str\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thava/client/.venv/lib/python3.11/site-packages/torch/storage.py:218\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.device.type == \u001b[33m\"\u001b[39m\u001b[33mmeta\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + info_str\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m data_str = \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.size()))\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data_str + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + info_str\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thava/client/.venv/lib/python3.11/site-packages/torch/storage.py:456\u001b[39m, in \u001b[36mUntypedStorage.__getitem__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.device.type == \u001b[33m\"\u001b[39m\u001b[33mmeta\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    455\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNot available for \u001b[39m\u001b[33m'\u001b[39m\u001b[33mmeta\u001b[39m\u001b[33m'\u001b[39m\u001b[33m device type\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "x = torch.randn(10, 32, 512).to(0)  # (sequence_length, batch_size, embedding_dim)\n",
    "print(x.shape)\n",
    "y = torch.randn(10, 32, 512).to(0)  # (sequence_length, batch_size, embedding_dim)\n",
    "print(y.shape)\n",
    "output = model(x, y)\n",
    "print(output.shape)  # (sequence_length, batch_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1, 2, 3], device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='mps:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='mps:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.to(device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1 = torch.nn.Linear(8, 1)\n",
    "        self.act1 = torch.nn.ReLU()\n",
    "        self.hidden2 = torch.nn.Linear(12, 8)\n",
    "        self.act2 = torch.nn.ReLU()\n",
    "        self.output = torch.nn.Linear(8, 1)\n",
    "        self.act_output = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden1(x)\n",
    "        # x = self.act1(self.hidden1(x))\n",
    "        # x = self.act2(self.hidden2(x))\n",
    "        # x = self.act_output(self.output(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodule = Model().to(device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.Model"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mymodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1.0, 2, 3, 4, 5, 6, 7, 8]], device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serialize: 7.8e-05\n",
      "IPC: 0.19710493087768555\n",
      "Deserialize: 0.00017189979553222656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out = mymodule(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rtorch.biject.RTensor"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RId(id=2240209448702670)\n",
      "Serialize: 4.5e-05\n",
      "IPC: 0.08270430564880371\n",
      "Deserialize: 4.0531158447265625e-06\n",
      "\n",
      "tensor([[-1.4626]], device='mps:0', grad_fn=<LinearBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(out.rid)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch.nn.modules.module.Module._wrapped_call_impl(self, *args, **kwargs)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.BCELoss.__call__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x135e14ac0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mymodule.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch.optim.adam.Adam.__init__(self, params: Union[Iterable[torch.Tensor], Iterable[Dict[str, Any]]], lr: Union[float, torch.Tensor] = 0.001, betas: Tuple[float, float] = (0.9, 0.999), eps: float = 1e-08, weight_decay: float = 0, amsgrad: bool = False, *, foreach: Optional[bool] = None, maximize: bool = False, capturable: bool = False, differentiable: bool = False, fused: Optional[bool] = None)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.optim.Adam.__init__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(mymodule.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.optim.adam.Adam"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.01\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serialize: 5.6e-05\n",
      "IPC: 0.6681473255157471\n",
      "Deserialize: 4.458427429199219e-05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([0.1, 0.2, 0.3], device=0)\n",
    "b = torch.tensor([0.1, 0.2, 0.3], device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serialize: 6.2e-05\n",
      "IPC: 0.12306618690490723\n",
      "Deserialize: 4.887580871582031e-05\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0., device='mps:0')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([0.1, 0.2, 0.3])\n",
    "b = torch.tensor([0.1, 0.2, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serialize: 1.8e-05\n",
      "IPC: 0.06506967544555664\n",
      "Deserialize: 6.222724914550781e-05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3,4,5], device=0)\n",
    "b = torch.tensor([2,3,4,5,6], device=0)\n",
    "c = a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 8)\n",
      "49413\n",
      "Serialize: 0.00018\n",
      "IPC: 1.054084062576294\n",
      "Deserialize: 6.008148193359375e-05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = 0\n",
    "\n",
    "dataset = np.loadtxt('pima-indians.csv', delimiter=',')\n",
    "X = dataset[:,0:8]\n",
    "print(X.shape)\n",
    "y = dataset[:,8]\n",
    "\n",
    "X = torch.tensor(X, dtype=torch.float32, device=device)\n",
    "y = torch.tensor(y, dtype=torch.float32, device=device).reshape(-1,1)\n",
    "\n",
    "model = Model().to(device=device)\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serialize: 4.2e-05\n",
      "IPC: 0.13765978813171387\n",
      "Deserialize: 5.2928924560546875e-05\n",
      "\n",
      "Serialize: 0.00011\n",
      "IPC: 0.13586115837097168\n",
      "Deserialize: 1.0013580322265625e-05\n",
      "\n",
      "Finished epoch 0, latest loss tensor(5032.7725, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=2558771468014304)\n",
      "Finished epoch 1, latest loss tensor(4262.5713, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4302313441825504)\n",
      "Finished epoch 2, latest loss tensor(3559.2476, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4022118365369056)\n",
      "Finished epoch 3, latest loss tensor(2922.8027, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3689735141298912)\n",
      "Finished epoch 4, latest loss tensor(2353.2368, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=375691131065056)\n",
      "Finished epoch 5, latest loss tensor(1850.5488, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=2185251047183072)\n",
      "Finished epoch 6, latest loss tensor(1414.7397, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4439425977783008)\n",
      "Finished epoch 7, latest loss tensor(1045.8090, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4233787238617824)\n",
      "Finished epoch 8, latest loss tensor(743.7565, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=1989013991428832)\n",
      "Finished epoch 9, latest loss tensor(508.5825, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=1714385192588000)\n",
      "Finished epoch 10, latest loss tensor(340.2869, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3227012544697056)\n",
      "Finished epoch 11, latest loss tensor(238.6946, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3295809330844384)\n",
      "Finished epoch 12, latest loss tensor(186.6703, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4123797421134560)\n",
      "Finished epoch 13, latest loss tensor(143.6227, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3354053382345440)\n",
      "Finished epoch 14, latest loss tensor(106.9998, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3832212091409120)\n",
      "Finished epoch 15, latest loss tensor(76.8017, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3103467810427616)\n",
      "Finished epoch 16, latest loss tensor(52.9053, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=2227844237857504)\n",
      "Finished epoch 17, latest loss tensor(34.8716, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4327232842076896)\n",
      "Finished epoch 18, latest loss tensor(22.6873, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4288728460268256)\n",
      "Finished epoch 19, latest loss tensor(17.3092, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4453659499401952)\n",
      "Finished epoch 20, latest loss tensor(16.3425, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=2169230819168992)\n",
      "Finished epoch 21, latest loss tensor(14.1901, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=2165202139845344)\n",
      "Finished epoch 22, latest loss tensor(11.4569, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=2206180422816480)\n",
      "Finished epoch 23, latest loss tensor(9.7878, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3867417938334433)\n",
      "Finished epoch 24, latest loss tensor(9.2455, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=2175531536192225)\n",
      "Finished epoch 25, latest loss tensor(7.8626, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=948729962664673)\n",
      "Finished epoch 26, latest loss tensor(7.3715, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3135173259006689)\n",
      "Finished epoch 27, latest loss tensor(6.2629, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4231648344904417)\n",
      "Finished epoch 28, latest loss tensor(6.6969, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4352414235333345)\n",
      "Finished epoch 29, latest loss tensor(6.6918, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=1645193269449441)\n",
      "Finished epoch 30, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3979941786522337)\n",
      "Finished epoch 31, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3177680550335201)\n",
      "Finished epoch 32, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3731684086878945)\n",
      "Finished epoch 33, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=958857495548641)\n",
      "Finished epoch 34, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=1953503201825505)\n",
      "Finished epoch 35, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=958346394440417)\n",
      "Finished epoch 36, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3809573318791905)\n",
      "Finished epoch 37, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3303355588383457)\n",
      "Finished epoch 38, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4283029038666466)\n",
      "Finished epoch 39, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3313865373356770)\n",
      "Finished epoch 40, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4319141123691234)\n",
      "Finished epoch 41, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3374858203927266)\n",
      "Finished epoch 42, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4354583193817826)\n",
      "Finished epoch 43, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3149806212584162)\n",
      "Finished epoch 44, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3188980609290978)\n",
      "Finished epoch 45, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4414278944264930)\n",
      "Finished epoch 46, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=554451964891874)\n",
      "Finished epoch 47, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=942420655706850)\n",
      "Finished epoch 48, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=926404722660066)\n",
      "Finished epoch 49, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=1021392219378402)\n",
      "Finished epoch 50, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3294529430590178)\n",
      "Finished epoch 51, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=1952145992159970)\n",
      "Finished epoch 52, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4353372013040355)\n",
      "Finished epoch 53, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=963551894803171)\n",
      "Finished epoch 54, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3741214619308771)\n",
      "Finished epoch 55, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=1451876791456483)\n",
      "Finished epoch 56, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4401385452442339)\n",
      "Finished epoch 57, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3155488454316771)\n",
      "Finished epoch 58, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=2136528938177251)\n",
      "Finished epoch 59, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4300187433013987)\n",
      "Finished epoch 60, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3842408343769827)\n",
      "Finished epoch 61, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4441620706071267)\n",
      "Finished epoch 62, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=2190284748853987)\n",
      "Finished epoch 63, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=1876747841278691)\n",
      "Finished epoch 64, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4029325320491747)\n",
      "Finished epoch 65, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=1951905473991396)\n",
      "Finished epoch 66, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3159053277172452)\n",
      "Finished epoch 67, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3311125184221924)\n",
      "Finished epoch 68, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3218542869189348)\n",
      "Finished epoch 69, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=968512582030052)\n",
      "Finished epoch 70, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=707421520106212)\n",
      "Finished epoch 71, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=2829758134588132)\n",
      "Finished epoch 72, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4425394319626980)\n",
      "Finished epoch 73, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4398610903569124)\n",
      "Finished epoch 74, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4325407480976100)\n",
      "Finished epoch 75, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3291449939038948)\n",
      "Finished epoch 76, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=2680031279682276)\n",
      "Finished epoch 77, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4294479421477604)\n",
      "Finished epoch 78, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4055593340474085)\n",
      "Finished epoch 79, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4379000082895589)\n",
      "Finished epoch 80, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4473021211972325)\n",
      "Finished epoch 81, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=2077803850339045)\n",
      "Finished epoch 82, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=2696682867888869)\n",
      "Finished epoch 83, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=2076098748322533)\n",
      "Finished epoch 84, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4065046563492581)\n",
      "Finished epoch 85, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4458448387936997)\n",
      "Finished epoch 86, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4007940678324965)\n",
      "Finished epoch 87, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=2114268122682085)\n",
      "Finished epoch 88, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3776652394468069)\n",
      "Finished epoch 89, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=1354767580893925)\n",
      "Finished epoch 90, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4367506750411493)\n",
      "Finished epoch 91, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=2057548784571110)\n",
      "Finished epoch 92, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=999131403883238)\n",
      "Finished epoch 93, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=2637463858811622)\n",
      "Finished epoch 94, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3655633100968678)\n",
      "Finished epoch 95, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=1674008205038310)\n",
      "Finished epoch 96, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=1010109340291814)\n",
      "Finished epoch 97, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=384392734806758)\n",
      "Finished epoch 98, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4417817997316838)\n",
      "Finished epoch 99, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3584143370326758)\n",
      "Finished epoch 100, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3673908186813158)\n",
      "Finished epoch 101, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3128503174796007)\n",
      "Finished epoch 102, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4494633487405799)\n",
      "Finished epoch 103, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=1676039724569319)\n",
      "Finished epoch 104, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3217224314229479)\n",
      "Finished epoch 105, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4485004170728167)\n",
      "Finished epoch 106, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3752119541273319)\n",
      "Finished epoch 107, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=1650987180331751)\n",
      "Finished epoch 108, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4281993951548135)\n",
      "Finished epoch 109, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3585453335352039)\n",
      "Finished epoch 110, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3212143367918311)\n",
      "Finished epoch 111, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=2641462473364200)\n",
      "Finished epoch 112, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=1936314742706920)\n",
      "Finished epoch 113, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=2040618023490280)\n",
      "Finished epoch 114, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3287425554682600)\n",
      "Finished epoch 115, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4456653091607272)\n",
      "Finished epoch 116, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=1085971347641064)\n",
      "Finished epoch 117, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3504935583453928)\n",
      "Finished epoch 118, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3186674211853032)\n",
      "Finished epoch 119, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=2113881575625448)\n",
      "Finished epoch 120, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3376206823658216)\n",
      "Finished epoch 121, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=1002438528701160)\n",
      "Finished epoch 122, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=2079629211439848)\n",
      "Finished epoch 123, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=2807952585626345)\n",
      "Finished epoch 124, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=909147544064745)\n",
      "Finished epoch 125, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3187120888451817)\n",
      "Finished epoch 126, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4444575643570921)\n",
      "Finished epoch 127, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4095128514433769)\n",
      "Finished epoch 128, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=2222960860041961)\n",
      "Finished epoch 129, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=1596475455410921)\n",
      "Finished epoch 130, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=757857321063145)\n",
      "Finished epoch 131, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=2192625506030313)\n",
      "Finished epoch 132, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=1721355924509417)\n",
      "Finished epoch 133, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=2202379376759530)\n",
      "Finished epoch 134, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4403734799553258)\n",
      "Finished epoch 135, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4383904935547626)\n",
      "Finished epoch 136, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4246654960636650)\n",
      "Finished epoch 137, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=2943325659828970)\n",
      "Finished epoch 138, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=1250653278671594)\n",
      "Finished epoch 139, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4330870679376618)\n",
      "Finished epoch 140, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=1932672610439914)\n",
      "Finished epoch 141, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=1012772220015338)\n",
      "Finished epoch 142, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3045296773370602)\n",
      "Finished epoch 143, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=2011910462083818)\n",
      "Finished epoch 144, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4475383443985131)\n",
      "Finished epoch 145, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4167618972455659)\n",
      "Finished epoch 146, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=2178576668005099)\n",
      "Finished epoch 147, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=2027934985065195)\n",
      "Finished epoch 148, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=461646311559915)\n",
      "Finished epoch 149, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4161610313208555)\n",
      "Finished epoch 150, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3102144960500459)\n",
      "Finished epoch 151, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3336139073753835)\n",
      "Finished epoch 152, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=1791230747448043)\n",
      "Finished epoch 153, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4449407481778923)\n",
      "Finished epoch 154, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4328078950634220)\n",
      "Finished epoch 155, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4412986159108844)\n",
      "Finished epoch 156, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4319248497873644)\n",
      "Finished epoch 157, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3822509760287468)\n",
      "Finished epoch 158, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=1506285437162220)\n",
      "Finished epoch 159, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=1107600802943724)\n",
      "Finished epoch 160, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=1664146960126700)\n",
      "Finished epoch 161, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4448037387211500)\n",
      "Finished epoch 162, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3650912931910380)\n",
      "Finished epoch 163, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3113865926251244)\n",
      "Finished epoch 164, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=2790764126507757)\n",
      "Finished epoch 165, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4463838571893485)\n",
      "Finished epoch 166, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3195259851477741)\n",
      "Finished epoch 167, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4423264015848173)\n",
      "Finished epoch 168, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3760383058350829)\n",
      "Finished epoch 169, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=2884948464341741)\n",
      "Finished epoch 170, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4232460093723373)\n",
      "Finished epoch 171, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3965751214576365)\n",
      "Finished epoch 172, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4427657767391981)\n",
      "Finished epoch 173, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4340959557554925)\n",
      "Finished epoch 174, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=2088794671649518)\n",
      "Finished epoch 175, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=1476087522104046)\n",
      "Finished epoch 176, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=2655829138969326)\n",
      "Finished epoch 177, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3970759146443502)\n",
      "Finished epoch 178, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=2014182499783406)\n",
      "Finished epoch 179, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4428838883398382)\n",
      "Finished epoch 180, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=889708522083054)\n",
      "Finished epoch 181, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3226870810776302)\n",
      "Finished epoch 182, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=2183563125035758)\n",
      "Finished epoch 183, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3799639059436270)\n",
      "Finished epoch 184, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4397824924553967)\n",
      "Finished epoch 185, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=2546208688673519)\n",
      "Finished epoch 186, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4095781349462767)\n",
      "Finished epoch 187, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=1723245710119663)\n",
      "Finished epoch 188, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=1988043328819951)\n",
      "Finished epoch 189, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3921916778353391)\n",
      "Finished epoch 190, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=2504745074397935)\n",
      "Finished epoch 191, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=2898924287922927)\n",
      "Finished epoch 192, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=937339709395695)\n",
      "Finished epoch 193, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3849121377653487)\n",
      "Finished epoch 194, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4395058965615344)\n",
      "Finished epoch 195, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=3896765449868016)\n",
      "Finished epoch 196, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=889326269993712)\n",
      "Finished epoch 197, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=4197310081372912)\n",
      "Finished epoch 198, latest loss tensor(6.5558, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=2623058538500848)\n",
      "Finished epoch 199, latest loss tensor(6.6917, device='mps:0', grad_fn=<MseLossBackward0>), id RId(id=1424685353505520)\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 200\n",
    "batch_size = 256\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(0, 768, batch_size):\n",
    "        Xbatch = X[i:i+batch_size]\n",
    "        y_pred = model(Xbatch)\n",
    "        ybatch = y[i:i+batch_size]\n",
    "        loss = loss_fn(y_pred, ybatch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f'Finished epoch {epoch}, latest loss {loss}, id {loss.rid}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "client",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
