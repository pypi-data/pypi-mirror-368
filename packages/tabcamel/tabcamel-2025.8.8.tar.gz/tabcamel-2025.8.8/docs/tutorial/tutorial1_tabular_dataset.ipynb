{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1: Working with the `TabularDataset` Class\n",
    "\n",
    "Welcome to this comprehensive tutorial on using the `TabularDataset` class from TabCamel! This tutorial will guide you through:\n",
    "\n",
    "- **Dataset Creation**: Loading datasets from OpenML for classification and regression tasks\n",
    "- **Dataset Properties**: Understanding key attributes and methods\n",
    "- **Sampling**: Creating stratified and uniform subsamples\n",
    "- **Splitting**: Dividing datasets into train/test sets\n",
    "- **Complex Operations**: Chaining operations for advanced data preprocessing workflows\n",
    "\n",
    "By the end of this tutorial, you'll have a solid understanding of how to effectively use `TabularDataset` for your machine learning projects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "First, let's prepare our Python environment by loading the necessary extensions and configuring automatic reloading for development.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable auto-reloading of modules when they change\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Configure matplotlib to display plots inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the main TabularDataset class\n",
    "from tabcamel.data.dataset import TabularDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating Datasets\n",
    "\n",
    "The `TabularDataset` class provides an easy way to load and work with datasets from OpenML, UCI, bnlearn, sklearn, pgmpy, and local sources. Let's explore how to create datasets for different types of machine learning tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Loading OpenML Datasets\n",
    "\n",
    "[OpenML](https://www.openml.org/) is a collaborative platform for machine learning that provides access to thousands of datasets. The `TabularDataset` class can automatically download and prepare these datasets for your machine learning experiments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Tasks\n",
    "\n",
    "For classification problems, we need to specify `task_type=\"classification\"`. Let's load the famous \"adult\" dataset (also known as Census Income dataset) for binary classification:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabularDataset(dataset_name=adult, task_type=classification, target_col=target, is_tensor=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a classification dataset from OpenML\n",
    "dataset_openml = TabularDataset(\n",
    "    dataset_name=\"adult\",           # OpenML dataset name\n",
    "    task_type=\"classification\",     # Specify this is a classification task\n",
    ")\n",
    "\n",
    "# Display basic information about the dataset\n",
    "dataset_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================DATA INFO============================\n",
      "Dataset: adult\n",
      "Task type: classification\n",
      "Status (is_tensor): False\n",
      "Number of samples: 48842\n",
      "Number of features: 14 (Numerical: 2, Categorical: 12)\n",
      "Number of classes: 2\n",
      "Class distribution: {'<=50K': 0.7607182343065395, '>50K': 0.23928176569346055}\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "# Print detailed information about the dataset\n",
    "print(dataset_openml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "age",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "workclass",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "fnlwgt",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "education",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "education-num",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "marital-status",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "occupation",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "relationship",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "race",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sex",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "capitalgain",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "capitalloss",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "hoursperweek",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "native-country",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "target",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "5a4f4a01-79b6-4c71-b116-d5e1c701e1d5",
       "rows": [
        [
         "0",
         "2",
         "State-gov",
         "77516",
         "Bachelors",
         "13",
         "Never-married",
         "Adm-clerical",
         "Not-in-family",
         "White",
         "Male",
         "1",
         "0",
         "2",
         "United-States",
         "<=50K"
        ],
        [
         "1",
         "3",
         "Self-emp-not-inc",
         "83311",
         "Bachelors",
         "13",
         "Married-civ-spouse",
         "Exec-managerial",
         "Husband",
         "White",
         "Male",
         "0",
         "0",
         "0",
         "United-States",
         "<=50K"
        ],
        [
         "2",
         "2",
         "Private",
         "215646",
         "HS-grad",
         "9",
         "Divorced",
         "Handlers-cleaners",
         "Not-in-family",
         "White",
         "Male",
         "0",
         "0",
         "2",
         "United-States",
         "<=50K"
        ],
        [
         "3",
         "3",
         "Private",
         "234721",
         "11th",
         "7",
         "Married-civ-spouse",
         "Handlers-cleaners",
         "Husband",
         "Black",
         "Male",
         "0",
         "0",
         "2",
         "United-States",
         "<=50K"
        ],
        [
         "4",
         "1",
         "Private",
         "338409",
         "Bachelors",
         "13",
         "Married-civ-spouse",
         "Prof-specialty",
         "Wife",
         "Black",
         "Female",
         "0",
         "0",
         "2",
         "Cuba",
         "<=50K"
        ]
       ],
       "shape": {
        "columns": 15,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capitalgain</th>\n",
       "      <th>capitalloss</th>\n",
       "      <th>hoursperweek</th>\n",
       "      <th>native-country</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  age         workclass  fnlwgt  education  education-num      marital-status  \\\n",
       "0   2         State-gov   77516  Bachelors             13       Never-married   \n",
       "1   3  Self-emp-not-inc   83311  Bachelors             13  Married-civ-spouse   \n",
       "2   2           Private  215646    HS-grad              9            Divorced   \n",
       "3   3           Private  234721       11th              7  Married-civ-spouse   \n",
       "4   1           Private  338409  Bachelors             13  Married-civ-spouse   \n",
       "\n",
       "          occupation   relationship   race     sex capitalgain capitalloss  \\\n",
       "0       Adm-clerical  Not-in-family  White    Male           1           0   \n",
       "1    Exec-managerial        Husband  White    Male           0           0   \n",
       "2  Handlers-cleaners  Not-in-family  White    Male           0           0   \n",
       "3  Handlers-cleaners        Husband  Black    Male           0           0   \n",
       "4     Prof-specialty           Wife  Black  Female           0           0   \n",
       "\n",
       "  hoursperweek native-country target  \n",
       "0            2  United-States  <=50K  \n",
       "1            0  United-States  <=50K  \n",
       "2            2  United-States  <=50K  \n",
       "3            2  United-States  <=50K  \n",
       "4            2           Cuba  <=50K  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the first few rows of the dataset\n",
    "dataset_openml.data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Tasks\n",
    "\n",
    "For regression problems, we specify `task_type=\"regression\"`. Let's load the \"liver-disorders\" dataset for continuous target prediction:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabularDataset(dataset_name=liver-disorders, task_type=regression, target_col=target, is_tensor=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a regression dataset from OpenML\n",
    "dataset_openml = TabularDataset(\n",
    "    dataset_name=\"liver-disorders\",  # OpenML dataset name\n",
    "    task_type=\"regression\",  # Specify this is a regression task\n",
    ")\n",
    "\n",
    "# Display basic information about the regression dataset\n",
    "dataset_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================DATA INFO============================\n",
      "Dataset: liver-disorders\n",
      "Task type: regression\n",
      "Status (is_tensor): False\n",
      "Number of samples: 345\n",
      "Number of features: 5 (Numerical: 5, Categorical: 0)\n",
      "Number of classes: None\n",
      "Class distribution: None\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "# Print detailed information about the regression dataset\n",
    "print(dataset_openml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mcv",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "alkphos",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sgpt",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sgot",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "gammagt",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "target",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "392620d0-8a01-478a-9fcc-0883aacd5df2",
       "rows": [
        [
         "0",
         "85",
         "92",
         "45",
         "27",
         "31",
         "0.0"
        ],
        [
         "1",
         "85",
         "64",
         "59",
         "32",
         "23",
         "0.0"
        ],
        [
         "2",
         "86",
         "54",
         "33",
         "16",
         "54",
         "0.0"
        ],
        [
         "3",
         "91",
         "78",
         "34",
         "24",
         "36",
         "0.0"
        ],
        [
         "4",
         "87",
         "70",
         "12",
         "28",
         "10",
         "0.0"
        ],
        [
         "5",
         "98",
         "55",
         "13",
         "17",
         "17",
         "0.0"
        ],
        [
         "6",
         "88",
         "62",
         "20",
         "17",
         "9",
         "0.5"
        ],
        [
         "7",
         "88",
         "67",
         "21",
         "11",
         "11",
         "0.5"
        ],
        [
         "8",
         "92",
         "54",
         "22",
         "20",
         "7",
         "0.5"
        ],
        [
         "9",
         "90",
         "60",
         "25",
         "19",
         "5",
         "0.5"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mcv</th>\n",
       "      <th>alkphos</th>\n",
       "      <th>sgpt</th>\n",
       "      <th>sgot</th>\n",
       "      <th>gammagt</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85</td>\n",
       "      <td>92</td>\n",
       "      <td>45</td>\n",
       "      <td>27</td>\n",
       "      <td>31</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85</td>\n",
       "      <td>64</td>\n",
       "      <td>59</td>\n",
       "      <td>32</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86</td>\n",
       "      <td>54</td>\n",
       "      <td>33</td>\n",
       "      <td>16</td>\n",
       "      <td>54</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91</td>\n",
       "      <td>78</td>\n",
       "      <td>34</td>\n",
       "      <td>24</td>\n",
       "      <td>36</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87</td>\n",
       "      <td>70</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>98</td>\n",
       "      <td>55</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>88</td>\n",
       "      <td>62</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>88</td>\n",
       "      <td>67</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>92</td>\n",
       "      <td>54</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>90</td>\n",
       "      <td>60</td>\n",
       "      <td>25</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mcv  alkphos  sgpt  sgot  gammagt  target\n",
       "0   85       92    45    27       31     0.0\n",
       "1   85       64    59    32       23     0.0\n",
       "2   86       54    33    16       54     0.0\n",
       "3   91       78    34    24       36     0.0\n",
       "4   87       70    12    28       10     0.0\n",
       "5   98       55    13    17       17     0.0\n",
       "6   88       62    20    17        9     0.5\n",
       "7   88       67    21    11       11     0.5\n",
       "8   92       54    22    20        7     0.5\n",
       "9   90       60    25    19        5     0.5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the first 10 rows of the regression dataset\n",
    "dataset_openml.data_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Understanding Dataset Properties\n",
    "\n",
    "The `TabularDataset` class provides several useful properties and methods to inspect and understand your data. Let's explore the key attributes and functionalities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available methods and attributes:\n",
      "['X_df', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_categorical_feature_list', '_class2distribution', '_class2samples', '_col2type', '_data_df', '_data_id', '_data_source', '_dataset_name', '_infer_column_types', '_init_data_df', '_init_dataset_properties', '_is_tensor', '_metafeature_dict', '_num_categorical_features', '_num_classes', '_num_features', '_num_numerical_features', '_num_samples', '_numerical_feature_list', '_parse_metafeatures', '_sanity_check', '_target_col', '_task_type', '_update_data_df', '_update_dataset_properties', 'categorical_feature_list', 'class2distribution', 'class2samples', 'class_list', 'col2type', 'data_df', 'data_indices', 'dataset_name', 'drop_class', 'drop_constant_feature', 'drop_low_sample_class', 'drop_nan_feature', 'get_cardinality_list', 'info_df', 'is_tensor', 'metafeature_dict', 'num_classes', 'num_features', 'num_samples', 'numerical_feature_list', 'sample', 'split', 'target_col', 'task_type', 'y_s']\n"
     ]
    }
   ],
   "source": [
    "# Create a dataset instance to explore its properties\n",
    "dataset = TabularDataset(\n",
    "    dataset_name=\"adult\",\n",
    "    task_type=\"classification\",\n",
    "    metafeature_dict={},  # Optional: dictionary for storing metadata\n",
    "    data_df=None,         # Optional: provide your own DataFrame\n",
    "    target_col=None,      # Optional: specify custom target column\n",
    ")\n",
    "\n",
    "# Display all available methods and attributes\n",
    "print(\"Available methods and attributes:\")\n",
    "print(dir(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 48842\n"
     ]
    }
   ],
   "source": [
    "# Get the total number of samples in the dataset\n",
    "print(f\"Total number of samples: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data indices: 48842\n"
     ]
    }
   ],
   "source": [
    "# Get the number of data indices (should match the total length)\n",
    "# data_indices tracks which rows from the original dataset are included\n",
    "print(f\"Number of data indices: {len(dataset.data_indices)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dataset Subsampling\n",
    "\n",
    "Subsampling is useful when you want to work with a smaller portion of your dataset for faster experimentation or when dealing with computational constraints. The `TabularDataset` class supports both stratified and uniform sampling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset:\n",
      "============================DATA INFO============================\n",
      "Dataset: adult\n",
      "Task type: classification\n",
      "Status (is_tensor): False\n",
      "Number of samples: 48842\n",
      "Number of features: 14 (Numerical: 2, Categorical: 12)\n",
      "Number of classes: 2\n",
      "Class distribution: {'<=50K': 0.7607182343065395, '>50K': 0.23928176569346055}\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "# Create a fresh dataset for sampling experiments\n",
    "dataset = TabularDataset(\n",
    "    dataset_name=\"adult\",\n",
    "    task_type=\"classification\",\n",
    ")\n",
    "\n",
    "print(\"Original dataset:\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample dictionary keys: dict_keys(['dataset_sampled', 'sample_indices'])\n",
      "\n",
      "Sampled dataset:\n",
      "============================DATA INFO============================\n",
      "Dataset: adult\n",
      "Task type: classification\n",
      "Status (is_tensor): False\n",
      "Number of samples: 1000\n",
      "Number of features: 14 (Numerical: 2, Categorical: 12)\n",
      "Number of classes: 2\n",
      "Class distribution: {'<=50K': 0.76, '>50K': 0.24}\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "# Perform stratified sampling to maintain class distribution\n",
    "# sample_mode=\"stratified\" ensures proportional representation of all classes\n",
    "sample_dict = dataset.sample(\n",
    "    sample_mode=\"stratified\",  # Maintain class proportions\n",
    "    sample_size=1000,  # Take 1000 samples\n",
    ")\n",
    "\n",
    "print(\"Sample dictionary keys:\", sample_dict.keys())\n",
    "print(\"\\nSampled dataset:\")\n",
    "print(sample_dict[\"dataset_sampled\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 sample indices:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[20745, 1127, 14826, 8235, 22110, 28885, 21041, 2248, 1003, 3237]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the first 10 sample indices (row numbers from original dataset)\n",
    "print(\"First 10 sample indices:\")\n",
    "sample_dict[\"sample_indices\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is 20-sample subset contained in 40-sample subset? True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test stratified sampling consistency\n",
    "# With the same seed, smaller samples should be subsets of larger ones\n",
    "subsample20 = dataset.sample(\n",
    "    sample_size=20,\n",
    "    sample_mode=\"stratified\",\n",
    ")\n",
    "\n",
    "subsample40 = dataset.sample(\n",
    "    sample_size=40,\n",
    "    sample_mode=\"stratified\",\n",
    ")\n",
    "\n",
    "# Check if the 20-sample subset is contained in the 40-sample subset\n",
    "is_subset = set(subsample20[\"sample_indices\"]).issubset(subsample40[\"sample_indices\"])\n",
    "print(f\"Is 20-sample subset contained in 40-sample subset? {is_subset}\")\n",
    "is_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 ⊆ 40: True, 40 ⊆ 100: True\n"
     ]
    }
   ],
   "source": [
    "# Test uniform sampling consistency\n",
    "# Uniform sampling also maintains the subset property with the same seed\n",
    "subsample20 = dataset.sample(\n",
    "    sample_size=20,\n",
    "    sample_mode=\"uniform\",\n",
    ")\n",
    "\n",
    "subsample40 = dataset.sample(\n",
    "    sample_size=40,\n",
    "    sample_mode=\"uniform\",\n",
    ")\n",
    "\n",
    "subsample100 = dataset.sample(\n",
    "    sample_size=100,\n",
    "    sample_mode=\"uniform\",\n",
    ")\n",
    "\n",
    "# Check subset relationships for uniform sampling\n",
    "subset_20_in_40 = set(subsample20[\"sample_indices\"]).issubset(subsample40[\"sample_indices\"])\n",
    "subset_40_in_100 = set(subsample40[\"sample_indices\"]).issubset(subsample100[\"sample_indices\"])\n",
    "\n",
    "print(f\"20 ⊆ 40: {subset_20_in_40}, 40 ⊆ 100: {subset_40_in_100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dataset Splitting\n",
    "\n",
    "Dataset splitting is crucial for machine learning to separate data into training and testing sets. The `TabularDataset` class provides flexible splitting options with stratification support.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset for splitting:\n",
      "============================DATA INFO============================\n",
      "Dataset: adult\n",
      "Task type: classification\n",
      "Status (is_tensor): False\n",
      "Number of samples: 48842\n",
      "Number of features: 14 (Numerical: 2, Categorical: 12)\n",
      "Number of classes: 2\n",
      "Class distribution: {'<=50K': 0.7607182343065395, '>50K': 0.23928176569346055}\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "# Create a fresh dataset for splitting experiments\n",
    "dataset = TabularDataset(\n",
    "    dataset_name=\"adult\",\n",
    "    task_type=\"classification\",\n",
    ")\n",
    "\n",
    "print(\"Original dataset for splitting:\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split dictionary keys: dict_keys(['train_set', 'test_set', 'indices_train', 'indices_test'])\n",
      "\n",
      "Training set:\n",
      "============================DATA INFO============================\n",
      "Dataset: adult\n",
      "Task type: classification\n",
      "Status (is_tensor): False\n",
      "Number of samples: 39073\n",
      "Number of features: 14 (Numerical: 2, Categorical: 12)\n",
      "Number of classes: 2\n",
      "Class distribution: {'<=50K': 0.7607299157986334, '>50K': 0.23927008420136667}\n",
      "=================================================================\n",
      "\n",
      "Test set:\n",
      "============================DATA INFO============================\n",
      "Dataset: adult\n",
      "Task type: classification\n",
      "Status (is_tensor): False\n",
      "Number of samples: 9769\n",
      "Number of features: 14 (Numerical: 2, Categorical: 12)\n",
      "Number of classes: 2\n",
      "Class distribution: {'<=50K': 0.7606715119254785, '>50K': 0.23932848807452145}\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "# Perform stratified train-test split\n",
    "# test_size=0.2 means 20% for testing, 80% for training\n",
    "split_dict = dataset.split(\n",
    "    test_size=0.2,  # 20% of data for testing\n",
    "    split_mode=\"stratified\",  # Maintain class proportions in both sets\n",
    ")\n",
    "\n",
    "print(\"Split dictionary keys:\", split_dict.keys())\n",
    "print(\"\\nTraining set:\")\n",
    "print(split_dict[\"train_set\"])\n",
    "print(\"\\nTest set:\")\n",
    "print(split_dict[\"test_set\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 training indices:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[34495, 18591, 12562, 552, 3479, 40259, 23462, 30226, 44653, 18603]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the first 10 training indices\n",
    "print(\"First 10 training indices:\")\n",
    "split_dict[\"indices_train\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set DataFrame index (first 10 rows):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index([34495, 18591, 12562, 552, 3479, 40259, 23462, 30226, 44653, 18603], dtype='int64')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the training set DataFrame index with the training indices\n",
    "# These should correspond to the same rows from the original dataset\n",
    "print(\"Training set DataFrame index (first 10 rows):\")\n",
    "split_dict[\"train_set\"].data_df.head(10).index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Advanced Operations: Chaining Sampling and Splitting\n",
    "\n",
    "Real-world machine learning workflows often require combining multiple operations. The `TabularDataset` class allows you to chain operations like sampling and splitting in various orders to create sophisticated data preprocessing pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Sample Then Split\n",
    "\n",
    "This approach first reduces the dataset size through sampling, then splits the sampled data. This is useful when you want to work with a smaller dataset while maintaining proper train-test separation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset:\n",
      "============================DATA INFO============================\n",
      "Dataset: adult\n",
      "Task type: classification\n",
      "Status (is_tensor): False\n",
      "Number of samples: 48842\n",
      "Number of features: 14 (Numerical: 2, Categorical: 12)\n",
      "Number of classes: 2\n",
      "Class distribution: {'<=50K': 0.7607182343065395, '>50K': 0.23928176569346055}\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "# Start with a fresh dataset for chaining operations\n",
    "dataset = TabularDataset(\n",
    "    dataset_name=\"adult\",\n",
    "    task_type=\"classification\",\n",
    ")\n",
    "\n",
    "print(\"Original dataset:\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sizes - Original: 48842, Subsample: 9768, Train: 7814, Test: 1954\n",
      "\n",
      "Subsampled dataset (20% of original):\n",
      "============================DATA INFO============================\n",
      "Dataset: adult\n",
      "Task type: classification\n",
      "Status (is_tensor): False\n",
      "Number of samples: 9768\n",
      "Number of features: 14 (Numerical: 2, Categorical: 12)\n",
      "Number of classes: 2\n",
      "Class distribution: {'<=50K': 0.7606470106470107, '>50K': 0.23935298935298935}\n",
      "=================================================================\n",
      "\n",
      "Training set (80% of subsample):\n",
      "============================DATA INFO============================\n",
      "Dataset: adult\n",
      "Task type: classification\n",
      "Status (is_tensor): False\n",
      "Number of samples: 7814\n",
      "Number of features: 14 (Numerical: 2, Categorical: 12)\n",
      "Number of classes: 2\n",
      "Class distribution: {'<=50K': 0.7606859482979268, '>50K': 0.2393140517020732}\n",
      "=================================================================\n",
      "\n",
      "Test set (20% of subsample):\n",
      "============================DATA INFO============================\n",
      "Dataset: adult\n",
      "Task type: classification\n",
      "Status (is_tensor): False\n",
      "Number of samples: 1954\n",
      "Number of features: 14 (Numerical: 2, Categorical: 12)\n",
      "Number of classes: 2\n",
      "Class distribution: {'<=50K': 0.7604912998976459, '>50K': 0.23950870010235414}\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Stratified subsample 20% of the original data\n",
    "# This maintains class distribution while reducing dataset size\n",
    "dataset_subsample = dataset.sample(\n",
    "    sample_size=0.2,  # Take 20% of original data\n",
    "    sample_mode=\"stratified\",\n",
    ")[\"dataset_sampled\"]\n",
    "\n",
    "# Step 2: Stratified split the subsampled data into Train and Test sets (4:1 ratio)\n",
    "# This ensures both training and testing maintain the original class distribution\n",
    "split_dict = dataset_subsample.split(\n",
    "    test_size=0.2,  # 20% of subsample for testing\n",
    "    split_mode=\"stratified\",\n",
    ")\n",
    "train_set = split_dict[\"train_set\"]\n",
    "test_set = split_dict[\"test_set\"]\n",
    "\n",
    "# Display the progression: Original → Subsample → Train/Test\n",
    "print(\n",
    "    f\"Sample sizes - Original: {dataset.num_samples}, \"\n",
    "    f\"Subsample: {dataset_subsample.num_samples}, \"\n",
    "    f\"Train: {train_set.num_samples}, \"\n",
    "    f\"Test: {test_set.num_samples}\"\n",
    ")\n",
    "\n",
    "print(f\"\\nSubsampled dataset (20% of original):\")\n",
    "print(dataset_subsample)\n",
    "print(f\"\\nTraining set (80% of subsample):\")\n",
    "print(train_set)\n",
    "print(f\"\\nTest set (20% of subsample):\")\n",
    "print(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Split Then Sample\n",
    "\n",
    "This approach first splits the dataset, then samples from the training portion. This is common in active learning scenarios where you want to simulate having access to a large \"oracle\" set but only use a small portion for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset for split-then-sample:\n",
      "============================DATA INFO============================\n",
      "Dataset: adult\n",
      "Task type: classification\n",
      "Status (is_tensor): False\n",
      "Number of samples: 48842\n",
      "Number of features: 14 (Numerical: 2, Categorical: 12)\n",
      "Number of classes: 2\n",
      "Class distribution: {'<=50K': 0.7607182343065395, '>50K': 0.23928176569346055}\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "# Create a fresh dataset for the split-then-sample workflow\n",
    "dataset = TabularDataset(\n",
    "    dataset_name=\"adult\",\n",
    "    task_type=\"classification\",\n",
    "    metafeature_dict={},  # Empty metadata dictionary\n",
    "    data_df=None,  # Let TabularDataset load the data\n",
    "    target_col=None,  # Use default target column\n",
    ")\n",
    "\n",
    "print(\"Original dataset for split-then-sample:\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oracle set samples: 39073, Test set samples: 9769\n",
      "\n",
      "Final training set:\n",
      "============================DATA INFO============================\n",
      "Dataset: adult\n",
      "Task type: classification\n",
      "Status (is_tensor): False\n",
      "Number of samples: 7814\n",
      "Number of features: 14 (Numerical: 2, Categorical: 12)\n",
      "Number of classes: 2\n",
      "Class distribution: {'<=50K': 0.7606859482979268, '>50K': 0.2393140517020732}\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Stratified split the data into Oracle and Test sets (4:1 ratio)\n",
    "# The \"oracle\" set represents all available training data\n",
    "split_dict = dataset.split(\n",
    "    split_mode=\"stratified\",\n",
    "    test_size=0.2,  # 20% for final testing\n",
    ")\n",
    "oracle_set = split_dict[\"train_set\"]  # 80% available for training\n",
    "test_set = split_dict[\"test_set\"]  # 20% reserved for final evaluation\n",
    "\n",
    "print(f\"Oracle set samples: {oracle_set.num_samples}, Test set samples: {test_set.num_samples}\")\n",
    "\n",
    "# Step 2: Stratified subsample 20% of the Oracle data for actual training\n",
    "# This simulates having limited labeling budget in active learning\n",
    "train_set = oracle_set.sample(\n",
    "    sample_mode=\"stratified\",\n",
    "    sample_size=0.2,  # Use only 20% of available training data\n",
    ")[\"dataset_sampled\"]\n",
    "\n",
    "print(f\"\\nFinal training set:\")\n",
    "print(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Sequential Splitting\n",
    "\n",
    "Sometimes you need to create multiple splits, such as train/validation/test sets. This can be achieved by splitting twice in sequence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset for sequential splitting:\n",
      "============================DATA INFO============================\n",
      "Dataset: adult\n",
      "Task type: classification\n",
      "Status (is_tensor): False\n",
      "Number of samples: 48842\n",
      "Number of features: 14 (Numerical: 2, Categorical: 12)\n",
      "Number of classes: 2\n",
      "Class distribution: {'<=50K': 0.7607182343065395, '>50K': 0.23928176569346055}\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "# Start with a fresh dataset for sequential splitting\n",
    "dataset = TabularDataset(\n",
    "    dataset_name=\"adult\",\n",
    "    task_type=\"classification\",\n",
    ")\n",
    "\n",
    "print(\"Original dataset for sequential splitting:\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After initial split - Training + Validation set:\n",
      "============================DATA INFO============================\n",
      "Dataset: adult\n",
      "Task type: classification\n",
      "Status (is_tensor): False\n",
      "Number of samples: 39073\n",
      "Number of features: 14 (Numerical: 2, Categorical: 12)\n",
      "Number of classes: 2\n",
      "Class distribution: {'<=50K': 0.7607299157986334, '>50K': 0.23927008420136667}\n",
      "=================================================================\n",
      "\n",
      "Split sizes - Train+Val: 39073, Test: 9769\n",
      "After second split - Final training set:\n",
      "============================DATA INFO============================\n",
      "Dataset: adult\n",
      "Task type: classification\n",
      "Status (is_tensor): False\n",
      "Number of samples: 31258\n",
      "Number of features: 14 (Numerical: 2, Categorical: 12)\n",
      "Number of classes: 2\n",
      "Class distribution: {'<=50K': 0.7607332522874144, '>50K': 0.23926674771258558}\n",
      "=================================================================\n",
      "\n",
      "Final split sizes - Train: 31258, Validation: 7815, Test: 9769\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Initial split - divide data into training+validation and test sets\n",
    "split_dict_1 = dataset.split(\n",
    "    train_size=0.8,  # 80% of data for training+validation\n",
    "    split_mode=\"stratified\",  # 20% of data for testing\n",
    ")\n",
    "\n",
    "train_val_set = split_dict_1[\"train_set\"]  # Training + validation set\n",
    "test_set_1 = split_dict_1[\"test_set\"]  # Test set\n",
    "\n",
    "print(\"After initial split - Training + Validation set:\")\n",
    "print(train_val_set)\n",
    "print(f\"\\nSplit sizes - Train+Val: {train_val_set.num_samples}, Test: {test_set_1.num_samples}\")\n",
    "\n",
    "# Step 2: Second split - divide training+validation into separate sets\n",
    "split_dict_2 = train_val_set.split(\n",
    "    train_size=0.8,  # 80% of train_val_set for training\n",
    "    split_mode=\"stratified\",  # 20% of train_val_set for validation\n",
    ")\n",
    "\n",
    "final_train_set = split_dict_2[\"train_set\"]  # Final training set\n",
    "validation_set = split_dict_2[\"test_set\"]  # Validation set\n",
    "\n",
    "print(\"After second split - Final training set:\")\n",
    "print(final_train_set)\n",
    "print(\n",
    "    f\"\\nFinal split sizes - Train: {final_train_set.num_samples}, \"\n",
    "    f\"Validation: {validation_set.num_samples}, \"\n",
    "    f\"Test: {test_set_1.num_samples}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is final training set a subset of train+val set? True\n"
     ]
    }
   ],
   "source": [
    "# Verify that the final training set is a subset of the initial training+validation set\n",
    "# This should be True since we split train_val_set to create final_train_set\n",
    "is_subset = set(train_val_set.data_indices).issuperset(final_train_set.data_indices)\n",
    "print(f\"Is final training set a subset of train+val set? {is_subset}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Data Cleaning Then Splitting\n",
    "\n",
    "Real datasets often have imbalanced classes or classes with very few samples. The `TabularDataset` class provides methods to clean the data before splitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data indices before cleaning (sample from middle range):\n",
      "[480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499]\n"
     ]
    }
   ],
   "source": [
    "# Load a dataset that may have imbalanced classes\n",
    "dataset = TabularDataset(\n",
    "    dataset_name=\"collins\",\n",
    "    task_type=\"classification\",\n",
    ")\n",
    "\n",
    "print(\"Data indices before cleaning (sample from middle range):\")\n",
    "print(dataset.data_indices[480:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset after removing classes with < 10 samples:\n",
      "============================DATA INFO============================\n",
      "Dataset: collins\n",
      "Task type: classification\n",
      "Status (is_tensor): False\n",
      "Number of samples: 970\n",
      "Number of features: 19 (Numerical: 19, Categorical: 0)\n",
      "Number of classes: 26\n",
      "Class distribution: {'109': 0.08247422680412371, '209': 0.08247422680412371, '207': 0.07731958762886598, '107': 0.07731958762886598, '106': 0.049484536082474224, '206': 0.049484536082474224, '201': 0.04536082474226804, '101': 0.04536082474226804, '105': 0.03711340206185567, '205': 0.03711340206185567, '108': 0.030927835051546393, '208': 0.030927835051546393, '214': 0.029896907216494847, '110': 0.029896907216494847, '210': 0.029896907216494847, '213': 0.029896907216494847, '114': 0.029896907216494847, '113': 0.029896907216494847, '102': 0.027835051546391754, '202': 0.027835051546391754, '111': 0.024742268041237112, '211': 0.024742268041237112, '104': 0.01752577319587629, '103': 0.01752577319587629, '204': 0.01752577319587629, '203': 0.01752577319587629}\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "# Remove classes with fewer than 10 samples to ensure reliable splitting\n",
    "# This is important for stratified splitting to work properly\n",
    "dataset.drop_low_sample_class(min_sample_per_class=10)\n",
    "print(\"Dataset after removing classes with < 10 samples:\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data indices after cleaning (sample from middle range):\n",
      "[486, 487, 488, 489, 490, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514]\n"
     ]
    }
   ],
   "source": [
    "# Examine data indices after cleaning (may have gaps due to removed classes)\n",
    "print(\"Data indices after cleaning (sample from middle range):\")\n",
    "print(dataset.data_indices[480:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the cleaned dataset - stratification will work properly now\n",
    "split_dict = dataset.split(split_mode=\"stratified\", test_size=0.2)\n",
    "train_set = split_dict[\"train_set\"]\n",
    "test_set = split_dict[\"test_set\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are training indices a subset of cleaned dataset? True\n"
     ]
    }
   ],
   "source": [
    "# Verify that training indices are a subset of the cleaned dataset indices\n",
    "is_train_subset = set(train_set.data_indices).issubset(dataset.data_indices)\n",
    "print(f\"Are training indices a subset of cleaned dataset? {is_train_subset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are test indices a subset of cleaned dataset? True\n"
     ]
    }
   ],
   "source": [
    "# Verify that test indices are also a subset of the cleaned dataset indices\n",
    "is_test_subset = set(test_set.data_indices).issubset(dataset.data_indices)\n",
    "print(f\"Are test indices a subset of cleaned dataset? {is_test_subset}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Handling Very Small Datasets\n",
    "\n",
    "When working with very small datasets, sampling can be challenging. Let's see how `TabularDataset` handles edge cases with minimal data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Very small dataset after sampling:\n",
      "============================DATA INFO============================\n",
      "Dataset: soybean\n",
      "Task type: classification\n",
      "Status (is_tensor): False\n",
      "Number of samples: 19\n",
      "Number of features: 35 (Numerical: 0, Categorical: 35)\n",
      "Number of classes: 19\n",
      "Class distribution: {'2-4-d-injury': 0.05263157894736842, 'alternarialeaf-spot': 0.05263157894736842, 'anthracnose': 0.05263157894736842, 'bacterial-blight': 0.05263157894736842, 'bacterial-pustule': 0.05263157894736842, 'brown-spot': 0.05263157894736842, 'brown-stem-rot': 0.05263157894736842, 'charcoal-rot': 0.05263157894736842, 'cyst-nematode': 0.05263157894736842, 'diaporthe-pod-&-stem-blight': 0.05263157894736842, 'diaporthe-stem-canker': 0.05263157894736842, 'downy-mildew': 0.05263157894736842, 'frog-eye-leaf-spot': 0.05263157894736842, 'herbicide-injury': 0.05263157894736842, 'phyllosticta-leaf-spot': 0.05263157894736842, 'phytophthora-rot': 0.05263157894736842, 'powdery-mildew': 0.05263157894736842, 'purple-seed-stain': 0.05263157894736842, 'rhizoctonia-root-rot': 0.05263157894736842}\n",
      "=================================================================\n",
      "\n",
      "This demonstrates that TabularDataset can handle very small samples\n",
      "while maintaining stratification as much as possible.\n"
     ]
    }
   ],
   "source": [
    "# Load a small dataset and create a very small sample\n",
    "data = TabularDataset(\n",
    "    dataset_name=\"soybean\",\n",
    "    task_type=\"classification\",\n",
    ")\n",
    "\n",
    "# Sample only 19 instances - this tests edge case handling\n",
    "data_small = data.sample(sample_mode=\"stratified\", sample_size=19)[\"dataset_sampled\"]\n",
    "print(\"Very small dataset after sampling:\")\n",
    "print(data_small)\n",
    "print(f\"\\nThis demonstrates that TabularDataset can handle very small samples\")\n",
    "print(f\"while maintaining stratification as much as possible.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary and Best Practices\n",
    "\n",
    "Congratulations! You've learned how to use the `TabularDataset` class effectively. Here's a summary of key concepts:\n",
    "\n",
    "### Key Features Covered:\n",
    "- **Dataset Loading**: Automatic download and preparation of OpenML datasets\n",
    "- **Task Types**: Support for both classification and regression tasks\n",
    "- **Sampling Methods**: Stratified and uniform sampling with consistent seeding\n",
    "- **Splitting Options**: Flexible train-test splitting with stratification\n",
    "- **Operation Chaining**: Combining sampling, splitting, and cleaning operations\n",
    "\n",
    "### Best Practices:\n",
    "1. **Use Stratified Methods**: Always use `sample_mode=\"stratified\"` and `split_mode=\"stratified\"` for classification tasks to maintain class balance\n",
    "2. **Clean Before Splitting**: Remove problematic classes or samples before splitting to ensure reliable stratification\n",
    "3. **Understand Index Tracking**: The `data_indices` attribute tracks which samples from the original dataset are included\n",
    "4. **Progressive Sampling**: Smaller samples are subsets of larger samples when using the same seed\n",
    "5. **Handle Edge Cases**: The library gracefully handles very small datasets and edge cases\n",
    "\n",
    "### Next Steps:\n",
    "- Explore other TabCamel modules for data transformation and feature engineering\n",
    "- Experiment with different OpenML datasets for your specific use cases\n",
    "- Integrate `TabularDataset` into your machine learning pipelines\n",
    "\n",
    "Happy machine learning with TabCamel! 🐪"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
