# {{ config.project_name }}

{{ config.description }}

This MCP (Model Context Protocol) server was generated by `mcp-forge` and provides a modern implementation following the latest MCP specifications (2025-03-26).

## Features

- âœ… **Modern Transports**: {% if config.transport == "both" %}Both stdio and Streamable HTTP{% elif config.transport == "http" %}Streamable HTTP{% else %}stdio{% endif %} transport support
- ðŸ› ï¸ **Tools**: Execute actions with validated inputs and outputs
- ðŸ“¦ **Resources**: Serve static and dynamic content
{% if config.with_prompts -%}
- ðŸ’¬ **Prompts**: Reusable message templates for LLM interactions
{% endif -%}
{% if config.with_sampling -%}
- ðŸ¤– **Sampling**: AI-to-AI collaboration support
{% endif -%}
- ðŸš€ **FastMCP 2.0**: Built on the standard Python MCP framework

## Project Structure

```
{{ config.project_name }}/
â”œâ”€â”€ {{ config.package_name }}/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ server.py                # Unified server with transport selection
{% if config.transport in ["stdio", "both"] -%}
â”‚   â”œâ”€â”€ server_stdio.py          # stdio transport implementation
{% endif -%}
{% if config.transport in ["http", "both"] -%}
â”‚   â”œâ”€â”€ server_http.py           # Streamable HTTP transport
{% endif -%}
â”‚   â”œâ”€â”€ interfaces/
â”‚   â”‚   â”œâ”€â”€ tool.py              # Tool base interface
â”‚   â”‚   â”œâ”€â”€ resource.py          # Resource base interface
{% if config.with_prompts -%}
â”‚   â”‚   â””â”€â”€ prompt.py            # Prompt base interface
{% endif -%}
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ tool_service.py      # Tool management
â”‚   â”‚   â”œâ”€â”€ resource_service.py  # Resource management
{% if config.with_prompts -%}
â”‚   â”‚   â””â”€â”€ prompt_service.py    # Prompt management
{% endif -%}
â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â”œâ”€â”€ add_numbers.py       # Example: Math tool
â”‚   â”‚   â”œâ”€â”€ date_difference.py   # Example: Date tool
â”‚   â”‚   â””â”€â”€ ...                  # More example tools
â”‚   â”œâ”€â”€ resources/
â”‚   â”‚   â”œâ”€â”€ hello_world.py       # Static resource example
â”‚   â”‚   â””â”€â”€ user_profile.py      # Dynamic resource example
{% if config.with_prompts -%}
â”‚   â””â”€â”€ prompts/
â”‚       â”œâ”€â”€ code_review.py       # Code review prompt
â”‚       â”œâ”€â”€ data_analysis.py     # Data analysis prompt
â”‚       â””â”€â”€ debug_assistant.py   # Debug assistant prompt
{% endif -%}
â”œâ”€â”€ pyproject.toml               # Project dependencies
â””â”€â”€ README.md                    # This file
```

## Setup

This project uses `uv` for fast, reliable dependency management.

```bash
# Navigate to project
cd {{ config.project_name }}

# Create virtual environment and install
uv venv
uv pip install -e .
```

## Running the Server

### Unified Entry Point (Recommended)

```bash
# Run with stdio transport (for Claude Desktop, Cursor, etc.)
python -m {{ config.package_name }}.server --transport stdio

# Run with HTTP transport (for web deployments)
python -m {{ config.package_name }}.server --transport http

# Run with HTTP in development mode (auto-reload)
python -m {{ config.package_name }}.server --transport http --reload

# Custom host/port for HTTP
python -m {{ config.package_name }}.server --transport http --host 0.0.0.0 --port 8080
```

{% if config.transport in ["stdio", "both"] -%}
### Direct stdio Transport

```bash
python -m {{ config.package_name }}.server_stdio
```
{% endif %}

{% if config.transport in ["http", "both"] -%}
### Direct HTTP Transport

```bash
# Default: http://127.0.0.1:8000/mcp
python -m {{ config.package_name }}.server_http

# Custom configuration
python -m {{ config.package_name }}.server_http --host 0.0.0.0 --port 8080 --reload
```

The Streamable HTTP transport provides:
- Single `/mcp` endpoint for all operations
- Session management with secure IDs
- Bi-directional communication
- Compatible with web deployments
{% endif %}

## Development Guide

### Adding Tools

1. Create a new file in `{{ config.package_name }}/tools/`
2. Inherit from `Tool` interface
3. Define input model with Pydantic
4. Implement `execute` method
5. Register in `server.py`'s `get_available_tools()`

Example:
```python
from {{ config.package_name }}.interfaces.tool import Tool, ToolResponse, BaseToolInput
from pydantic import Field

class MyToolInput(BaseToolInput):
    param: str = Field(description="Tool parameter")

class MyTool(Tool):
    name = "my_tool"
    description = "Does something useful"
    input_model = MyToolInput
    
    async def execute(self, input_data: MyToolInput) -> ToolResponse:
        # Tool logic here
        return ToolResponse(...)
```

### Adding Resources

1. Create a new file in `{{ config.package_name }}/resources/`
2. Inherit from `Resource` interface
3. Define URI pattern (static or dynamic)
4. Implement `read` method
5. Register in `server.py`'s `get_available_resources()`

Example:
```python
from {{ config.package_name }}.interfaces.resource import Resource, ResourceResponse

class MyResource(Resource):
    name = "my_resource"
    description = "Serves content"
    uri = "resource://data/{id}"  # Dynamic URI
    mime_type = "application/json"
    
    async def read(self, id: str) -> ResourceResponse:
        # Resource logic here
        return ResourceResponse(...)
```

{% if config.with_prompts -%}
### Adding Prompts

1. Create a new file in `{{ config.package_name }}/prompts/`
2. Inherit from `Prompt` interface
3. Define arguments and generation logic
4. Register in `server.py`'s `get_available_prompts()`

Example:
```python
from {{ config.package_name }}.interfaces.prompt import Prompt, PromptMessage, PromptArgument

class MyPrompt(Prompt):
    @property
    def name(self) -> str:
        return "my_prompt"
    
    @property
    def description(self) -> str:
        return "Generates helpful prompts"
    
    async def generate(self, **kwargs) -> List[PromptMessage]:
        return [
            PromptMessage(role="user", content="..."),
            PromptMessage(role="assistant", content="...")
        ]
```
{% endif %}

## Testing Your Server

### With Claude Desktop

1. Add to Claude Desktop config:
```json
{
  "mcpServers": {
    "{{ config.project_name }}": {
      "command": "python",
      "args": ["-m", "{{ config.package_name }}.server", "--transport", "stdio"]
    }
  }
}
```

2. Restart Claude Desktop

### With HTTP Client

```bash
# Start server
python -m {{ config.package_name }}.server --transport http

# Test with curl
curl -X POST http://localhost:8000/mcp \
  -H "Content-Type: application/json" \
  -d '{"jsonrpc": "2.0", "method": "initialize", "params": {}, "id": 1}'
```

## Configuration

{% if config.with_sampling -%}
### Sampling Support

This server has sampling capability enabled, allowing it to request completions from LLMs through the client. This enables sophisticated AI-to-AI collaboration patterns.
{% endif %}

### Environment Variables

- `MCP_LOG_LEVEL`: Set logging level (DEBUG, INFO, WARNING, ERROR)
- `MCP_HOST`: Override default host for HTTP transport
- `MCP_PORT`: Override default port for HTTP transport

## Resources

- [MCP Specification](https://modelcontextprotocol.io/specification)
- [FastMCP Documentation](https://gofastmcp.com)
- [MCP TypeScript SDK](https://github.com/modelcontextprotocol/typescript-sdk)
- [MCP Python SDK](https://github.com/modelcontextprotocol/python-sdk)

## License

This project was generated with mcp-forge. Add your license here.