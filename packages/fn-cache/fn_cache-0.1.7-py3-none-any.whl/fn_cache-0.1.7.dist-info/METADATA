Metadata-Version: 2.4
Name: fn-cache
Version: 0.1.7
Summary: è½»é‡çº§é€šç”¨ç¼“å­˜åº“
Home-page: https://github.com/leowzz/fn_cache
Author: LeoWang
Author-email: LeoWang <leolswq@163.com>
Maintainer-email: LeoWang <leolswq@163.com>
License: MIT
Project-URL: Homepage, https://github.com/leowzz/fn_cache
Project-URL: Documentation, https://fn-cache.readthedocs.io/
Project-URL: Repository, https://github.com/leowzz/fn_cache
Project-URL: Bug Tracker, https://github.com/leowzz/fn_cache/issues
Keywords: cache,memory,ttl,lru,async,decorator
Classifier: Development Status :: 5 - Production/Stable
Classifier: Intended Audience :: Developers
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: Topic :: System :: Distributed Computing
Classifier: Topic :: Database :: Database Engines/Servers
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: typing-extensions>=4.0.0; python_version < "3.9"
Requires-Dist: pydantic<2.12,>2.10
Requires-Dist: fastapi<0.116.0,>0.100.0
Requires-Dist: loguru~=0.7.3
Provides-Extra: dev
Requires-Dist: pytest>=7.0.0; extra == "dev"
Requires-Dist: pytest-asyncio>=0.21.0; extra == "dev"
Requires-Dist: pytest-cov>=4.0.0; extra == "dev"
Requires-Dist: black>=23.0.0; extra == "dev"
Requires-Dist: isort>=5.12.0; extra == "dev"
Requires-Dist: flake8>=6.0.0; extra == "dev"
Requires-Dist: mypy>=1.0.0; extra == "dev"
Provides-Extra: docs
Requires-Dist: sphinx>=6.0.0; extra == "docs"
Requires-Dist: sphinx-rtd-theme>=1.2.0; extra == "docs"
Requires-Dist: myst-parser>=1.0.0; extra == "docs"
Dynamic: author
Dynamic: home-page
Dynamic: license-file
Dynamic: requires-python

# fn_cache: è½»é‡çº§å‡½æ•°ç¼“å­˜å·¥å…·

`fn_cache` æ˜¯ä¸€ä¸ªä¸“ä¸ºç°ä»£ Python åº”ç”¨è®¾è®¡çš„è½»é‡çº§ç¼“å­˜åº“ï¼Œæä¾›ç»Ÿä¸€çš„æ¥å£ã€å¤šç§ç¼“å­˜ç­–ç•¥å’Œå­˜å‚¨åç«¯ã€‚æ— è®ºæ‚¨éœ€è¦ç®€å•çš„å†…å­˜ç¼“å­˜è¿˜æ˜¯åˆ†å¸ƒå¼ Redis ç¼“å­˜ï¼Œ`fn_cache` éƒ½èƒ½è½»æ¾åº”å¯¹ã€‚

## âœ¨ æ ¸å¿ƒç‰¹æ€§

- **å¤šç§ç¼“å­˜ç­–ç•¥**: æ”¯æŒ TTL (Time-To-Live) å’Œ LRU (Least Recently Used) ç¼“å­˜æ·˜æ±°ç­–ç•¥. æ”¯æŒå¼‚æ­¥å‡½æ•°çš„ LRU ç¼“å­˜ï¼ˆasync lru_cacheï¼‰ï¼Œè®©å¼‚æ­¥åœºæ™¯ä¸‹ä¹Ÿèƒ½é«˜æ•ˆåˆ©ç”¨ LRU ç­–ç•¥
- **çµæ´»çš„å­˜å‚¨åç«¯**: å†…ç½®å†…å­˜å’Œ Redis ä¸¤ç§å­˜å‚¨åç«¯ï¼Œå¯æ ¹æ®éœ€æ±‚è½»æ¾åˆ‡æ¢
- **å¤šç§åºåˆ—åŒ–æ ¼å¼**: æ”¯æŒ JSONã€Pickleã€MessagePack å’Œå­—ç¬¦ä¸²åºåˆ—åŒ–
- **ç‰ˆæœ¬æ§åˆ¶æœºåˆ¶**: é€šè¿‡å…¨å±€ç‰ˆæœ¬å·å®ç°ä¸€é”®å¤±æ•ˆæ‰€æœ‰ç¼“å­˜ï¼Œä¾¿äºè°ƒè¯•å’Œç®¡ç†
- **ç”¨æˆ·çº§åˆ«ç‰ˆæœ¬æ§åˆ¶**: æ”¯æŒæŒ‰ç”¨æˆ·å¤±æ•ˆç¼“å­˜ï¼Œé€‚ç”¨äºå¤šç”¨æˆ·åº”ç”¨åœºæ™¯
- **ç¼“å­˜é”®æšä¸¾**: æ”¯æŒå®šä¹‰ç»“æ„åŒ–çš„ç¼“å­˜é”®æ¨¡æ¿ï¼Œæé«˜ä»£ç å¯ç»´æŠ¤æ€§
- **åŠ¨æ€è¿‡æœŸæ—¶é—´**: æ”¯æŒæ ¹æ®ç¼“å­˜å€¼åŠ¨æ€è®¡ç®—è¿‡æœŸæ—¶é—´
- **å¼ºå¤§çš„è£…é¥°å™¨**: æä¾› `cached` è£…é¥°å™¨ï¼Œæ”¯æŒä¸°å¯Œçš„é…ç½®ï¼Œå¹¶ä¸åŒæ­¥/å¼‚æ­¥å‡½æ•°æ— ç¼é›†æˆ
- **ç¼“å­˜é¢„åŠ è½½**: æ”¯æŒåœ¨æœåŠ¡å¯åŠ¨æ—¶é¢„å…ˆåŠ è½½æ•°æ®åˆ°å†…å­˜ç¼“å­˜ï¼Œæå‡åº”ç”¨åˆå§‹æ€§èƒ½
- **ç¼“å­˜ç»Ÿè®¡**: æä¾›è¯¦ç»†çš„ç¼“å­˜æ€§èƒ½ç›‘æ§ï¼ŒåŒ…æ‹¬å‘½ä¸­ç‡ã€å“åº”æ—¶é—´ç­‰æŒ‡æ ‡
- **å†…å­˜ç›‘æ§**: æ”¯æŒå†…å­˜å ç”¨ç›‘æ§å’Œå®šæœŸæŠ¥å‘Š
- **å¥å£®çš„é”™è¯¯å¤„ç†**: å†…ç½® Redis è¶…æ—¶å’Œè¿æ¥é”™è¯¯å¤„ç†ï¼Œç¡®ä¿ç¼“å­˜é—®é¢˜ä¸å½±å“æ ¸å¿ƒä¸šåŠ¡é€»è¾‘

## ğŸš€ å¿«é€Ÿä¸Šæ‰‹

### 1. åŸºæœ¬ç”¨æ³•: `cached` è£…é¥°å™¨

ä½¿ç”¨ `cached` è£…é¥°å™¨ï¼Œå¯ä»¥è½»æ¾ä¸ºå‡½æ•°æ·»åŠ ç¼“å­˜åŠŸèƒ½ã€‚

```python
from fn_cache import cached, SerializerType


# ä½¿ç”¨å†…å­˜TTLç¼“å­˜ (é»˜è®¤)
@cached(ttl_seconds=60)
def get_some_data(user_id: int):
    print("æ­£åœ¨æ‰§è¡Œå¤æ‚çš„æ•°æ®æŸ¥è¯¢...")
    return f"è¿™æ˜¯ç”¨æˆ· {user_id} çš„æ•°æ®"


# ä½¿ç”¨ä¸åŒåºåˆ—åŒ–å™¨
@cached(
    storage_type='memory',
    serializer_type=SerializerType.JSON,
    ttl_seconds=300
)
def get_user_profile(user_id: int):
    return {"user_id": user_id, "name": f"ç”¨æˆ·_{user_id}"}


# ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼Œå‡½æ•°ä¼šæ‰§è¡Œ
get_some_data(123)  # è¾“å‡º: "æ­£åœ¨æ‰§è¡Œå¤æ‚çš„æ•°æ®æŸ¥è¯¢..."

# ç¬¬äºŒæ¬¡è°ƒç”¨ï¼Œç›´æ¥ä»ç¼“å­˜è¿”å›
get_some_data(123)  # æ— è¾“å‡º
```

### 2. å¼‚æ­¥å‡½æ•°æ”¯æŒ

```python
@cached(ttl_seconds=300)
async def fetch_user_data(user_id: int):
    print(f"æ­£åœ¨ä»æ•°æ®åº“è·å–ç”¨æˆ· {user_id} çš„æ•°æ®...")
    await asyncio.sleep(1)  # æ¨¡æ‹Ÿæ•°æ®åº“æŸ¥è¯¢å»¶è¿Ÿ
    return {
        "user_id": user_id,
        "name": f"User_{user_id}",
        "email": f"user{user_id}@example.com"
    }
```

### 3. ç¼“å­˜é¢„åŠ è½½

å¯¹äºéœ€è¦å¿«é€Ÿå“åº”çš„å†…å­˜ç¼“å­˜æ•°æ®ï¼Œå¯ä»¥ä½¿ç”¨é¢„åŠ è½½åŠŸèƒ½ï¼Œåœ¨æœåŠ¡å¯åŠ¨æ—¶å°±å°†çƒ­ç‚¹æ•°æ®åŠ è½½åˆ°ç¼“å­˜ä¸­ã€‚

```python
from fn_cache import cached, preload_all_caches
import asyncio


# 1. å®šä¹‰ä¸€ä¸ªæ•°æ®æä¾›è€…å‡½æ•°
def user_ids_provider():
    # è¿™äº›IDå¯ä»¥æ˜¯æ¥è‡ªé…ç½®ã€æ•°æ®åº“æˆ–å…¶ä»–æ¥æº
    for user_id in [1, 2, 3]:
        yield (user_id,), {}  # (args, kwargs)


# 2. åœ¨è£…é¥°å™¨ä¸­æŒ‡å®š preload_provider
@cached(storage_type='memory', preload_provider=user_ids_provider)
def get_user_name(user_id: int):
    print(f"ä»æ•°æ®åº“æŸ¥è¯¢ç”¨æˆ· {user_id}...")
    return f"ç”¨æˆ·_{user_id}"


# 3. åœ¨åº”ç”¨å¯åŠ¨æ—¶ï¼Œè°ƒç”¨é¢„åŠ è½½å‡½æ•°
async def main():
    await preload_all_caches()

    # æ­¤æ—¶ï¼Œæ•°æ®å·²åœ¨ç¼“å­˜ä¸­ï¼Œå‡½æ•°ä¸ä¼šå†æ¬¡æ‰§è¡Œ
    print(get_user_name(1))  # ç›´æ¥è¾“å‡º "ç”¨æˆ·_1"
    print(get_user_name(2))  # ç›´æ¥è¾“å‡º "ç”¨æˆ·_2"


if __name__ == "__main__":
    asyncio.run(main())
```

### 4. ç¼“å­˜ç»Ÿè®¡å’Œç›‘æ§

```python
from fn_cache import get_cache_statistics, start_cache_memory_monitoring

# å¯åŠ¨å†…å­˜ç›‘æ§
start_cache_memory_monitoring(interval_seconds=300)  # æ¯5åˆ†é’Ÿç›‘æ§ä¸€æ¬¡

# è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
stats = get_cache_statistics()
for cache_id, cache_stats in stats.items():
    print(f"ç¼“å­˜ {cache_id}:")
    print(f"  å‘½ä¸­ç‡: {cache_stats['hit_rate']:.2%}")
    print(f"  å¹³å‡å“åº”æ—¶é—´: {cache_stats['avg_response_time']:.4f}s")
```

## ğŸ“š API å‚è€ƒ

### `cached` è£…é¥°å™¨ç±»

è¿™æ˜¯ `fn_cache` çš„æ ¸å¿ƒè£…é¥°å™¨ã€‚

**å‚æ•°**:

- `cache_type` (`CacheType`): ç¼“å­˜ç±»å‹ï¼Œ`CacheType.TTL` (é»˜è®¤) æˆ– `CacheType.LRU`
- `storage_type` (`StorageType`): å­˜å‚¨ç±»å‹ï¼Œ`StorageType.MEMORY` (é»˜è®¤) æˆ– `StorageType.REDIS`
- `serializer_type` (`SerializerType`): åºåˆ—åŒ–ç±»å‹ï¼Œ`SerializerType.JSON` (é»˜è®¤)ã€`SerializerType.PICKLE`ã€`SerializerType.MESSAGEPACK` æˆ– `SerializerType.STRING`
- `ttl_seconds` (`int`): TTL ç¼“å­˜çš„è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ä¸º 600
- `max_size` (`int`): LRU ç¼“å­˜çš„æœ€å¤§å®¹é‡ï¼Œé»˜è®¤ä¸º 1000
- `key_func` (`Callable`): è‡ªå®šä¹‰ç¼“å­˜é”®ç”Ÿæˆå‡½æ•°ã€‚æ¥æ”¶ä¸è¢«è£…é¥°å‡½æ•°ç›¸åŒçš„å‚æ•°
- `key_params` (`list[str]`): ç”¨äºè‡ªåŠ¨ç”Ÿæˆç¼“å­˜é”®çš„å‚æ•°ååˆ—è¡¨
- `prefix` (`str`): ç¼“å­˜é”®çš„å‰ç¼€ï¼Œé»˜è®¤ä¸º `"fn_cache:"`
- `preload_provider` (`Callable`): ä¸€ä¸ªå‡½æ•°ï¼Œè¿”å›ä¸€ä¸ªå¯è¿­ä»£å¯¹è±¡ï¼Œç”¨äºç¼“å­˜é¢„åŠ è½½ã€‚è¿­ä»£çš„æ¯ä¸ªå…ƒç´ éƒ½æ˜¯ä¸€ä¸ª `(args, kwargs)` å…ƒç»„

### `CacheKeyEnum` åŸºç±»

ç¼“å­˜é”®æšä¸¾åŸºç±»ï¼Œç”¨äºå®šä¹‰ç»“æ„åŒ–çš„ç¼“å­˜é”®æ¨¡æ¿ã€‚

```python
class CacheKeyEnum(str, Enum):
    """ç¼“å­˜é”®æšä¸¾åŸºç±»"""
    
    def format(self, **kwargs) -> str:
        """æ ¼å¼åŒ–ç¼“å­˜é”®ï¼Œæ›¿æ¢æ¨¡æ¿ä¸­çš„å‚æ•°"""
        return self.value.format(**kwargs)
```

### `UniversalCacheManager` ç±»

æä¾›äº†æ‰€æœ‰åº•å±‚ç¼“å­˜æ“ä½œçš„æ¥å£ã€‚

**æ ¸å¿ƒæ–¹æ³•**:

- `get(key, user_id=None)`: (å¼‚æ­¥) è·å–ç¼“å­˜
- `set(key, value, ttl_seconds=None, user_id=None)`: (å¼‚æ­¥) è®¾ç½®ç¼“å­˜
- `delete(key)`: (å¼‚æ­¥) åˆ é™¤ç¼“å­˜
- `get_sync(key, user_id=None)` / `set_sync(...)` / `delete_sync(key)`: å†…å­˜ç¼“å­˜çš„åŒæ­¥ç‰ˆæœ¬
- `increment_global_version()`: (å¼‚æ­¥) é€’å¢å…¨å±€ç‰ˆæœ¬å·ï¼Œä½¿æ‰€æœ‰ç¼“å­˜å¤±æ•ˆ
- `increment_user_version(user_id)`: (å¼‚æ­¥) é€’å¢ç”¨æˆ·ç‰ˆæœ¬å·ï¼Œä½¿è¯¥ç”¨æˆ·çš„æ‰€æœ‰ç¼“å­˜å¤±æ•ˆ
- `invalidate_all()`: (å¼‚æ­¥) ä½¿æ‰€æœ‰ç¼“å­˜å¤±æ•ˆ
- `invalidate_user_cache(user_id)`: (å¼‚æ­¥) ä½¿ç”¨æˆ·çš„æ‰€æœ‰ç¼“å­˜å¤±æ•ˆ

**æ ¸å¿ƒå±æ€§**:

- `is_global_cache_enabled_sync` (`bool`): (åŒæ­¥) æ£€æŸ¥å†…å­˜ç¼“å­˜æ˜¯å¦å·²å¯ç”¨

### å…¨å±€æ§åˆ¶å‡½æ•°

- `preload_all_caches()`: (å¼‚æ­¥) æ‰§è¡Œæ‰€æœ‰å·²æ³¨å†Œçš„ç¼“å­˜é¢„åŠ è½½ä»»åŠ¡
- `invalidate_all_caches()`: (å¼‚æ­¥) å¤±æ•ˆæ‰€æœ‰ä½¿ç”¨é»˜è®¤ç®¡ç†å™¨çš„ç¼“å­˜
- `invalidate_user_cache(user_id)`: (å¼‚æ­¥) ä½¿ç”¨æˆ·çš„æ‰€æœ‰ç¼“å­˜å¤±æ•ˆ
- `get_cache_statistics(cache_id=None)`: è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
- `reset_cache_statistics(cache_id=None)`: é‡ç½®ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
- `start_cache_memory_monitoring(interval_seconds=300)`: å¯åŠ¨å†…å­˜ç›‘æ§
- `get_cache_memory_usage()`: è·å–å†…å­˜ä½¿ç”¨æƒ…å†µ

## âš™ï¸ é«˜çº§ç”¨æ³•

### åˆ‡æ¢åˆ° Redis å­˜å‚¨

åªéœ€æ›´æ”¹ `storage_type` å‚æ•°å³å¯ã€‚

```python
@cached(
    storage_type=StorageType.REDIS, 
    serializer_type=SerializerType.MESSAGEPACK,
    ttl_seconds=3600
)
async def get_shared_data():
    # ... ä»æ•°æ®åº“æˆ–RPCè·å–æ•°æ® ...
    return {"data": "some shared data"}
```

### ä½¿ç”¨ LRU ç¼“å­˜ç­–ç•¥

```python
@cached(
    cache_type=CacheType.LRU,
    max_size=100,
    storage_type=StorageType.MEMORY
)
def calculate_fibonacci(n: int) -> int:
    """è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—ï¼ˆåŒæ­¥å‡½æ•°ç¤ºä¾‹ï¼‰"""
    if n <= 1:
        return n
    return calculate_fibonacci(n-1) + calculate_fibonacci(n-2)
```

### è‡ªå®šä¹‰ç¼“å­˜é”®

å¯¹äºå¤æ‚çš„å‚æ•°ï¼Œå¯ä»¥æä¾›è‡ªå®šä¹‰çš„ `key_func`ã€‚

```python
def make_user_key(user: User):
    return f"user_cache:{user.org_id}:{user.id}"

@cached(key_func=make_user_key)
def get_user_permissions(user: User):
    # ...
    return ["perm1", "perm2"]
```

æˆ–è€…ï¼Œä½¿ç”¨ `key_params` è‡ªåŠ¨ç”Ÿæˆã€‚

```python
@cached(key_params=['user_id', 'tenant_id'])
def get_document(doc_id: int, user_id: int, tenant_id: str):
    # è‡ªåŠ¨ç”Ÿæˆçš„keyç±»ä¼¼äº: "app.module.get_document:user_id=123:tenant_id=abc"
    pass
```

### ç”¨æˆ·çº§åˆ«ç¼“å­˜ç®¡ç†

```python
from fn_cache import UniversalCacheManager, CacheConfig, StorageType


class UserCacheService:
    def __init__(self):
        config = CacheConfig(
            storage_type=StorageType.REDIS,
            serializer_type=SerializerType.JSON,
            prefix="user_cache:"
        )
        self.cache = UniversalCacheManager(config)

    async def get_user_data(self, user_id: int):
        cache_key = f"user_data:{user_id}"

        # ä½¿ç”¨ç”¨æˆ·çº§åˆ«ç‰ˆæœ¬æ§åˆ¶
        cached_data = await self.cache.get(cache_key, user_id=str(user_id))
        if cached_data:
            return cached_data

        # ç¼“å­˜æœªå‘½ä¸­ï¼Œè·å–æ•°æ®
        user_data = await self._fetch_user_data(user_id)

        # å­˜å‚¨åˆ°ç¼“å­˜ï¼Œä½¿ç”¨ç”¨æˆ·çº§åˆ«ç‰ˆæœ¬æ§åˆ¶
        await self.cache.set(cache_key, user_data, user_id=str(user_id))
        return user_data

    async def invalidate_user_cache(self, user_id: int):
        """ä½¿ç”¨æˆ·çš„æ‰€æœ‰ç¼“å­˜å¤±æ•ˆ"""
        await self.cache.invalidate_user_cache(str(user_id))
```

### åŠ¨æ€è¿‡æœŸæ—¶é—´

```python
@cached(
    ttl_seconds=300
)
async def get_user_vip_info(user_id: int):
    # VIPç”¨æˆ·ç¼“å­˜1å°æ—¶ï¼Œæ™®é€šç”¨æˆ·ç¼“å­˜30åˆ†é’Ÿ
    pass
```

### å¤šå‚æ•°ç¼“å­˜é”®

```python
@cached(
    ttl_seconds=300
)
async def get_user_profile(user_id: int, tenant_id: str):
    # æ”¯æŒå¤šç§Ÿæˆ·çš„ç”¨æˆ·èµ„æ–™ç¼“å­˜
    pass
```

## ğŸ”§ é…ç½®é€‰é¡¹

### CacheConfig é…ç½®ç±»

```python
from fn_cache import CacheConfig, CacheType, StorageType, SerializerType

config = CacheConfig(
    cache_type=CacheType.TTL,  # ç¼“å­˜ç­–ç•¥: TTL æˆ– LRU
    storage_type=StorageType.MEMORY,  # å­˜å‚¨åç«¯: MEMORY æˆ– REDIS
    serializer_type=SerializerType.JSON,  # åºåˆ—åŒ–ç±»å‹: JSON, PICKLE, MESSAGEPACK, STRING
    ttl_seconds=600,  # TTL è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
    max_size=1000,  # LRU æœ€å¤§å®¹é‡
    prefix="cache:",  # ç¼“å­˜é”®å‰ç¼€
    global_version_key="fn_cache:global:version",  # å…¨å±€ç‰ˆæœ¬å·é”®
    user_version_key="fn_cache:user:version:{user_id}",  # ç”¨æˆ·ç‰ˆæœ¬å·é”®
    make_expire_sec_func=None,  # åŠ¨æ€è¿‡æœŸæ—¶é—´å‡½æ•°
    serializer_kwargs={},  # åºåˆ—åŒ–å™¨å‚æ•°
    enable_statistics=True,  # æ˜¯å¦å¯ç”¨ç»Ÿè®¡
    enable_memory_monitoring=True,  # æ˜¯å¦å¯ç”¨å†…å­˜ç›‘æ§
    redis_config={  # Redisè¿æ¥é…ç½®
        "host": "localhost",
        "port": 6379,
        "db": 0,
        "decode_responses": True,
        "socket_timeout": 1.0,
        "socket_connect_timeout": 1.0,
        "retry_on_timeout": True,
        "health_check_interval": 30,
    }
)
```

## ğŸ’¡ è®¾è®¡ç†å¿µ

- **ç»Ÿä¸€æ¥å£**: `UniversalCacheManager` æä¾›äº†ç»Ÿä¸€çš„æ¥å£ï¼Œå±è”½äº†ä¸åŒå­˜å‚¨åç«¯çš„å®ç°ç»†èŠ‚
- **ç‰ˆæœ¬æ§åˆ¶**: é€šè¿‡å…¨å±€ç‰ˆæœ¬å·æœºåˆ¶å®ç°ä¸€é”®å¤±æ•ˆæ‰€æœ‰ç¼“å­˜ï¼Œä¾¿äºè°ƒè¯•å’Œç®¡ç†
- **ç”¨æˆ·çº§åˆ«æ§åˆ¶**: æ”¯æŒæŒ‰ç”¨æˆ·å¤±æ•ˆç¼“å­˜ï¼Œé€‚ç”¨äºå¤šç”¨æˆ·åº”ç”¨åœºæ™¯
- **ç»“æ„åŒ–ç¼“å­˜é”®**: é€šè¿‡æšä¸¾å®šä¹‰ç¼“å­˜é”®æ¨¡æ¿ï¼Œæé«˜ä»£ç å¯ç»´æŠ¤æ€§å’Œä¸€è‡´æ€§
- **è£…é¥°å™¨æ¨¡å¼**: `cached` ä½¿ç”¨è£…é¥°å™¨æ¨¡å¼ï¼Œä»¥éä¾µå…¥çš„æ–¹å¼ä¸ºå‡½æ•°æ·»åŠ ç¼“å­˜é€»è¾‘
- **é”™è¯¯éš”ç¦»**: å†…ç½® Redis è¶…æ—¶å’Œè¿æ¥é”™è¯¯å¤„ç†ï¼Œç¡®ä¿ç¼“å­˜é—®é¢˜ä¸å½±å“æ ¸å¿ƒä¸šåŠ¡é€»è¾‘
- **æ€§èƒ½ä¼˜åŒ–**: æ”¯æŒç¼“å­˜é¢„åŠ è½½å’ŒåŠ¨æ€è¿‡æœŸæ—¶é—´ï¼Œæå‡åº”ç”¨æ€§èƒ½
- **ç›‘æ§ç»Ÿè®¡**: æä¾›è¯¦ç»†çš„ç¼“å­˜æ€§èƒ½ç›‘æ§ï¼Œå¸®åŠ©ä¼˜åŒ–ç¼“å­˜ç­–ç•¥

## ğŸ“ ä½¿ç”¨ç¤ºä¾‹

æ›´å¤šè¯¦ç»†çš„ä½¿ç”¨ç¤ºä¾‹ï¼Œè¯·å‚è€ƒ `examples_v2.py` æ–‡ä»¶ï¼Œå…¶ä¸­åŒ…å«äº†ï¼š

- ä¸åŒåºåˆ—åŒ–å™¨çš„ä½¿ç”¨
- ç¼“å­˜ç»Ÿè®¡å’Œæ€§èƒ½ç›‘æ§
- å†…å­˜ç›‘æ§åŠŸèƒ½
- æ‰¹é‡æ“ä½œå’Œç¼“å­˜é¢„çƒ­
- ç”¨æˆ·çº§åˆ«ç‰ˆæœ¬æ§åˆ¶
- ç›´æ¥ä½¿ç”¨ç¼“å­˜ç®¡ç†å™¨

## ğŸ”„ v2.0 æ–°ç‰¹æ€§

ç›¸æ¯” v1.0ï¼Œv2.0 ç‰ˆæœ¬æ–°å¢äº†ä»¥ä¸‹ç‰¹æ€§ï¼š

1. **å¤šç§åºåˆ—åŒ–æ ¼å¼æ”¯æŒ**: æ”¯æŒ JSONã€Pickleã€MessagePack å’Œå­—ç¬¦ä¸²åºåˆ—åŒ–
2. **ç¼“å­˜ç»Ÿè®¡åŠŸèƒ½**: æä¾›è¯¦ç»†çš„ç¼“å­˜æ€§èƒ½ç›‘æ§ï¼ŒåŒ…æ‹¬å‘½ä¸­ç‡ã€å“åº”æ—¶é—´ç­‰æŒ‡æ ‡
3. **æ›´çµæ´»çš„é…ç½®**: æ”¯æŒåºåˆ—åŒ–å™¨å‚æ•°ã€Redis è¿æ¥é…ç½®ç­‰
4. **æ›´å¥½çš„é”™è¯¯å¤„ç†**: æ”¹è¿›çš„å¼‚å¸¸å¤„ç†å’Œæ—¥å¿—è®°å½•
5. **æ€§èƒ½ä¼˜åŒ–**: æ›´é«˜æ•ˆçš„åºåˆ—åŒ–å’Œååºåˆ—åŒ–
6. **ç›‘æ§å¢å¼º**: æ›´è¯¦ç»†çš„å†…å­˜ä½¿ç”¨ç›‘æ§å’Œç»Ÿè®¡æŠ¥å‘Š

## ğŸ“¦ å®‰è£…

```bash
pip install fn_cache
```

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

## ğŸªª è®¸å¯è¯

MIT License
